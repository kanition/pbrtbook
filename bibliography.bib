# preface
@article{10.1093/comjnl/27.2.97,
  author   = {Knuth, Donald Ervin},
  title    = {Literate Programming},
  journal  = {The Computer Journal},
  volume   = {27},
  number   = {2},
  pages    = {97-111},
  year     = {1984},
  month    = {01},
  abstract = {{The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.}},
  issn     = {0010-4620},
  doi      = {10.1093/comjnl/27.2.97},
  eprint   = {https://academic.oup.com/comjnl/article-pdf/27/2/97/981657/270097.pdf}
}

@book{10.5555/536126,
  author    = {Knuth, Donald Ervin},
  title     = {{M}etafont: The Program},
  year      = {1986},
  isbn      = {0201134381},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  address   = {USA},
  edition   = {1st}
}

@book{10.5555/536123,
  author    = {Knuth, Donald Ervin},
  title     = {{TEX}: The Program},
  year      = {1986},
  isbn      = {0201134373},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  address   = {USA}
}

@book{10.1145/164984,
  author    = {Knuth, Donald Ervin},
  title     = {The Stanford GraphBase: A Platform for Combinatorial Computing},
  year      = {1993},
  isbn      = {0201542757},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA}
}

@book{10.5555/555424,
  author    = {Fraser, Christopher W. and Hanson, David R.},
  title     = {A Retargetable {C} Compiler: Design and Implementation},
  year      = {1995},
  isbn      = {0805316701},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  address   = {USA},
  abstract  = {From the Publisher:This new text examines the design and implementation of Icc, a production-quality, retargetable compiler, designed at AT&amp;T Bell Laboratories and Princeton University for the ANSI C programming language. The authors' innovative approach - a "literate program" that intermingles the text with the source code - gives a detailed tour of the code that explains the implementation and design decisions reflected in the software. And while most books describe toy compilers or focus on isolated pieces of code, the authors have made available the entire source code for a real compiler. Structured as a self-study guide that describes the real-world tradeoffs encountered in building a production-quality compiler, A Retargetable C Compiler is also useful to individuals who work in application areas using or creating language-based tools and techniques. Features: discusses the implementation and design tradeoffs made while constructing a real ANSI C compiler, illustrating the interaction between theory and practice; covers compiler theory only as needed to understand the implementation of Icc, focusing instead on practical, applied issues; encourages a deeper understanding of programming in C, by providing C programmers with a tour of the language from the perspective of compiler authors; includes coverage of code generators for the MIPS R3000, SPARC, and Intel 386 and its successors; and provides access to the full source code for the Icc compiler, the three back ends, and the code-generator generator, either on disk or via FTP.}
}

@book{10.5555/1036653,
  author    = {Ruckert, Martin},
  title     = {Understanding {MP3}},
  year      = {2005},
  isbn      = {3528059052},
  publisher = {Friedr. Vieweg \& Sohn Verlag/GWV Fachverlage GmbH},
  address   = {Wiesbaden, Germany}
}

#prefaceonline
@book{4b212a02-105c-42a2-ad5c-91c16a06e815,
  author    = {Ström, Jakob O and Åström, Karl and Akenine-Möller, Tomas},
  isbn      = {978-91-637-9354-7},
  language  = {eng},
  publisher = {ImmersiveMath},
  title     = {Immersive Linear Algebra},
  url       = {http://immersivemath.com/ila/},
  year      = {2015}
}

@book{978-1138627000,
  author    = {Tomas Akenine-M\"{o}ller and Eric Haines and Naty Hoffman and Angelo Pesce and Micha\l{} Iwanicki and S\'{e}bastien Hillaire},
  publisher = {A. K. Peters/CRC Press},
  title     = {Real-Time Rendering},
  year      = {2018},
  month     = {8},
  edition   = {4},
  pages     = {1200},
  isbn      = {978-1-13862-700-0},
  address   = {Boca Raton, FL, USA},
  url       = {https://www.realtimerendering.com/}
}

#chapter01
@article{10.1007/BF02684409,
  author     = {Szirmay-Kalos, L. and M\'{a}rton, G.},
  title      = {Worst-Case versus Average Case Complexity of Ray-Shooting},
  year       = {1998},
  issue_date = {1998},
  publisher  = {Springer-Verlag},
  address    = {Berlin, Heidelberg},
  volume     = {61},
  number     = {2},
  issn       = {0010-485X},
  doi        = {10.1007/BF02684409},
  journal    = {Computing},
  month      = oct,
  pages      = {103-131},
  numpages   = {29},
  keywords   = {complexity, ray-shooting, computational geometry, stochastic analysis}
}

@article{10.1145/358876.358882,
  author     = {Whitted, Turner},
  title      = {An Improved Illumination Model for Shaded Display},
  year       = {1980},
  issue_date = {June 1980},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {23},
  number     = {6},
  issn       = {0001-0782},
  doi        = {10.1145/358876.358882},
  abstract   = {To accurately render a two-dimensional image of a three-dimensional scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of “rays” extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. A visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction, as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.},
  journal    = {Commun. ACM},
  month      = jun,
  pages      = {343-349},
  numpages   = {7},
  keywords   = {computer animation, visible surface algorithms, computer graphics, shading, raster displays}
}

@inproceedings{10.1145/74333.74361,
  author    = {Kajiya, James T. and Kay, Timothy L.},
  title     = {Rendering Fur with Three Dimensional Textures},
  year      = {1989},
  isbn      = {0897913124},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/74333.74361},
  abstract  = {We present a method for rendering scenes with fine detail via an object called a texel, a rendering primitive inspired by volume densities mixed with anisotropic lighting models. This technique solves a long outstanding problem in image synthesis: the rendering of furry surfaces.},
  booktitle = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {271-280},
  numpages  = {10},
  series    = {SIGGRAPH '89}
}

# 1.3.2
@book{10.5555/136311,
  author    = {Levine, John R. and Mason, Tony and Brown, Doug},
  title     = {Lex \& Yacc},
  year      = {1992},
  isbn      = {1565920007},
  publisher = {O'Reilly \& Associates, Inc.},
  address   = {USA},
  edition   = {2}
}

# 2.extra
@inbook{10.5555/90767.90913,
  author    = {Maillot, Patrick-Gilles},
  title     = {Using Quaternions for Coding {3D} Transformations},
  year      = {1990},
  isbn      = {0122861695},
  publisher = {Academic Press Professional, Inc.},
  address   = {USA},
  booktitle = {Graphics Gems},
  pages     = {498-515},
  numpages  = {18}
}

@misc{enwiki:1013104981,
  author       = {{Wikipedia contributors}},
  title        = {Division ring --- {Wikipedia}{,} The Free Encyclopedia},
  year         = {2021},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Division_ring&oldid=1013104981}},
  note         = {[Online; accessed 16-April-2021]}
}

# 1.7
@inproceedings{10.1145/800224.806819,
  author    = {Cook, Robert L. and Torrance, Kenneth E.},
  title     = {A Reflectance Model for Computer Graphics},
  year      = {1981},
  isbn      = {0897910451},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800224.806819},
  abstract  = {This paper presents a new reflectance model for rendering computer synthesized images. The model accounts for the relative brightness of different materials and light sources in the same scene. It describes the directional distribution of the reflected light and a color shift that occurs as the reflectance changes with incidence angle. The paper presents a method for obtaining the spectral energy distribution of the light reflected from an object made of a specific real material and discusses a procedure for accurately reproducing the color associated with the spectral energy distribution. The model is applied to the simulation of a metal and a plastic.},
  booktitle = {Proceedings of the 8th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {307-316},
  numpages  = {10},
  keywords  = {Reflectance, Computer graphics, Shading, Image synthesis},
  location  = {Dallas, Texas, USA},
  series    = {SIGGRAPH '81}
}

@article{10.1145/357290.357293,
  author     = {Cook, Robert L. and Torrance, Kenneth E.},
  title      = {A Reflectance Model for Computer Graphics},
  year       = {1982},
  issue_date = {Jan. 1982},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/357290.357293},
  journal    = {ACM Trans. Graph.},
  month      = {1},
  pages      = {7-24},
  numpages   = {18},
  keywords   = {image synthesis, reflectance}
}

@inproceedings{10.1145/800031.808601,
  author    = {Goral, Cindy M. and Torrance, Kenneth E. and Greenberg, Donald P. and Battaile, Bennett},
  title     = {Modeling the Interaction of Light between Diffuse Surfaces},
  year      = {1984},
  isbn      = {0897911385},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800031.808601},
  abstract  = {A method is described which models the interaction of light between diffusely reflecting surfaces. Current light reflection models used in computer graphics do not account for the object-to-object reflection between diffuse surfaces, and thus incorrectly compute the global illumination effects. The new procedure, based on methods used in thermal engineering, includes the effects of diffuse light sources of finite area, as well as the “color-bleeding” effects which are caused by the diffuse reflections. A simple environment is used to illustrate these simulated effects and is presented with photographs of a physical model. The procedure is applicable to environments composed of ideal diffuse reflectors and can account for direct illumination from a variety of light sources. The resultant surface intensities are independent of observer position, and thus environments can be preprocessed for dynamic sequences.},
  booktitle = {Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {213-222},
  numpages  = {10},
  keywords  = {Diffuse reflections, Shading, Radiosity, Light reflection models, Form factors},
  series    = {SIGGRAPH '84}
}

@inproceedings{10.1145/325334.325171,
  author    = {Cohen, Michael F. and Greenberg, Donald P.},
  title     = {The Hemi-Cube: A Radiosity Solution for Complex Environments},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325171},
  abstract  = {This paper presents a comprehensive method to calculate object to object diffuse reflections within complex environments containing hidden surfaces and shadows. In essence, each object in the environment is treated as a secondary light source. The method provides an accurate representation of the "diffuse" and "ambient" terms found in typical image synthesis algorithms. The phenomena of "color bleeding" from one surface to another, shading within shadow envelopes, and penumbras along shadow boundaries are accurately reproduced. Additional advantages result because computations are indepedent of viewer position. This allows the efficient rendering of multiple views of the same scene for dynamic sequences. Light sources can be modulated and object reflectivities can be changed, with minimal extra computation. The procedures extend the radiosity method beyond the bounds previously imposed.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {31-40},
  numpages  = {10},
  keywords  = {hidden surface, form-factors, depth buffer, radiosity, diffuse reflections},
  series    = {SIGGRAPH '85}
}

@inproceedings{10.1145/325334.325169,
  author    = {Nishita, Tomoyuki and Nakamae, Eihachiro},
  title     = {Continuous Tone Representation of Three-Dimensional Objects Taking Account of Shadows and Interreflection},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325169},
  abstract  = {The effect of shadows and interreflection created by room obstructions is an important factor in the continuous tone representation of interiors. For indirect illumination, in most cases a uniform ambient light has been considered, even though the interreflection gives very complex effects with the shaded images.The proposed method for indirect lighting with shadows results in the following advanced points:1) The indirect illuminance caused by the surfaces of objects such as ceilings, floors, walls, desks, bookcases etc. gives added realism to images.2) The proposed method is suitable for every type of light source such as point sources, linear sources, and area sources.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {23-30},
  numpages  = {8},
  keywords  = {diffuse reflections, penumbrae, interreflection of light, shading, area light source, shadows},
  series    = {SIGGRAPH '85}
}

@inproceedings{10.1145/800031.808590,
  author    = {Cook, Robert L. and Porter, Thomas and Carpenter, Loren},
  title     = {Distributed Ray Tracing},
  year      = {1984},
  isbn      = {0897911385},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800031.808590},
  abstract  = { Ray tracing is one of the most elegant techniques in computer graphics. Many phenomena that are difficult or impossible with other techniques are simple with ray tracing, including shadows, reflections, and refracted light. Ray directions, however, have been determined precisely, and this has limited the capabilities of ray tracing. By distributing the directions of the rays according to the analytic function they sample, ray tracing can incorporate fuzzy phenomena. This provides correct and easy solutions to some previously unsolved or partially solved problems, including motion blur, depth of field, penumbras, translucency, and fuzzy reflections. Motion blur and depth of field calculations can be integrated with the visible surface calculations, avoiding the problems found in previous methods. },
  booktitle = {Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {137-145},
  numpages  = {9},
  keywords  = {Transparency, Depth of field, Gloss, Shadows, Camera, Motion blur, Translucency, Penumbras, Constructive solid geometry, Focus, Ray tracing},
  series    = {SIGGRAPH '84}
}

@inproceedings{10.1145/15922.15902,
  author    = {Kajiya, James T.},
  title     = {The Rendering Equation},
  year      = {1986},
  isbn      = {0897911962},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/15922.15902},
  abstract  = {We present an integral equation which generalizes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting rendering algorithm extends the range of optical phenomena which can be effectively simulated.},
  booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {143-150},
  numpages  = {8},
  series    = {SIGGRAPH '86}
}

@article{farmer1981comparing,
  title   = {Comparing the 4341 and {M}80/42},
  author  = {Farmer, DF},
  journal = {Computerworld},
  volume  = {15},
  pages   = {9-20},
  year    = {1981}
}

@inproceedings{10.1145/800031.808594,
  author    = {Kajiya, James T. and Von Herzen, Brian P},
  title     = {Ray Tracing Volume Densities},
  year      = {1984},
  isbn      = {0897911385},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800031.808594},
  abstract  = {This paper presents new algorithms to trace objects represented by densities within a volume grid, e.g. clouds, fog, flames, dust, particle systems. We develop the light scattering equations, discuss previous methods of solution, and present a new approximate solution to the full three-dimensional radiative scattering problem suitable for use in computer graphics. Additionally we review dynamical models for clouds used to make an animated movie.},
  booktitle = {Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {165-174},
  numpages  = {10},
  keywords  = {Light scattering, Stochastic modeling, Clouds, Radiative transport, Particle systems, Simulation of natural phenomena, Computer graphics, Ray tracing, Raster graphics},
  series    = {SIGGRAPH '84}
}

@inproceedings{10.1145/97879.97886,
  author    = {Arvo, James and Kirk, David},
  title     = {Particle Transport and Image Synthesis},
  year      = {1990},
  isbn      = {0897913442},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/97879.97886},
  abstract  = {The rendering equation is similar to the linear Boltzmann equation which has been widely studied in physics and nuclear engineering. Consequently, many of the powerful techniques which have been developed in these fields can be applied to problems in image synthesis. In this paper we adapt several statistical techniques commonly used in neutron transport to stochastic ray tracing and, more generally, to Monte Carlo solution of the rendering equation. First, we describe a technique known as Russian roulette which can be used to terminate the recursive tracing of rays without introducing statistical bias. We also examine the practice of creating ray trees in classical ray tracing in the light of a well-known technique in particle transport known as splitting. We show that neither ray trees nor paths as described in [10] constitute an optimal sampling plan in themselves and that a hybrid may be more efficient.},
  booktitle = {Proceedings of the 17th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {63-66},
  numpages  = {4},
  location  = {Dallas, TX, USA},
  series    = {SIGGRAPH '90}
}

@inproceedings{10.1145/122718.122735,
  author    = {Kirk, David and Arvo, James},
  title     = {Unbiased Sampling Techniques for Image Synthesis},
  year      = {1991},
  isbn      = {0897914368},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/122718.122735},
  abstract  = {We examine a class of adaptive sampling techniques employed in image synthesis and show that those commonly used for efficient anti-aliasing are statistically biased. This bias is dependent upon the image function being sampled as well as the strategy for determining the number of samples to use. It is most prominent in areas of high contrast and is attributable to early stages of sampling systematically favoring one extreme or the other. If the expected outcome of the entire adaptive sampling algorithm is considered, we find that the bias of the early decisions is still present in the final estimator. We propose an alternative strategy for performing adaptive sampling that is unbiased but potentially more costly. We conclude that it may not always be practical to mitigate this source of bias, but as a source of error it should be considered when high accuracy and image fidelity are a central concern.},
  booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {153-156},
  numpages  = {4},
  keywords  = {statistical bias, adaptive sampling, Monte Carlo, antialiasing},
  series    = {SIGGRAPH '91}
}

@phdthesis{10.5555/124947,
  author      = {Shirley, Peter S.},
  title       = {Physically Based Lighting Calculations for Computer Graphics},
  year        = {1991},
  institution = {University of Illinois at Urbana-Champaign},
  address     = {USA},
  abstract    = {Realistic image generation is presented in a theoretical formulation that builds from previous work on the rendering equation. Previous and new solution techniques for the global illumination are discussed in the context of this formulation. The physical rules governing reflection are used to make improvements in local reflection models. The conventional local illumination models used in computer graphics are examined and modified to be consistent with these physical rules.Global illumination is treated in terms of evaluation of a Global Radiance Function. Image-based solution methods are phrased as a lazy evaluation of the Global Radiance Function; evaluation takes place for visible points. Zonal solution methods are phrased as table based solutions. A proof is given that, subject to certain constraints, only O(N) rays are required for a zonal solution with N zones. Simulation allows for surfaces which are not zoned to interact with those that are.The ray tracing zonal solution methods used for surfaces are extended to scenes with participating media. The impact of wavelength selection and time dependencies is also discussed.An object oriented implementation is discussed. This implementation separates the local and global illumination modules, so all of the specifics of the local models are hidden from the global energy transport code. This allows new local modules to be added by specifying the black box access routines.},
  note        = {UMI Order NO. GAX91-24487}
}

@article{10.1145/226150.226151,
  author     = {Shirley, Peter S. and Wang, Changyaw and Zimmerman, Kurt},
  title      = {{M}onte {C}arlo Techniques for Direct Lighting Calculations},
  year       = {1996},
  issue_date = {Jan. 1996},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {15},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/226150.226151},
  abstract   = {In a distributed ray tracer, the sampling strategy is the crucial part of the direct lighting calculation. Monte Carlo integration with importance sampling is used to carry out this calculation. Importance sampling involves the design of integrand-specific probability density functions that are used to generate sample points for the numerical quadrature. Probability density functions are presented that aid in the direct lighting calculation from luminaires of various simple shapes. A method for defining a probability density function over a set of luminaires is presented that allows the direct lighting calculation to be carried out with a number of sample points that is independent of the number of luminaires.},
  journal    = {ACM Trans. Graph.},
  month      = {1},
  pages      = {1-36},
  numpages   = {36},
  keywords   = {Monte Carlo integration, ray tracing, direct lighting, realistic image synthesis, importance sampling, luminaires}
}

@book{10.1007/978-1-4612-3526-2,
  author    = {Hall, Roy A.},
  publisher = {Springer},
  title     = {Illumination and Color in Computer Generated Imagery},
  year      = {1989},
  doi       = {10.1007/978-1-4612-3526-2},
  address   = {New York},
  series    = {Monographs in Visual Communication},
  isbn      = {978-0-387-96774-5},
  keywords  = {Computer Graphics, Image Processing and Computer Vision}
}

@book{GLASSNER1995,
  author    = {Glassner, Andrew S.},
  title     = {Principles of Digital Image Synthesis},
  isbn      = {978-0-08-051475-8},
  publisher = {Morgan Kaufmann},
  address   = {San Francisco (CA)},
  year      = {1995},
  series    = {The Morgan Kaufmann Series in Computer Graphics},
  doi       = {10.1016/B978-0-08-051475-8.50009-2},
  abstract  = {From the Publisher:Image synthesis, or rendering, is a field of transformation: it changes geometry and physics into meaningful images. Because the most popular algorithms frequently change, it is increasingly important for researchers and implementors to have a basic understanding of the principles of image synthesis. Focusing on theory, Andrew Glassner provides a comprehensive explanation of the three core fields of study that come together to form digital image synthesis: the human visual system, digital signal processing, and the interaction of matter and light. Assuming no more than a basic background in calculus, Glassner transforms his passion and expertise into a thorough presentation of each of these disciplines, and their elegant orchestration into modern rendering techniques such as radiosity and ray tracing.}
}

@inproceedings{10.1145/192161.192286,
  author    = {Ward, Gregory J.},
  title     = {The RADIANCE Lighting Simulation and Rendering System},
  year      = {1994},
  isbn      = {0897916670},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/192161.192286},
  abstract  = {This paper describes a physically-based rendering system tailored to the demands of lighting design and architecture. The simulation uses a light-backwards ray-tracing method with extensions to efficiently solve the rendering equation under most conditions. This includes specular, diffuse and directional-diffuse reflection and transmission in any combination to any level in any environment, including complicated, curved geometries. The simulation blends deterministic and stochastic ray-tracing techniques to achieve the best balance between speed and accuracy in its local and global illumination methods. Some of the more interesting techniques are outlined, with references to more detailed descriptions elsewhere. Finally, examples are given of successful applications of this free software by others.},
  booktitle = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {459-472},
  numpages  = {14},
  keywords  = {Monte Carlo, physically-based rendering, lighting simulation, ray-tracing, radiosity},
  series    = {SIGGRAPH '94}
}

@phdthesis{slusallek1996vision,
  title       = {Vision-an Architecture for Physically-based Rendering: Vision-Eine Architektur F{\"u}r Die Physikalisch-basierte Bildsynthese},
  author      = {Slusallek, Philipp},
  year        = {1995},
  month       = {04},
  institution = {University of Erlangen, Inst. f{\"u}r Math. Maschinen und Datenverarbeitung (Informatik), Computer Graphics Group}
}

@inproceedings{10.1145/258734.258914,
  author    = {Greenberg, Donald P. and Torrance, Kenneth E. and Shirley, Peter and Arvo, James and Lafortune, Eric and Ferwerda, James A. and Walter, Bruce and Trumbore, Ben and Pattanaik, Sumanta and Foo, Sing-Choong},
  title     = {A Framework for Realistic Image Synthesis},
  year      = {1997},
  isbn      = {0897918967},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/258734.258914},
  booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {477-494},
  numpages  = {18},
  keywords  = {light reflection, perception, realistic image synthesis},
  series    = {SIGGRAPH '97}
}

@phdthesis{veach1997robust,
  title  = {Robust {M}onte {C}arlo methods for light transport simulation},
  author = {Veach, Eric},
  year   = {1997},
  month  = {12},
  school = {Stanford University},
  url    = {http://graphics.stanford.edu/papers/veach_thesis}
}

@inproceedings{10.1007/978-3-7091-6242-2_26,
  author    = {Wald, Ingo and Slusallek, Philipp and Benthin, Carsten},
  editor    = {Gortler, Steven J. and Myszkowski, Karol},
  title     = {Interactive Distributed Ray Tracing of Highly Complex Models},
  booktitle = {Rendering Techniques 2001},
  year      = {2001},
  publisher = {Springer Vienna},
  address   = {Vienna},
  pages     = {277-288},
  abstract  = {Many disciplines must handle the creation, visualization, and manipulation of huge and complex 3D environments. Examples include large structural and mechanical engineering projects dealing with entire cars, ships, buildings, and processing plants. The complexity of such models is usually far beyond the interactive rendering capabilities of todays 3D graphics hardware. Previous approaches relied on costly preprocessing for reducing the number of polygons that need to be rendered per frame but suffered from excessive precomputation times --- often several days or even weeks.},
  isbn      = {978-3-7091-6242-2}
}

@inproceedings{10.1145/37401.37414,
  author    = {Cook, Robert L. and Carpenter, Loren and Catmull, Edwin},
  title     = {The Reyes Image Rendering Architecture},
  year      = {1987},
  isbn      = {0897912276},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/37401.37414},
  abstract  = {An architecture is presented for fast high-quality rendering of complex images. All objects are reduced to common world-space geometric entities called micropolygons, and all of the shading and visibility calculations operate on these micropolygons. Each type of calculation is performed in a coordinate system that is natural for that type of calculation. Micropolygons are created and textured in the local coordinate sysem of the object, with the result that texture filtering is simplified and improved. Visibility is calculated in screen space using stochastic point sampling with a z buffer. There are no clipping or inverse perspective calculations. Geometric and texture locality are exploited to minimize paging and to support models that contain arbitrarily many primitives.},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {95-102},
  numpages  = {8},
  series    = {SIGGRAPH '87}
}

@article{snow2010terminators,
  title   = {{T}erminators and {I}ron {M}en: Image-based lighting and physical shading at {ILM}},
  author  = {Snow, Ben},
  journal = {part of “Physically Based Shading Models in Film and Game Production,” SIGGRAPH},
  year    = {2010}
}

 @online{ohmer1997,
  title        = {Ray Tracers: Blue Sky Studios},
  url          = {https://www.awn.com/animationworld/ray-tracers-blue-sky-studios},
  organization = {Animation World Network},
  author       = {Ohmer, Susan},
  date         = {1997-05-01}
}

@inproceedings{10.1145/2776880.2792699,
  author    = {Keller, A. and Fascione, L. and Fajardo, M. and Georgiev, I. and Christensen, P. and Hanika, J. and Eisenacher, C. and Nichols, G.},
  title     = {The Path Tracing Revolution in the Movie Industry},
  year      = {2015},
  isbn      = {9781450336345},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2776880.2792699},
  abstract  = {As path tracing allows for more realistic and faster lighting, an increasing number of movies are created the physically based way. With examples from recent movies, the architectures and novel workflows of the next generation of production renderers are introduced to a wide audience including technical directors, artists, and researchers.},
  booktitle = {ACM SIGGRAPH 2015 Courses},
  articleno = {24},
  numpages  = {7},
  location  = {Los Angeles, California},
  series    = {SIGGRAPH '15}
}

% 1.8
@inproceedings{10.1145/1468075.1468082,
  author    = {Appel, Arthur},
  title     = {Some Techniques for Shading Machine Renderings of Solids},
  year      = {1968},
  isbn      = {9781450378970},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1468075.1468082},
  abstract  = {Some applications of computer graphics require a vivid illusion of reality. These include the spatial organization of machine parts, conceptual architectural design, simulation of mechanisms, and industrial design. There has been moderate success in the automatic generation of wire frame, cardboard model, polyhedra, and quadric surface line drawings. The capability of the machine to generate vivid sterographic pictures has been demonstrated. There are, however considerable reasons for developing techniques by which line drawings of solids can be shaded, especially the enhancement of the sense of solidity and depth. Figures 1 and 2 illustrate the value of shading and shadow casting in spatial description. In the line drawing there is no clue as to the relative position of the flat plane and the sheet metal console. When shadows are rendered, it is clear that the plane is below and to the rear of the console, and the hollow nature of the sheet metal assembly is emphasized. Shading can specify the tone or color of a surface and the amount of light falling upon that surface from one or more light sources. Shadows when sharply defined tend to suggest another viewpoint and improves surface definition. When controlled, shading can also emphasize particular parts of the drawing. If techniques for the automatic determination of chiaroscuro with good resolution should prove to be competitive with line drawings, and this is a possibility, machine generated photographs might replace line drawings as the principal mode of graphical communication in engineering and architecture.},
  booktitle = {Proceedings of the April 30--May 2, 1968, Spring Joint Computer Conference},
  pages     = {37-45},
  numpages  = {9},
  location  = {Atlantic City, New Jersey},
  series    = {AFIPS '68 (Spring)}
}

@article{doi:10.1177/003754977101600104,
  author   = {Robert A. Goldstein and Roger Nagel},
  title    = {3-{D} Visual simulation},
  journal  = {SIMULATION},
  volume   = {16},
  number   = {1},
  pages    = {25-31},
  year     = {1971},
  doi      = {10.1177/003754977101600104},
  abstract = {This paper describes a visual simulation technique by which fully computer-generated perspective views of three-dimensional objects may be produced. The method is based on a relatively simple geometric modeling technique for the mathematical representa tion of the three elements essential to the picture- taking process, namely, a camera, a light source, and the object or objects to be photographed. Once these three basic components have been defined, geometric ray tracing is employed to compute a "picture" of the object as it appears in the simu- Zated camera. In essence, individual light rays are traced from their source to the surface of the object. The reflected component of each ray is computed and traced to its point of intersection with the film plane. Thus, each reflected ray pro vides the intensity at a single point on the pic ture, and, when a sufficient number of points have been computed, the entire area of intensity data may be displayed on a cathode ray tube. Several examples of the pictorial output of this process are shown, and the application to the computer- generated films is discussed. }
}

@inproceedings{10.1145/800249.807438,
  author    = {Kay, Douglas Scott and Greenberg, Donald P.},
  title     = {Transparency for Computer Synthesized Images},
  year      = {1979},
  isbn      = {0897910044},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800249.807438},
  abstract  = {Simple transparency algorithms which assume a linear transparency over an entire surface are the type most often employed to produce computer synthesized images of transparent objects with curved surfaces. Although most of the images created with these algorithms do give the impression of transparency, they usually do not look realistic. One of the most serious problems is that the intensity of the light that is transmitted through the objects is generally not proportional to the amount of material through which it must pass. Another problem is that the image seen behind the objects is not distorted as would naturally occur when the light is refracted as it passes through a material of different density.Use of a non-linear transparency algorithm can provide a great improvement in the realism of an image at a small additional cost. Making the transparency proportional to the normal to the surface causes it to decrease towards the edges of the surface where the path of the light through the object is longer. The exact simulation of refraction, however, requires that each sight ray be individually traced from the observer, through the picture plane and through each transparent object until an opaque surface is intersected. Since the direction of the ray would change as each material of differing optical density was entered, the hidden surface calculations required would be very time consuming. However, if a few assumptions are made about the geometry of each object and about the conditions under which they are viewed, a much simplier algorithm can be used to approximate the refractive effect. This method proceeds in a back to front order, mapping the current background image onto the next surface, until all surfaces have been considered.},
  booktitle = {Proceedings of the 6th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {158-164},
  numpages  = {7},
  keywords  = {Computer graphics, Refraction, Image synthesis, Shading, Transparency},
  location  = {Chicago, Illinois, USA},
  series    = {SIGGRAPH '79}
}

@inproceedings{10.1145/37401.37411,
  author    = {Heckbert, Paul S.},
  title     = {Ray Tracing {JELL}-{OTM} Brand Gelatin},
  year      = {1987},
  isbn      = {0897912276},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/37401.37411},
  abstract  = {Ray tracing has established itself in recent years as the most general image synthesis algorithm. Researchers have investigated ray-surface intersection calculations for a number of surface primitives, including checkerboards, glass balls, green fractal hills, mandrills, abstract blue surfaces, more glass balls, robot arms, pool balls, low-resolution clouds, morphine molecules, aquatic blobby things making strange noises, fantastic cities, and running skeletons. Unfortunately, nobody has ray traced any food. The Dessert Realism Project here at Pixar is addressing this problem. This paper presents new technology for ray tracing Jell-O® brand gelatin. We believe the method may have application to other brands of gelatin and perhaps pudding as well.},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {73-74},
  numpages  = {2},
  series    = {SIGGRAPH '87}
}

@book{10.5555/154731,
  author    = {Cohen, Michael F. and Wallace, John and Hanrahan, Pat},
  title     = {Radiosity and Realistic Image Synthesis},
  year      = {1993},
  isbn      = {0121782700},
  publisher = {Academic Press Professional, Inc.},
  address   = {USA}
}

@book{10.5555/561383,
  author    = {Sillion, Francois X. and Puech, Claude},
  title     = {Radiosity and Global Illumination},
  year      = {1994},
  isbn      = {1558602771},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  abstract  = {From the Publisher:The radiosity method, originally a computation tool for thermal engineers, has evolved in recent years into a powerful and flexible simulation technique for radiant energy transfer. The ability to compute quantitatively accurate simulations of light transfers has opened a vast domain of applications for computer graphics. Thermal radiation studies, lighting design and remote sensing are a few of the fields affected by this exciting technique for producing synthetic images. Here, the authors reformulate some of the most recent and innovative research results into a consistent framework, allowing readers to quickly acquire a comprehensive view of the technique and its derivatives. In addition to reviewing practical issues and offering recommendations, the authors also provide a complete theoretical presentation of the various radiosity algorithms.Special highlights include 93 illustrations and 45 color plates and a practical guide which provides detailed information on various design issues for the development of global illumination software.}
}

@book{10.5555/200607,
  author    = {Ashdown, Ian},
  title     = {Radiosity: A Programmer's Perspective},
  year      = {1995},
  isbn      = {0471304883},
  publisher = {John Wiley \& Sons, Inc.},
  address   = {USA}
}

@inproceedings{Kirk88theray,
  author    = {David Kirk and James Arvo},
  title     = {The Ray Tracing Kernel},
  booktitle = {In Proceedings of Ausgraph},
  year      = {1988},
  month     = {7},
  pages     = {75-82},
  address   = {Melbourne, Australia}
}

@book{10.5555/94788,
  editor    = {Glassner, Andrew S.},
  title     = {An Introduction to Ray Tracing},
  year      = {1989},
  isbn      = {0122861604},
  publisher = {Academic Press Ltd.},
  address   = {GBR}
}

@book{10.5555/940410,
  author    = {Shirley, Peter S. and Morley, R. Keith},
  title     = {Realistic Ray Tracing},
  year      = {2003},
  isbn      = {1568811985},
  publisher = {A. K. Peters, Ltd.},
  address   = {USA},
  edition   = {2},
  abstract  = {From the Publisher:Realistic Ray Tracing is an innovative, in-depth look at the theory and techniques of ray tracing, a method of producing photorealistic computer graphics images by applying simple algorithms. This book will guide you through the steps of creating your own powerful ray tracer program, proceeding from simple images through advanced special effects such as soft shadows, glass and metal textures, and motion blur. It concentrates on the nuts and bolts of writing ray tracing programs, with plenty of practical, detail-oriented how-to advice and careful attention to the underlying theory.}
}

@book{10.5555/1324795,
  author    = {Suffern, Kevin},
  title     = {Ray Tracing from the Ground Up},
  year      = {2007},
  isbn      = {1568812728},
  publisher = {A. K. Peters, Ltd.},
  address   = {USA}
}

@inproceedings{egtp.19911035,
  booktitle = {EG 1991-Technical Papers},
  editor    = {Werner Purgathofer},
  title     = {A Testbed for Image Synthesis},
  author    = {Trumbore, Ben and Lytle, Wayne and Greenberg, Donald P.},
  year      = {1991},
  month     = {09},
  address   = {North-Holland},
  publisher = {Eurographics Association},
  pages     = {467-480},
  issn      = {1017-4656},
  doi       = {10.2312/egtp.19911035}
}

@article{4037684,
  author  = {Hall, Roy A. and Greenberg, Donald P.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {A Testbed for Realistic Image Synthesis},
  year    = {1983},
  volume  = {3},
  number  = {8},
  pages   = {10-20},
  doi     = {10.1109/MCG.1983.263292}
}

@book{10.5555/286090,
  author    = {Larson, Greg Ward and Shakespeare, Rob},
  title     = {Rendering with Radiance: The Art and Science of Lighting Visualization},
  year      = {1998},
  isbn      = {1558604995},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA}
}

@inproceedings{10.1145/325334.325174,
  author    = {Duff, Tom},
  title     = {Compositing 3-{D} Rendered Images},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325174},
  abstract  = {The complexity of anti-aliased 3-D rendering systems can be controlled by using a tool-building approach like that of the UNIX™ text-processing tools. Such an approach requires a simple picture representation amenable to anti-aliasing that all rendering programs can produce, a compositing algorithm for that representation and a command language to piece together scenes. This paper advocates a representation that combines Porter and Duff's compositing algebra with a Z-buffer to provide simple anti-aliased 3-D compositing.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {41-44},
  numpages  = {4},
  keywords  = {anti-aliasing, Z-buffer, image synthesis, compositing, 3-D rendering, hidden-surface elimination},
  series    = {SIGGRAPH '85}
}

@article{glassner1993spectrum,
  title   = {Spectrum: An architecture for image synthesis, research, education, and practice},
  author  = {Glassner, Andrew S.},
  editor  = {Strauss, Paul S.},
  journal = {Developing Large-scale Graphics Software Toolkits,(SIGGRAPH'93 Course Notes 3)},
  pages   = {1.1-1.44},
  year    = {1993},
  month   = {08}
}

@article{468387,
  author  = {Slusallek, Philipp and Seidel, Hans-Peter},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Vision-an architecture for global illumination calculations},
  year    = {1995},
  volume  = {1},
  number  = {1},
  pages   = {77-96},
  doi     = {10.1109/2945.468387}
}

@inproceedings{10.1007/978-3-7091-7484-5_6,
  author    = {Slusallek, Philipp and Seidel, Hans-Peter},
  editor    = {Pueyo, Xavier and Schr{\"o}der, Peter},
  title     = {Towards an Open Rendering Kernel for Image Synthesis},
  booktitle = {Rendering Techniques '96},
  year      = {1996},
  publisher = {Springer Vienna},
  address   = {Vienna},
  pages     = {51-60},
  abstract  = {In order to use realistic image synthesis successfully in research and development as well as in commercial products, two important prerequisites have to be fulfilled. First of all, good, accurate, robust, and fast algorithms are required. Impressive progress has been made in this respect during the last years, which has also been documented in this workshop. The second step is the creation of a suitable and general software architecture, that offers an environment into which these rendering algorithms can be integrated.},
  isbn      = {978-3-7091-7484-5}
}

@book{10.5555/555371,
  author    = {Apodaca, Anthony A. and Gritz, Larry and Barsky, Brian A.},
  title     = {Advanced RenderMan: Creating {CGI} for Motion Picture},
  year      = {1999},
  month     = {12},
  isbn      = {1558606181},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  edition   = {1st},
  abstract  = {From the Publisher: Introduced by Pixar Studios over a decade ago, the RenderMan Interface Specification is the dominant standard for sending data to the leading rendering programs used by 3D artists and animators. But users are hampered by the lack of authoritative, up-to-date information on applying the standard, having long had to rely on the ten-year-old RenderMan Companion and a far-flung collection of course notes and Web sites. Advanced RenderMan: Beyond the Companion is precisely what RenderMan users are dying for. It offers thoroughly updated coverage while moving beyond the original work's scope to provide in-depth information on dozens of advanced topics. Both a reference and a tutorial, this book will be indispensable to graphics programmers, modelers, animators, technical directors, and hobbyists-it is truly the key to their ability to achieve state-of-the-art 3D effects. Key Features: Written by the world's foremost RenderMan experts-key figures at Pixar, the company that developed and first implemented the standard Offers advanced users instruction not available anywhere else while providing a leg up to relative beginners-including tips on avoiding mistakes and an appendix covering key math skills. Filled with technical illustrations and many full-color representations of effects supported by the RenderMan standard Via a companion Web site, provides comprehensive documentation of the standard's semantics and syntax, example source code, shaders and other software, and the full set of SIGGRAPH course notes on RenderMan}
}

@article{doi:10.1080/10867651.1996.10487462,
  author    = {Larry Gritz and James K. Hahn},
  title     = {{BMRT}: A Global Illumination Implementation of the RenderMan Standard},
  journal   = {Journal of Graphics Tools},
  volume    = {1},
  number    = {3},
  pages     = {29-47},
  year      = {1996},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.1996.10487462}
}

@inproceedings{732097,
  author    = {Sung, Kelvin and Craighead, James and Changyaw Wang and Bakshi, Sanjay and Pearce, Andrew and Woo, Andrew},
  booktitle = {Proceedings Pacific Graphics '98. Sixth Pacific Conference on Computer Graphics and Applications (Cat. No.98EX208)},
  title     = {Design and implementation of the Maya Renderer},
  year      = {1998},
  pages     = {150-159},
  doi       = {10.1109/PCCGA.1998.732097}
}

@book{10.5555/863712,
  author    = {Driemeyer, Thomas and Herken, Rolf},
  title     = {Programming Mental Ray},
  year      = {2003},
  isbn      = {3211838511},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  edition   = {2}
}

@inproceedings{4061561,
  author    = {Bigler, James and Stephens, Abe and Parker, Steven G.},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {Design for Parallel Interactive Ray Tracing Systems},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {187-196},
  doi       = {10.1109/RT.2006.280230}
}

 @misc{acton_2014,
  title   = {Data-Oriented Design and {C}++},
  url     = {https://www.slideshare.net/cellperformance/data-oriented-design-and-c},
  journal = {SlideShare},
  author  = {Acton, Mike},
  year    = {2014},
  month   = {9}
}

% 2.9
@incollection{SHOEMAKE1991351,
  title     = {VII.6 - Quaternions and 4x4 matrices},
  editor    = {James Arvo},
  booktitle = {Graphics Gems II},
  publisher = {Morgan Kaufmann},
  address   = {San Diego},
  pages     = {351-354},
  year      = {1991},
  isbn      = {978-0-08-050754-5},
  doi       = {10.1016/B978-0-08-050754-5.50074-8},
  author    = {Ken Shoemake},
  abstract  = {Publisher Summary
               This chapter describes the quaternions and 4 x 4 matrices. Quaternions are steadily replacing Euler angles as the internal representation of orientations. They mesh remarkably well with 4 × 4 homogeneous matrices. Matrix multiplication can be used quite nicely for quaternion multiplication, because quaternions are, in fact, four-component homogeneous coordinates for orientations, and because they multiply linearly. A quaternion q as a 4-vector, written as (xq, yq, zq, wq), or as just (x, y, z, w) is described. Some systems do not implement matrix manipulations carefully, and will misbehave if the bottom right entry of the matrix is not 1. Even when normalization is desired, it is not necessary to compute a square root and only addition, subtraction, multiplication, and division are used. It is found that only the last row and column of the two matrices differ, and then only by transposition or sign change.}
}

@inproceedings{10.1145/325334.325242,
  author    = {Shoemake, Ken},
  title     = {Animating Rotation with Quaternion Curves},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325242},
  abstract  = {Solid bodies roll and tumble through space. In computer animation, so do cameras. The rotations of these objects are best described using a four coordinate system, quaternions, as is shown in this paper. Of all quaternions, those on the unit sphere are most suitable for animation, but the question of how to construct curves on spheres has not been much explored. This paper gives one answer by presenting a new kind of spline curve, created on a sphere, suitable for smoothly in-betweening (i.e. interpolating) sequences of arbitrary rotations. Both theory and experiment show that the motion generated is smooth and natural, without quirks found in earlier methods.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {245-254},
  numpages  = {10},
  keywords  = {spherical geometry, B\'{e}zier curve, in-betweening, spline, rotation, B-spline, interpolation, animation, quaternion, approximation},
  series    = {SIGGRAPH '85}
}

@misc{Blow_2004,
  title   = {Understanding Slerp, Then Not Using It},
  url     = {http://number-none.com/product/Understanding%20Slerp,%20Then%20Not%20Using%20It/},
  journal = {Happycake Development Notes},
  author  = {Blow, Jonathan},
  year    = {2004},
  month   = {2}
}

@inproceedings{10.5555/155294.155324,
  author    = {Shoemake, Ken and Duff, Tom},
  title     = {Matrix Animation and Polar Decomposition},
  year      = {1992},
  isbn      = {0969533810},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  booktitle = {Proceedings of the Conference on Graphics Interface '92},
  pages     = {258-264},
  numpages  = {7},
  keywords  = {Polar decomposition, matrix animation, greedy algorithm, homogeneous matrix, spectral decomposition, QR decomposition, matrix decomposition, singular value decomposition, interpolation, rotation},
  location  = {Vancouver, British Columbia, Canada}
}

@article{doi:10.1137/0907079,
  author  = {Higham, Nicholas J.},
  title   = {Computing the Polar Decomposition-with Applications},
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume  = {7},
  number  = {4},
  pages   = {1160-1174},
  year    = {1986},
  doi     = {10.1137/0907079}
}

% 2.11
@article{10.1145/282957.282969,
  author     = {Goldman, Ronald N.},
  title      = {Illicit Expressions in Vector Algebra},
  year       = {1985},
  issue_date = {July 1985},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/282957.282969},
  abstract   = {In vector geometry there are 2 distinct types of entities: points P, Q, R … and vectors u, v, w … Generally, the operattions of vector algebra —addition, subtraction, scalar multiplication, dot product, and cross product—are intrinsically defined only for vectors, not for points. Yet illicit expressions containing terms like P + Q, cP, P X Q, etc. often appear in graphics textbooks, papers, and programs. In this paper we justify the use of such illicit expressions, and we we give criteria for recognizing when such an expression is truly legitimate. In particular we show that an algebraic expression E (P1, …, Pn) is legitimate if and only if E(v1 +  w, …vn + w) = E(v1, …, vn) + kw, k + 0, 1. We also derive many useful examples of such an expression.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  pages      = {223-243},
  numpages   = {21},
  keywords   = {vector geometry, vector algebra}
}

@inproceedings{10.1007/978-3-642-61542-9_19,
  author    = {DeRose, Tony D.},
  editor    = {Stra{\ss}er, Wolfgang and Seidel, Hans-Peter},
  title     = {A Coordinate-Free Approach to Geometric Programming},
  booktitle = {Theory and Practice of Geometric Modeling},
  year      = {1989},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {291-305},
  abstract  = {In this paper it is shown that traditional (coordinate-based) approaches to geometric programming lead to programs that are geometrically ambiguous, and potentially geometrically invalid. To combat these deficiencies, a geometric algebra and an associated coordinate-free abstract data type are outlined. The algebra and the abstract data type are founded on two basic principles: affine/Euclidean geometry and coordinate-freedom.},
  isbn      = {978-3-642-61542-9}
}

@techreport{Mann97acoordinate,
  author      = {Stephen Mann and Nathan Litke and Tony Derose},
  title       = {A Coordinate Free Geometry {ADT}},
  institution = {CS-97-15, Computer Science Department, University of Waterloo},
  year        = {1997}
}

@book{10.5555/2821579,
  author    = {Schneider, Philip and Eberly, David H.},
  title     = {Geometric Tools for Computer Graphics},
  year      = {2002},
  isbn      = {9780080478029},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  abstract  = {Do you spend too much time creating the building blocks of your graphics applications or finding and correcting errors Geometric Tools for Computer Graphics is an extensive, conveniently organized collection of proven solutions to fundamental problems that you'd rather not solve over and over again, including building primitives, distance calculation, approximation, containment, decomposition, intersection determination, separation, and more. If you have a mathematics degree, this book will save you time and trouble. If you don't, it will help you achieve things you may feel are out of your reach. Inside, each problem is clearly stated and diagrammed, and the fully detailed solutions are presented in easy-to-understand pseudocode. You also get the mathematics and geometry background needed to make optimal use of the solutions, as well as an abundance of reference material contained in a series of appendices. Features Filled with robust, thoroughly tested solutions that will save you time and help you avoid costly errors. Covers problems relevant for both 2D and 3D graphics programming. Presents each problem and solution in stand-alone form allowing you the option of reading only those entries that matter to you. Provides the math and geometry background you need to understand the solutions and put them to work. Clearly diagrams each problem and presents solutions in easy-to-understand pseudocode. Resources associated with the book are available at the companion Web site www.mkp.com/gtcg. * Filled with robust, thoroughly tested solutions that will save you time and help you avoid costly errors. * Covers problems relevant for both 2D and 3D graphics programming. * Presents each problem and solution in stand-alone form allowing you the option of reading only those entries that matter to you. * Provides the math and geometry background you need to understand the solutions and put them to work. * Clearly diagrams each problem and presents solutions in easy-to-understand pseudocode. * Resources associated with the book are available at the companion Web site www.mkp.com/gtcg. Table of Contents Preface 1. Introduction 2. Matrices and Linear Systems 3. Vector Algebra 4. Matrices, Vector Algebra, and Transformations 5. Geometric Primitives in 2D 6. Distance in 2D 7. Intersection in 2D 8. Miscellaneous 2D Problems 9. Geometric Primitives in 3D 10. Distance in 3D 11. Intersection in 3D 12. Miscellaneous 3D Problems 13. Computational Geometry Topics A. Numerical Methods B. Trigonometry C. Basic Formulas For Geometric Primitives Bibliography}
}

@book{10.5555/63448,
  author    = {Rogers, David F. and Adams, J. Alan},
  title     = {Mathematical Elements for Computer Graphics},
  edition   = {2},
  year      = {1990},
  isbn      = {0070535299},
  publisher = {McGraw-Hill, Inc.},
  address   = {New York, USA}
}

@book{10.5555/113163,
  author    = {Stolfi, Jorge},
  title     = {Oriented Projective Geometry},
  year      = {1991},
  isbn      = {0126720258},
  publisher = {Academic Press Professional, Inc.},
  address   = {San Diego, USA}
}

@book{lang2012introduction,
  title     = {Introduction to Linear Algebra},
  author    = {Lang, Serge},
  series    = {Undergraduate Texts in Mathematics},
  year      = {1986},
  edition   = {2},
  doi       = {10.1007/978-1-4612-1070-2},
  publisher = {Springer Science \& Business Media}
}

@book{buck1956advanced,
  title     = {Advanced Calculus},
  author    = {Buck, Robert Creighton},
  year      = {1978},
  address   = {New York, USA},
  publisher = {McGraw-Hill}
}

@book{10.1201/9781315365459,
  author    = {Tomas Akenine-Möller, Eric Haines, Naty Hoffman},
  publisher = {A. K. Peters/CRC Press},
  title     = {Real-Time Rendering},
  year      = {2008},
  edition   = {3},
  pages     = {1045},
  address   = {New York, USA},
  isbn      = {978-1-56881-424-7},
  doi       = {10.1201/9781315365459}
}

@inproceedings{inproceedings,
  author  = {Wallis, Bob},
  year    = {1990},
  month   = {08},
  pages   = {533-538},
  title   = {Forms, Vectors, And Transforms},
  isbn    = {9780080507538},
  journal = {Graphics Gems},
  doi     = {10.1016/B978-0-08-050753-8.50117-0}
}

@incollection{TURKOWSKI1990539,
  title     = {Properties of surface-normal transformations},
  editor    = {Andrew S. Glassner},
  booktitle = {Graphics Gems},
  publisher = {Morgan Kaufmann},
  address   = {San Diego},
  pages     = {539-547},
  year      = {1990},
  isbn      = {978-0-08-050753-8},
  doi       = {10.1016/B978-0-08-050753-8.50118-2},
  author    = {Ken Turkowski}
}

@incollection{SHOEMAKE1994207,
  title     = {III.4. - Polar Matrix Decomposition},
  editor    = {Paul S. Heckbert},
  booktitle = {Graphics Gems},
  publisher = {Academic Press},
  pages     = {207-221},
  year      = {1994},
  isbn      = {978-0-12-336156-1},
  doi       = {10.1016/B978-0-12-336156-1.50029-X},
  author    = {Ken Shoemake}
}

@inbook{10.5555/180895.180914,
  author    = {Shoemake, Ken},
  title     = {{E}uler Angle Conversion},
  year      = {1994},
  isbn      = {0123361559},
  publisher = {Academic Press Professional, Inc.},
  address   = {USA},
  booktitle = {Graphics Gems IV},
  pages     = {222-229},
  numpages  = {8}
}

@inproceedings{Bloom2003ErrorsAO,
  title  = {Errors and Omissions in {M}arc {A}lexa's  "Linear Combination of Transformations"},
  author = {Charles Bloom and Jonathan Blow and Casey Muratori},
  year   = {2003},
  url    = {http://pds16.egloos.com/pds/201003/31/85/Errors_and_Omissions_in_Marc_Alexa_s_Linear_Combination_of_Transformations.pdf}
}

@article{doi:10.1080/2151237X.2011.610255,
  author    = {David Eberly},
  title     = {A Fast and Accurate Algorithm for Computing SLERP},
  journal   = {Journal of Graphics, GPU, and Game Tools},
  volume    = {15},
  number    = {3},
  pages     = {161-176},
  year      = {2011},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2011.610255}
}

@inproceedings{10.1145/258734.258870,
  author    = {Ramamoorthi, Ravi and Barr, Alan H.},
  title     = {Fast Construction of Accurate Quaternion Splines},
  year      = {1997},
  isbn      = {0897918967},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/258734.258870},
  booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {287-292},
  numpages  = {6},
  keywords  = {splines, quaternions, Euler-Lagrange error functional, optimization},
  series    = {SIGGRAPH '97}
}

@article{10.1145/502122.502124,
  author     = {Buss, Samuel R. and Fillmore, Jay P.},
  title      = {Spherical Averages and Applications to Spherical Splines and Interpolation},
  year       = {2001},
  issue_date = {April 2001},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {20},
  number     = {2},
  issn       = {0730-0301},
  doi        = {10.1145/502122.502124},
  abstract   = {This article introduces a method for computing weighted averages on spheres based on least squares minimization that respects spherical distance. We prove existence and uniqueness properties of the weighted averages, and give fast iterative algorithms with linear and quadratic convergence rates. Our methods are appropriate to problems involving averages of spherical data in meteorological, geophysical, and astronomical applications. One simple application is a method for smooth averaging of quaternions, which generalizes Shoemake's spherical linear interpolation.The weighted averages methods allow a novel method of defining B\'{e}zier and spline curves on spheres, which provides direct generalization of B\'{e}zier and B-spline curves to spherical spline curves. We present a fast algorithm for spline interpolation on spheres. Our spherical splines allow the use of arbitrary knot positions; potential applications of spherical splines include smooth quaternion curves for applications in graphics, animation, robotics, and motion planning.},
  journal    = {ACM Trans. Graph.},
  month      = {4},
  pages      = {95-126},
  numpages   = {32},
  keywords   = {spherical interpolation, quaternion interpolation, B-spline, quaternions, barycentric coordinates, spherical mean, spline curve, spherical average, least squares minimization, spline interpolation, B\'{e}zier curve}
}


@article{doi:10.1080/10867651.1999.10487509,
  author    = {Tomas Akenine-Möller and John F. Hughes },
  title     = {Efficiently Building a Matrix to Rotate One Vector to Another},
  journal   = {Journal of Graphics Tools},
  volume    = {4},
  number    = {4},
  pages     = {1-4},
  year      = {1999},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.1999.10487509}
}

@book{moore1966interval,
  title     = {Interval analysis},
  author    = {Moore, Ramon E},
  volume    = {4},
  year      = {1966},
  address   = {Englewood Cliffs, New Jersey},
  publisher = {Prentice-Hall}
}

% 2.12
@inbook{10.5555/90767.90922,
  author    = {Arvo, James},
  title     = {Transforming Axis-Aligned Bounding Boxes},
  year      = {1990},
  isbn      = {0122861695},
  publisher = {Academic Press Professional, Inc.},
  address   = {USA},
  booktitle = {Graphics Gems},
  pages     = {548-550},
  numpages  = {3}
}

% 3.2
@book{gray2017modern,
  author    = {Alfred Gray and Elsa Abbena and Simon Salamon},
  title     = {Modern Differential Geometry of Curves and Surfaces with Mathematica},
  publisher = {Chapman and Hall/CRC},
  year      = {2006},
  address   = {New York, USA},
  doi       = {10.1201/9781315276038},
  edition   = {3},
  pagetotal = {1016}
}

% 3.8
@inproceedings{10.1145/192161.192233,
  author    = {Hoppe, Hugues and DeRose, Tony and Duchamp, Tom and Halstead, Mark and Jin, Hubert and McDonald, John and Schweitzer, Jean and Stuetzle, Werner},
  title     = {Piecewise Smooth Surface Reconstruction},
  year      = {1994},
  isbn      = {0897916670},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/192161.192233},
  abstract  = {We present a general method for automatic reconstruction of accurate, concise, piecewise smooth surface models from scattered range data. The method can be used in a variety of applications such as reverse engineering—the automatic generation of CAD models from physical objects. Novel aspects of the method are its ability to model surfaces of arbitrary topological type and to recover sharp features such as creases and corners. The method has proven to be effective, as demonstrated by a number of examples using both simulated and real data.A key ingredient in the method, and a principal contribution of this paper, is the introduction of a new class of piecewise smooth surface representations based on subdivision. These surfaces have a number of properties that make  them ideal for use in surface reconstruction: they are simple to implement, they can model sharp features concisely, and they can be fit to scattered range data using an unconstrained optimization procedure.},
  booktitle = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {295-302},
  numpages  = {8},
  keywords  = {range data analysis, geometric modeling, subdivision surfaces, shape recovery, surface fitting},
  series    = {SIGGRAPH '94}
}

% 3.9
@article{10.1109/IEEESTD.1985.82928,
  journal = {ANSI/IEEE Std 754-1985},
  title   = {{IEEE} Standard for Binary Floating-Point Arithmetic},
  year    = {1985},
  pages   = {1-20},
  doi     = {10.1109/IEEESTD.1985.82928}
}

@article{10.1109/IEEESTD.2008.4610935,
  journal = {IEEE Std 754-2008},
  title   = {{IEEE} Standard for Floating-Point Arithmetic},
  year    = {2008},
  pages   = {1-70},
  doi     = {10.1109/IEEESTD.2008.4610935}
}

@book{doi:10.1137/1.9780898718027,
  author    = {Higham, Nicholas J.},
  title     = {Accuracy and Stability of Numerical Algorithms},
  publisher = {Society for Industrial and Applied Mathematics},
  year      = {2002},
  doi       = {10.1137/1.9780898718027},
  address   = {Philadelphia, USA},
  edition   = {2}
}

@book{10.5555/1096474,
  author    = {Wilkinson, James Hardy},
  title     = {Rounding Errors in Algebraic Processes},
  year      = {1994},
  isbn      = {0486679993},
  publisher = {Dover Publications, Inc.},
  address   = {New York, USA}
}

@article{536271,
  author  = {Woo, Andrew and Pearce, Andrew and Ouellette, Marc},
  journal = {IEEE Computer Graphics and Applications},
  title   = {It's really not a rendering bug, you see},
  year    = {1996},
  volume  = {16},
  number  = {5},
  pages   = {21-25},
  doi     = {10.1109/38.536271}
}

@phdthesis{Wächter_2008,
  title        = {Quasi-{M}onte {C}arlo light transport simulation by efficient ray tracing},
  doi          = {10.18725/OPARU-974},
  abstractnote = {Photorealistic image synthesis can be described by a path integral. This integral is numerically approximated by summing up contributions of transport paths that connect light sources and sensors like e.g. a camera or the eye. The paths are trajectories of Markov processes, whose edges are straight lines along rays of light and whose vertices are light scattering events. The goal of this thesis was to accelerate the simulation of light transport, to find new algorithms and data structures to efficiently trace rays, and to better approximate the distribution of light by simultaneously simulating an ensemble of paths instead of single trajectories, using quasi-Monte-Carlo methods. We first present new data structures and heuristics that feature a smaller memory footprint at improved numerical precision. In addition it is possible to ray trace even massive scenes in a strictly limited, a priori fixed, memory block using rapid construction techniques that allow to rebuild the complete data structure at interactive frame rates. All efforts were combined in a unified framework that further allows one to build the acceleration hierarchy using an on demand policy and optionally balance the construction time versus the ray intersection time. Besides finding faster ray tracing algorithms, the total number of rays to be shot was reduced by mathematical means. By simplifying complicated mathematical schemes in a non-obvious way, the time complexity of the quasi-Monte-Carlo simulation process was reduced. When concentrating on the fact that the underlying Fredholm integral equation is in fact of low dimensional structure if not solved by the Neumann series, the resulting algorithms are simpler and in addition much more efficient. The combination of these new techniques allows photorealistic image synthesis in almost realtime. The results are demonstrated by several academic and industrial applications.},
  school       = {Universität Ulm},
  author       = {Wächter, Carsten},
  year         = {2008}
}

% 3.10
@techreport{Heckbert84themathematics,
  author      = {Paul S. Heckbert},
  title       = {The Mathematics of Quadric Surface Rendering and {SOID}},
  titleaddon  = {3-D Technical Memo 4},
  institution = {New York Institute of Technology Computer Graphics Laboratory Three Dimensional Animation Systems Group},
  year        = {1984},
  month       = {7}
}

@inproceedings{10.1145/800059.801136,
  author    = {Hanrahan, Pat},
  title     = {Ray Tracing Algebraic Surfaces},
  year      = {1983},
  isbn      = {0897911091},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800059.801136},
  abstract  = {Many interesting surfaces can be written as polynomial functions of the spatial coordinates,
               often of low degree. We present a method based on a ray casting algorithm, extended
               to work in more than three dimensions, to produce pictures of these surfaces. The
               method uses a symbolic algebra system to automatically derive the equation of intersection
               between the ray and the surface and then solves this equation using an exact polynomial
               root finding algorithm.Included are illustrations of the cusp catastrophe surface,
               and two unusually shaped quartic surfaces, Kummer's quadruple and Steiner's surface.},
  booktitle = {Proceedings of the 10th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {83-90},
  numpages  = {8},
  keywords  = {Polynomial roots, Ray tracing, Algebraic surfaces, Curved surface display, Symbolic algebra},
  location  = {Detroit, Michigan, USA},
  series    = {SIGGRAPH '83}
}

@article{10.1145/964967.801136,
  author     = {Hanrahan, Pat},
  title      = {Ray Tracing Algebraic Surfaces},
  year       = {1983},
  issue_date = {July 1983},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {17},
  number     = {3},
  issn       = {0097-8930},
  doi        = {10.1145/964967.801136},
  abstract   = {Many interesting surfaces can be written as polynomial functions of the spatial coordinates,
                often of low degree. We present a method based on a ray casting algorithm, extended
                to work in more than three dimensions, to produce pictures of these surfaces. The
                method uses a symbolic algebra system to automatically derive the equation of intersection
                between the ray and the surface and then solves this equation using an exact polynomial
                root finding algorithm.Included are illustrations of the cusp catastrophe surface,
                and two unusually shaped quartic surfaces, Kummer's quadruple and Steiner's surface.},
  journal    = {SIGGRAPH Comput. Graph.},
  month      = {7},
  pages      = {83-90},
  numpages   = {8},
  keywords   = {Symbolic algebra, Polynomial roots, Curved surface display, Ray tracing, Algebraic surfaces}
}

@inproceedings{10.5555/93267.93276,
  author    = {Mitchell, Don P.},
  title     = {Robust Ray Intersection with Interval Arithmetic},
  year      = {1990},
  publisher = {Canadian Information Processing Society},
  address   = {CAN},
  booktitle = {Proceedings on Graphics Interface '90},
  pages     = {68-74},
  numpages  = {7},
  location  = {Halifax, Nova Scotia}
}

@article{10.1111/j.1467-8659.2008.01189.x,
  author   = {Knoll, A. and Hijazi, Y. and Kensler, A. and Schott, M. and Hansen, C. and Hagen, H.},
  title    = {Fast Ray Tracing of Arbitrary Implicit Surfaces with Interval and Affine Arithmetic},
  journal  = {Computer Graphics Forum},
  volume   = {28},
  number   = {1},
  pages    = {26-40},
  keywords = {ray tracing, reduced affine arithmetic, shader metaprogramming, I.3.1, I.3.5, I.3.7 Computer Graphics: Graphics processors; curve, surface, solid and object representations; ray tracing},
  doi      = {10.1111/j.1467-8659.2008.01189.x},
  abstract = {Abstract Existing techniques for rendering arbitrary-form implicit surfaces are limited, either in performance, correctness or flexibility. Ray tracing algorithms employing interval arithmetic (IA) or affine arithmetic (AA) for root-funding are robust and general in the class of surfaces they support, but traditionally slow. Nonetheless, implemented efficiently using a stack-driven iterative algorithm and SIMD vector instructions, these methods can achieve interactive performance for common algebraic surfaces on the CPU. A similar algorithm can also be implemented stacklessly, allowing for efficient ray tracing on the GPU. This paper presents these algorithms, as well as an inclusion-preserving reduced affine arithmetic (RAA) for faster ray-surface intersection. Shader metaprogramming allows for immediate and automatic generation of symbolic expressions and their interval or affine extensions. Moreover, we are able to render even complex forms robustly, in real-time at high resolution.},
  year     = {2009}
}

@inproceedings{10.1145/800059.801137,
  author    = {Kajiya, James T.},
  title     = {New Techniques for Ray Tracing Procedurally Defined Objects},
  year      = {1983},
  isbn      = {0897911091},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800059.801137},
  abstract  = {We present new algorithms for efficient ray tracing of three procedurally defined
               objects: fractal surfaces, prisms, and surfaces of revolution. The fractal surface
               algorithm performs recursive subdivision adaptively. Subsurfaces which cannot intersect
               a given ray are culled from further consideration. The prism algorithm transforms
               the three dimensional ray-surface intersection problem into a two dimensional ray-curve
               intersection problem, which is solved by the method of strip trees. The surface of
               revolution algorithm transforms the three dimensional ray-surface intersection problem
               into a two dimensional curve-curve intersection problem, which again is solved by
               strip trees.},
  booktitle = {Proceedings of the 10th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {91-102},
  numpages  = {12},
  keywords  = {Stochastic models, Procedural modelling, Fractal surfaces, Computer graphics, Ray tracing, Surfaces of revolution, Strip trees, Raster graphics},
  location  = {Detroit, Michigan, USA},
  series    = {SIGGRAPH '83}
}

@article{10.1145/358523.358553,
  author     = {Fournier, Alain and Fussell, Don and Carpenter, Loren},
  title      = {Computer Rendering of Stochastic Models},
  year       = {1982},
  issue_date = {June 1982},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {25},
  number     = {6},
  issn       = {0001-0782},
  doi        = {10.1145/358523.358553},
  abstract   = {A recurrent problem in generating realistic pictures by computers is to represent
                natural irregular objects and phenomena without undue time or space overhead. We develop
                a new and powerful solution to this computer graphics problem by modeling objects
                as sample paths of stochastic processes. Of particular interest are those stochastic
                processes which previously have been found to be useful models of the natural phenomena
                to be represented. One such model applicable to the representation of terrains, known
                as “fractional Brownian motion,” has been developed by Mandelbrot.The value of a new
                approach to object modeling in computer graphics depends largely on the efficiency
                of the techniques used to implement the model. We introduce a new algorithm that computes
                a realistic, visually satisfactory approximation to fractional Brownian motion in
                faster time than with exact calculations. A major advantage of this technique is that
                it allows us to compute the surface to arbitrary levels of details without increasing
                the database. Thus objects with complex appearances can be displayed from a very small
                database. The character of the surface can be controlled by merely modifying a few
                parameters. A similar change allows complex motion to be created inexpensively.},
  journal    = {Commun. ACM},
  month      = {6},
  pages      = {371-384},
  numpages   = {14},
  keywords   = {stochastic models, terrain models, fractals}
}

@inproceedings{10.1145/74333.74363,
  author    = {Hart, John C. and Sandin, Daniel J. and Kauffman, Louis. H.},
  title     = {Ray Tracing Deterministic 3-{D} Fractals},
  year      = {1989},
  isbn      = {0897913124},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/74333.74363},
  abstract  = {As shown in 1982, Julia sets of quadratic functions as well as many other deterministic
               fractals exist in spaces of higher dimensionality than the complex plane. Originally
               a boundary-tracking algorithm was used to view these structures but required a large
               amount of storage space to operate. By ray tracing these objects, the storage facilities
               of a graphics workstation frame buffer are sufficient. A short discussion of a specific
               set of 3-D deterministic fractals precedes a full description of a ray-tracing algorithm
               applied to these objects. A comparison with the boundary-tracking method and applications
               to other 3-D deterministic fractals are also included.},
  booktitle = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {289-296},
  numpages  = {8},
  series    = {SIGGRAPH '89}
}

@inproceedings{10.1145/800064.801287,
  author    = {Kajiya, James T.},
  title     = {Ray Tracing Parametric Patches},
  year      = {1982},
  isbn      = {0897910761},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800064.801287},
  abstract  = {This paper describes an algorithm that uses ray tracing techniques to display bivariate
               polynomial surface patches. A new intersection algorithm is developed which uses ideas
               from algebraic geometry to obtain a numerical procedure for finding the intersection
               of a ray and a patch without subdivision. The algorithm may use complex coordinates
               for the (u, v)-parameters of the patches. The choice of these coordinates makes the
               computations more uniform, so that there are fewer special cases to be considered.
               In particular, the appearance and disappearance of silhouette edges can be handled
               quite naturally. The uniformity of these techniques may be suitable for implementation
               on either a general purpose pipelined machine, or on special purpose hardware.},
  booktitle = {Proceedings of the 9th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {245-254},
  numpages  = {10},
  keywords  = {Parametric patches, Ray tracing, Raster graphics, Computer graphics},
  location  = {Boston, Massachusetts, USA},
  series    = {SIGGRAPH '82}
}

@article{722295,
  author  = {Stürzlinger, Wolfgang},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Ray-tracing triangular trimmed free-form surfaces},
  year    = {1998},
  volume  = {4},
  number  = {3},
  pages   = {202-214},
  doi     = {10.1109/2945.722295}
}

@article{doi:10.1080/10867651.2000.10487519,
  author    = {William Martin and Elaine Cohen and Russell Fish and Peter Shirley},
  title     = {Practical Ray Tracing of Trimmed {NURBS} Surfaces},
  journal   = {Journal of Graphics Tools},
  volume    = {5},
  number    = {1},
  pages     = {27-52},
  year      = {2000},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.2000.10487519}
}

@article{https://doi.org/10.1111/1467-8659.00535,
  author   = {Roth, S. H. Martin and Diezi, Patrick and Gross, Markus H.},
  title    = {Ray Tracing Triangular Bézier Patches},
  journal  = {Computer Graphics Forum},
  volume   = {20},
  number   = {3},
  pages    = {422-432},
  keywords = {Isosurface, Reconstruction filter, Octree, Quantization.},
  doi      = {10.1111/1467-8659.00535},
  abstract = {We present a new approach to finding ray-patch intersections with triangular Bernstein-Bézier patches of arbitrary degree. This paper extends and complements on the short presentation17 . Unlike a previous approach which was based on a combination of hierarchical subdivision and a Newton-like iteration scheme21 , this work adapts the concept of Bézier clipping to the triangular domain. The problem of reporting wrong intersections, inherent to the original Bézier clipping algorithm14 , is inves-tigated and opposed to the triangular case. It turns out that reporting wrong hits is very improbable, even close to impossible, in the triangular set-up. A combination of Bézier clipping and a simple hierarchy of nested bounding volumes offers a reliable and accurate solution to the problem of ray tracing triangular Bézier patches.},
  year     = {2001}
}

@article{doi:10.1080/2151237X.2006.10129218,
  author    = {Carsten   Benthin  and  Ingo   Wald  and  Philipp   Slusallek},
  title     = {Techniques for Interactive Ray Tracing of Bézier Surfaces},
  journal   = {Journal of Graphics Tools},
  volume    = {11},
  number    = {2},
  pages     = {1-16},
  year      = {2006},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2006.10129218}
}

@article{doi:10.1080/10867651.2004.10504896,
  author    = {Shaun D. Ramsey and Kristin Potter and Charles Hansen},
  title     = {Ray Bilinear Patch Intersections},
  journal   = {Journal of Graphics Tools},
  volume    = {9},
  number    = {3},
  pages     = {41-47},
  year      = {2004},
  publisher = {Taylor & Francis},
  doi       = {10.1080/10867651.2004.10504896}
}

@article{10.1111/j.1467-8659.2011.01993.x,
  author   = {Ogaki, Shinji and Tokuyoshi, Yusuke},
  title    = {Direct Ray Tracing of Phong Tessellation},
  journal  = {Computer Graphics Forum},
  volume   = {30},
  number   = {4},
  pages    = {1337-1344},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing},
  doi      = {10.1111/j.1467-8659.2011.01993.x},
  abstract = {Abstract There are two major ways of calculating ray and parametric surface intersections in rendering. The first is through the use of tessellated triangles, and the second is to use parametric surfaces together with numerical methods such as Newton's method. Both methods are computationally expensive and complicated to implement. In this paper, we focus on Phong Tessellation and introduce a simple direct ray tracing method for Phong Tessellation. Our method enables rendering smooth surfaces in a computationally inexpensive yet robust way.},
  year     = {2011}
}

@article{Woop2013Watertight,
  author  = {Sven Woop and Carsten Benthin and Ingo Wald},
  title   = {Watertight Ray/Triangle Intersection},
  year    = {2013},
  month   = {6},
  day     = {28},
  journal = {Journal of Computer Graphics Techniques (JCGT)},
  volume  = {2},
  number  = {1},
  pages   = {65-82},
  url     = {http://jcgt.org/published/0002/01/05/},
  issn    = {2331-7418}
}

@article{doi:10.1080/10867651.1997.10487468,
  author    = { Tomas   Möller  and  Ben   Trumbore },
  title     = {Fast, Minimum Storage Ray-Triangle Intersection},
  journal   = {Journal of Graphics Tools},
  volume    = {2},
  number    = {1},
  pages     = {21-28},
  year      = {1997},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.1997.10487468}
}

@article{doi:10.1080/2151237X.2005.10129208,
  author    = {Lagae, Ares and Dutré, Philip},
  title     = {An Efficient Ray-Quadrilateral Intersection Test},
  journal   = {Journal of Graphics Tools},
  volume    = {10},
  number    = {4},
  pages     = {23-32},
  year      = {2005},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2005.10129208}
}

@inproceedings{shevtsov2007ray,
  title     = {Ray-triangle intersection algorithm for modern {CPU} architectures},
  author    = {Shevtsov, Maxim and Soupikov, Alexei and Kapustin, Alexander and Novorod, Nizhniy},
  booktitle = {Proceedings of GraphiCon},
  volume    = {2007},
  pages     = {33-39},
  year      = {2007}
}

@inproceedings{4061543,
  author    = {Kensler, Andrew and Shirley, Peter},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {Optimizing Ray-Triangle Intersection via Automated Search},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {33-38},
  doi       = {10.1109/RT.2006.280212}
}

@inproceedings{phong1975improved,
  title     = {Improved rendition of polygonal models of curved surfaces},
  author    = {Phong, Bui Tuong and Crow, Franklin C},
  booktitle = {Proc. of the 2nd USA-Japan Computer Conf},
  year      = {1975}
}

@inproceedings{10.1145/1186822.1073278,
  author    = {Yoon, Sung-Eui and Lindstrom, Peter and Pascucci, Valerio and Manocha, Dinesh},
  title     = {Cache-Oblivious Mesh Layouts},
  year      = {2005},
  isbn      = {9781450378253},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1186822.1073278},
  abstract  = {We present a novel method for computing cache-oblivious layouts of large meshes that
               improve the performance of interactive visualization and geometric processing algorithms.
               Given that the mesh is accessed in a reasonably coherent manner, we assume no particular
               data access patterns or cache parameters of the memory hierarchy involved in the computation.
               Furthermore, our formulation extends directly to computing layouts of multi-resolution
               and bounding volume hierarchies of large meshes.We develop a simple and practical
               cache-oblivious metric for estimating cache misses. Computing a coherent mesh layout
               is reduced to a combinatorial optimization problem. We designed and implemented an
               out-of-core multilevel minimization algorithm and tested its performance on unstructured
               meshes composed of tens to hundreds of millions of triangles. Our layouts can significantly
               reduce the number of cache misses. We have observed 2--20 times speedups in view-dependent
               rendering, collision detection, and isocontour extraction without any modification
               of the algorithms or runtime applications.},
  booktitle = {ACM SIGGRAPH 2005 Papers},
  pages     = {886-893},
  numpages  = {8},
  location  = {Los Angeles, California},
  series    = {SIGGRAPH '05}
}

@article{4015484,
  author  = {Yoon, Sung-Eui and Lindstrom, Peter},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Mesh Layouts for Block-Based Caches},
  year    = {2006},
  volume  = {12},
  number  = {5},
  pages   = {1213-1220},
  doi     = {10.1109/TVCG.2006.162}
}

@inproceedings{Nakamaru_raytracing,
  title        = {Ray tracing for curves primitive},
  author       = {Nakamaru, Koji and Ohno, Yoshio},
  editor       = {Skala, Václav},
  booksubtitle = {10th International Conference on Computer Graphics, Visualization and Computer Vision 2002},
  year         = {2002},
  month        = {02},
  address      = {UNIV W BOHEMIA, PLZEN, CZECH REPUBLIC},
  pages        = {311-316},
  publisher    = {UNIV WEST BOHEMIA},
  location     = {PILSEN UNIVERZITNI 8, PLZEN 306 14, CZECH REPUBLIC},
  abstract     = {The Curves primitive defined in RenderMan is useful for modelling and rendering ribbonlike objects. This paper gives a simple framework for ray-curve intersection tests in ray tracing, and provides concrete details for one form of the primitive. The form is especially important for fine objects such as hair and fur.}
}

@article{10.1145/6116.6118,
  author     = {Bronsvoort, Willem F. and Klok, Fopke},
  title      = {Ray Tracing Generalized Cylinders},
  year       = {1985},
  issue_date = {Oct. 1985},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/6116.6118},
  abstract   = {An algorithm is presented for ray tracing generalized cylinders, that is, objects
                defined by sweeping a two-dimensional contour along a three-dimensional trajectory.
                The contour can be any 'well-behaved' curve in the sense that it is continuous, and
                that the points where the tangent is horizontal or vertical can be determined, the
                trajectory can be any spline curve. First a definition is given of generalized cylinders
                in terms of the Frenet frame of the trajectory. Then the main problem in ray tracing
                these objects, the computation of the intersection points with a ray, is reduced to
                the problem of intersecting two two-dimensional curves. This problem is solved by
                a subdivision algorithm. The three-dimensional normal at the intersection point closest
                to the eye point, necessary to perform shading, is obtained by transforming the two-dimensional
                normal at the corresponding intersection point of the two two-dimensional curves.
                In this way it is possible to obtain highly realistic images for a very broad class
                of objects.},
  journal    = {ACM Trans. Graph.},
  month      = {10},
  pages      = {291-303},
  numpages   = {13}
}

@article{DeVoogt2000197,
  author        = {De Voogt, Erik and Van Der Helm, Aadjan and Bronsvoort, Willem F.},
  title         = {Ray tracing deformed generalized cylinders},
  journal       = {Visual Computer},
  year          = {2000},
  volume        = {16},
  number        = {3},
  pages         = {197-207},
  doi           = {10.1007/s003710050208},
  document_type = {Article},
  source        = {Scopus}
}

@book{10.5555/501891,
  author    = {Farin, Gerald},
  title     = {Curves and Surfaces for {CAGD}: A Practical Guide},
  year      = {2001},
  isbn      = {1558607374},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA},
  edition   = {5th},
  abstract  = {This fifth edition has been fully updated to cover the many advances made in CAGD
               and curve and surface theory since 1997, when the fourth edition appeared. The theory
               material has been streamlined using the blossoming approach; the applications material
               includes least squares techniques in addition to the traditional interpolation methods.
               In all other respects, it is, thankfully, the same. This means you get the informal,
               friendly style and unique approach that has made Curves and Surfaces for CAGD: A Practical
               Guide a true classic.}
}

@techreport{ramshaw1987blossoming,
  author      = {Ramshaw, Lyle},
  title       = {Blossoming: A connect-the-dots approach to splines},
  institution = {Digital Equipment Corporation Palo Alto},
  year        = {1987},
  month       = {6},
  pagetotal   = {172}
}

@inproceedings{10.1145/1179849.1179904,
  author    = {van Swaaij, Maurice},
  title     = {Ray-Tracing Fur for {\it {I}ce {A}ge}: The Melt Down},
  year      = {2006},
  isbn      = {1595933646},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1179849.1179904},
  booktitle = {ACM SIGGRAPH 2006 Sketches},
  pages     = {44-es},
  location  = {Boston, Massachusetts},
  series    = {SIGGRAPH '06}
}

@article{6684531,
  author  = {Qin, Hao and Chai, Menglei and Hou, Qiming and Ren, Zhong and Zhou, Kun},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Cone Tracing for Furry Object Rendering},
  year    = {2014},
  volume  = {20},
  number  = {8},
  pages   = {1178-1188},
  doi     = {10.1109/TVCG.2013.270}
}

@article{DOO1978356,
  title    = {Behaviour of recursive division surfaces near extraordinary points},
  journal  = {Computer-Aided Design},
  volume   = {10},
  number   = {6},
  pages    = {356-360},
  year     = {1978},
  issn     = {0010-4485},
  doi      = {10.1016/0010-4485(78)90111-2},
  author   = {D. Doo and M. Sabin},
  abstract = {The behaviour of the limits surface defined by a recursive division construction can be analysed in terms of the eigenvalues of a set of matrices. This analysis predicts effects actually observed, and leads to suggestions for the further improvement of the method.}
}

@article{CATMULL1978350,
  title    = {Recursively generated {B}-spline surfaces on arbitrary topological meshes},
  journal  = {Computer-Aided Design},
  volume   = {10},
  number   = {6},
  pages    = {350-355},
  year     = {1978},
  issn     = {0010-4485},
  doi      = {10.1016/0010-4485(78)90110-0},
  author   = {E. Catmull and J. Clark},
  abstract = {This paper describes a method for recursively generating surfaces that approximate points lying-on a mesh of arbitrary topology. The method is presented as a generalization of a recursive bicubic B-spline patch subdivision algorithm. For rectangular control-point meshes, the method generates a standard B-spline surface. For non-rectangular meshes, it generates surfaces that are shown to reduce to a standard B-spline surface except at a small number of points, called extraordinary points. Therefore, everywhere except at these points the surface is continuous in tangent and curvature. At the extraordinary points, the pictures of the surface indicate that the surface is at least continuous in tangent, but no proof of continuity is given. A similar algorithm for biquadratic B-splines is also presented.}
}

@mastersthesis{loop1987smooth,
  author = {Loop, Charles},
  title  = {Smooth subdivision surfaces based on triangles},
  school = {University of Utah, Department of Mathematics},
  year   = {1987}
}

@article{zorin2000subdivision,
  title   = {Subdivision for modeling and animation},
  author  = {Zorin, Denis and Schr{\"o}der, P and DeRose, A and Kobbelt, L and Levin, A and Sweldens, W},
  journal = {SIGGRAPH2000 course notes},
  year    = {2000}
}

@book{WARREN20021,
  author    = {Joe Warren and Henrik Weimer},
  title     = {Subdivision Methods for Geometric Design},
  subtitle  = {A Constructive Approach},
  publisher = {Morgan Kaufmann},
  year      = {2002},
  address   = {San Francisco},
  series    = {The Morgan Kaufmann Series in Computer Graphics},
  isbn      = {978-1-55860-446-9},
  doi       = {10.1016/B978-1-55860-446-9.X5000-5}
}

@article{10.1111/1467-8659.t01-2-00703,
  author   = {Müller, Kerstin and Techmann, Torsten and Fellner, Dieter},
  title    = {Adaptive Ray Tracing of Subdivision Surfaces},
  journal  = {Computer Graphics Forum},
  volume   = {22},
  number   = {3},
  pages    = {553-562},
  doi      = {10.1111/1467-8659.t01-2-00703},
  abstract = {Abstract Subdivision Surfaces as well as (interactive) ray tracing have become an important issue in computer graphics.But ray tracing of subdivision surfaces has received only little attention. We present a new approach for raytracing of subdivision surfaces. The algorithm uses a projection of the ray onto the surface and works mainly intwo dimensions along this projection. While proceeding from patch to patch, we examine the bounding volume oftheir borders: the lower the distance between ray and subdivision surface, the more refinement steps are adaptivelyapplied to the surface but only along the projection of the ray. The adaptive refinement of a patch is controlled bycurvature, size, its membership to the silhouette, and its potential contribution to the light transport. The algorithmis simple and mainly consists of elementary geometric computations. Hence it is fast and easy to implementwithout the need for elaborate preprocessing. The algorithm is robust in the sense that it deals with all features ofsubdivision surfaces like creases and corners. Categories and Subject Descripters (according to ACM CCS): I.3.7 [Computer Graphics]: Raytracing},
  year     = {2003}
}

@techreport{SCI:Ben2007a,
  author      = {Carsten Benthin and Solomon Boulos and Dylan Lacewell and Ingo Wald and Carsten Benthin and Solomon Boulos and Dylan Lacewell and Ingo Wald},
  title       = {Packet-based Ray Tracing of {C}atmull-{C}lark Subdivision Surfaces},
  number      = {UUSCI-2007-011},
  year        = {2007},
  institution = {University of Utah},
  type        = {{SCI} Institute Technical Report},
  keywords    = {interactive rt distributed interactive ray tracing dirt, rtcenter},
  url         = {http://www.sci.utah.edu/publications/SCITechReports/UUSCI-2007-011.pdf}
}

@inproceedings{10.1145/280814.280945,
  author    = {Stam, Jos},
  title     = {Exact Evaluation of {C}atmull-{C}lark Subdivision Surfaces at Arbitrary Parameter Values},
  year      = {1998},
  isbn      = {0897919998},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/280814.280945},
  booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {395-404},
  numpages  = {10},
  keywords  = {parametrizations, linear algebra, eigenanalysis, surface evaluation, Catmull-Clark surfaces, subdivison surfaces},
  series    = {SIGGRAPH '98}
}

@inproceedings{10.1145/504502.504505,
  author    = {Bolz, Jeffrey and Schr{\"o}der, Peter},
  title     = {Rapid Evaluation of {C}atmull-{C}lark Subdivision Surfaces},
  year      = {2002},
  isbn      = {1581134681},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/504502.504505},
  abstract  = {Using subdivision as a basic primitive for the construction of arbitrary topology,
               smooth, free-form surfaces is attractive for content destined for display on devices
               with greatly varying rendering performance. Subdivision naturally supports level of
               detail rendering and powerful compression algorithms. While the underlying algorithms
               are conceptually simple it is difficult to implement player engines which achieve
               optimal performance on modern CPUs such as the Intel Pentium family.In this paper
               we describe a novel table driven evaluation strategy for subdivision surfaces using
               as an example the scheme of Catmull and Clark. Cache conscious design and exploitation
               of SIMD instructions allows us to achieve nearly 100\% FPU utilization in the inner
               loop and achieve a composite performance of 1.2 flop/cycle on the Intel PIII and 1.8
               flop/cycle on the Intel P4 including all memory transfers. The algorithm supports
               tradeoffs between cache size and memory bus usage which we examine. A library which
               implements this engine is freely available from the authors.},
  booktitle = {Proceedings of the Seventh International Conference on 3D Web Technology},
  pages     = {11-17},
  numpages  = {7},
  location  = {Tempe, Arizona, USA},
  series    = {Web3D '02}
}

@inproceedings{10.1145/1572769.1572785,
  author    = {Patney, Anjul and Ebeida, Mohamed S. and Owens, John D.},
  title     = {Parallel View-Dependent Tessellation of {C}atmull-{C}lark Subdivision Surfaces},
  year      = {2009},
  isbn      = {9781605586038},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1572769.1572785},
  abstract  = {We present a strategy for performing view-adaptive, crack-free tessellation of Catmull-Clark
               subdivision surfaces entirely on programmable graphics hardware. Our scheme extends
               the concept of breadth-first subdivision, which up to this point has only been applied
               to parametric patches. While mesh representations designed for a CPU often involve
               pointer-based structures and irregular perelement storage, neither of these is well-suited
               to GPU execution. To solve this problem, we use a simple yet effective data structure
               for representing a subdivision mesh, and design a careful algorithm to update the
               mesh in a completely parallel manner. We demonstrate that in spite of the complexities
               of the subdivision procedure, real-time tessellation to pixel-sized primitives can
               be done.Our implementation does not rely on any approximation of the limit surface,
               and avoids both subdivision cracks and T-junctions in the subdivided mesh. Using the
               approach in this paper, we are able to perform real-time subdivision for several static
               as well as animated models. Rendering performance is scalable for increasingly complex
               models.},
  booktitle = {Proceedings of the Conference on High Performance Graphics 2009},
  pages     = {99-108},
  numpages  = {10},
  keywords  = {adaptive surface subdivision, subdivision surfaces, Catmull-Clark, GPGPU},
  location  = {New Orleans, Louisiana},
  series    = {HPG '09}
}

@article{10.1145/103162.103163,
  author     = {Goldberg, David},
  title      = {What Every Computer Scientist Should Know about Floating-Point Arithmetic},
  year       = {1991},
  issue_date = {March 1991},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {23},
  number     = {1},
  issn       = {0360-0300},
  doi        = {10.1145/103162.103163},
  abstract   = {Floating-point arithmetic is considered as esoteric subject by many people. This is
                rather surprising, because floating-point is ubiquitous in computer systems: Almost
                every language has a floating-point datatype; computers from PCs to supercomputers
                have floating-point accelerators; most compilers will be called upon to compile floating-point
                algorithms from time to time; and virtually every operating system must respond to
                floating-point exceptions such as overflow. This paper presents a tutorial on the
                aspects of floating-point that have a direct impact on designers of computer systems.
                It begins with background on floating-point representation and rounding error, continues
                with a discussion of the IEEE floating point standard, and concludes with examples
                of how computer system builders can better support floating point.},
  journal    = {ACM Comput. Surv.},
  month      = {3},
  pages      = {5-48},
  numpages   = {44},
  keywords   = {underflow, exception, guard digit, rounding error, NaN, gradual underflow, floating-point standard, denormalized number, relative error, ulp, floating-point, overflow, rounding mode}
}

@article{10.1145/1644001.1644003,
  author     = {Daumas, Marc and Melquiond, Guillaume},
  title      = {Certification of Bounds on Expressions Involving Rounded Operators},
  year       = {2010},
  issue_date = {January 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {37},
  number     = {1},
  issn       = {0098-3500},
  doi        = {10.1145/1644001.1644003},
  abstract   = {Gappa is a tool designed to formally verify the correctness of numerical software
                and hardware. It uses interval arithmetic and forward error analysis to bound mathematical
                expressions that involve rounded as well as exact operators. It then generates a theorem
                and its proof for each verified enclosure. This proof can be automatically checked
                with a proof assistant, such as Coq or HOL Light. It relies on a large companion library
                of facts that we have developed. This Coq library provides theorems dealing with addition,
                multiplication, division, and square root, for both fixed- and floating-point arithmetics.
                Gappa uses multiple-precision dyadic fractions for the endpoints of intervals and
                performs forward error analysis on rounded operators when necessary. When asked, Gappa
                reports the best bounds it is able to reach for a given expression in a given context.
                This feature can be used to identify where the set of facts and automatic techniques
                implemented in Gappa becomes insufficient. Gappa handles seamlessly additional properties
                expressed as interval properties or rewriting rules in order to establish more intricate
                bounds. Recent work showed that Gappa is suited to discharge proof obligations generated
                for small pieces of software. They may be produced by third-party tools and the first
                applications of Gappa use proof obligations written by designers or obtained from
                traces of execution.},
  journal    = {ACM Trans. Math. Softw.},
  month      = {1},
  articleno  = {2},
  numpages   = {20},
  keywords   = {HOL Light, proof obligation, proof system, dyadic fraction, floating point, Forward error analysis, interval arithmetic, PVS, Coq}
}

@inbook{10.5555/94788.94790,
  author    = {Haines, Eric},
  title     = {Essential Ray Tracing Algorithms},
  year      = {1989},
  isbn      = {0122861604},
  publisher = {Academic Press Ltd.},
  address   = {GBR},
  booktitle = {An Introduction to Ray Tracing},
  pages     = {33-77},
  numpages  = {45}
}

@inproceedings{Amanatides1990:27,
  author    = {John Amanatides and Don P. Mitchell},
  title     = {Some Regularization Problems in Ray Tracing},
  booktitle = {Proceedings of Graphics Interface '90},
  series    = {GI '90},
  year      = {1990},
  issn      = {0713-5424},
  location  = {Halifax, Nova Scotia, Canada},
  pages     = {221-228},
  numpages  = {8},
  url       = {http://graphicsinterface.org/wp-content/uploads/gi1990-27.pdf},
  publisher = {Canadian Man-Computer Communications Society},
  address   = {Toronto, Ontario, Canada}
}

@inproceedings{10.1145/74333.74364,
  author    = {Kalra, Devendra and Barr, Alan H.},
  title     = {Guaranteed Ray Intersections with Implicit Surfaces},
  year      = {1989},
  isbn      = {0897913124},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/74333.74364},
  abstract  = {In this paper, we present a robust and mathematically sound ray-intersection algorithm
               for implicit surfaces. The algorithm is guaranteed to numerically find the nearest
               intersection of the surface with a ray, and is guaranteed not to miss fine features
               of the surface. It does not require fine tuning or human choice of interactive parameters.
               Instead, it requires two upper bounds: "L" that limits the net rate of change of the
               implicit surface function f(x,y,z) and "G" that limits the rate of change of the gradient.
               We refer to an implicit surface with these rate limits as an "LG-implicit surface."Existing
               schemes to intersect a ray with an implicit surface have typically been guaranteed
               to work only for a limited set of implicit functions, such as quadric surfaces or
               polynomials, or else have been ad-hoc and have not been guaranteed to work. Our technique
               significantly extends the ability to intersect rays with implicit surfaces in a guaranteed
               fashion.},
  booktitle = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {297-306},
  numpages  = {10},
  series    = {SIGGRAPH '89}
}

@inproceedings{4061542,
  author    = {Dammertz, Holger and Keller, Alexander},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {Improving Ray Tracing Precision by Object Space Intersection Computation},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {25-31},
  doi       = {10.1109/RT.2006.280211}
}

@inproceedings{10.1145/73833.73857,
  author    = {Salesin, David and Stolfi, Jorge and Guibas, Leonidas},
  title     = {Epsilon Geometry: Building Robust Algorithms from Imprecise Computations},
  year      = {1989},
  isbn      = {0897913183},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/73833.73857},
  booktitle = {Proceedings of the Fifth Annual Symposium on Computational Geometry},
  pages     = {208-217},
  numpages  = {10},
  location  = {Saarbruchen, West Germany},
  series    = {SCG '89}
}

@article{Ize2013BVH,
  author  = {Thiago Ize},
  title   = {Robust {BVH} Ray Traversal},
  year    = {2013},
  month   = {7},
  day     = {19},
  journal = {Journal of Computer Graphics Techniques (JCGT)},
  volume  = {2},
  number  = {2},
  pages   = {12-27},
  url     = {http://jcgt.org/published/0002/02/02/},
  issn    = {2331-7418}
}

% 3.11
@incollection{HAINES199424,
  title     = {I.4. - Point in Polygon Strategies},
  editor    = {Paul S. Heckbert},
  booktitle = {Graphics Gems},
  publisher = {Academic Press},
  pages     = {24-46},
  year      = {1994},
  isbn      = {978-0-12-336156-1},
  doi       = {10.1016/B978-0-12-336156-1.50013-6},
  author    = {Eric Haines}
}

@book{10.5555/74803,
  author    = {Hoffmann, Christoph M.},
  title     = {Geometric and Solid Modeling: An Introduction},
  year      = {1989},
  isbn      = {1558600671},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address   = {San Francisco, CA, USA}
}

@article{ROTH1982109,
  title    = {Ray casting for modeling solids},
  journal  = {Computer Graphics and Image Processing},
  volume   = {18},
  number   = {2},
  pages    = {109-144},
  year     = {1982},
  issn     = {0146-664X},
  doi      = {10.1016/0146-664X(82)90169-1},
  author   = {Scott D Roth},
  abstract = {This paper presents ray casting as the methodological basis for a CAD/CAM solid modeling system. Solid objects are modeled by combining primitive solids, such as blocks and cylinders, using the set operators union, intersection, and difference. To visualize and analyze the composite solids modeled, virtual light rays are cast as probes. By virtue of its simplicity, ray casting is reliable and extensible. The most difficult mathematical problem is finding line-surface intersection points. So surfaces such as planes, quadrics, tori, and probably even parametric surface patches may bound the primitive solids. The adequacy and efficiency of ray casting are issues addressed here. A fast picture generation capability for interactive modeling is the biggest challenge. New methods are presented, accompanied by sample pictures and CPU times, to meet the challenge.}
}

@article{10.1111/1467-8659.t01-2-00647,
  author   = {Stam, Jos and Loop, Charles},
  title    = {Quad/Triangle Subdivision},
  journal  = {Computer Graphics Forum},
  volume   = {22},
  number   = {1},
  pages    = {79-85},
  doi      = {10.1111/1467-8659.t01-2-00647},
  abstract = {Abstract In this paper we introduce a new subdivision operator that unifies triangular and quadrilateral subdivision schemes. Designers often want the added flexibility of having both quads and triangles in their models. It is also well known that triangle meshes generate poor limit surfaces when using a quad scheme, while quad-only meshes behave poorly with triangular schemes. Our new scheme is a generalization of the well known Catmull-Clark and Loop subdivision algorithms. We show that our surfaces are C 1 everywhere and provide a proof that it is impossible to construct such a C 2 scheme at the quad/triangle boundary. However, we provide rules that produce surfaces with bounded curvature at the regular quad/triangle boundary and provide optimal masks that minimize the curvature divergence elsewhere. We demonstrate the visual quality of our surfaces with several examples. ACM CSS: I.3.5 Computer Graphics—Curve, surface, solid, and object representations},
  year     = {2003}
}

@inproceedings{10.1145/1661412.1618496,
  author    = {Fisher, Matthew and Fatahalian, Kayvon and Boulos, Solomon and Akeley, Kurt and Mark, William R. and Hanrahan, Pat},
  title     = {DiagSplit: Parallel, Crack-Free, Adaptive Tessellation for Micropolygon Rendering},
  year      = {2009},
  isbn      = {9781605588582},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1661412.1618496},
  abstract  = {We present DiagSplit, a parallel algorithm for adaptively tessellating displaced parametric
               surfaces into high-quality, crack-free micropolygon meshes. DiagSplit modifies the
               split-dice tessellation algorithm to allow splits along non-isoparametric directions
               in the surface's parametric domain, and uses a dicing scheme that supports unique
               tessellation factors for each subpatch edge. Edge tessellation factors are computed
               using only information local to subpatch edges. These modifications allow all subpatches
               generated by DiagSplit to be processed independently without introducing T-junctions
               or mesh cracks and without incurring the tessellation overhead of binary dicing. We
               demonstrate that DiagSplit produces output that is better (in terms of image quality
               and number of micropolygons produced) than existing parallel tessellation schemes,
               and as good as highly adaptive split-dice implementations that are less amenable to
               parallelization.},
  booktitle = {ACM SIGGRAPH Asia 2009 Papers},
  articleno = {150},
  numpages  = {10},
  keywords  = {micropolygons, real-time rendering, tessellation},
  location  = {Yokohama, Japan},
  series    = {SIGGRAPH Asia '09}
}

@inproceedings{10.1145/344779.344936,
  author    = {Pfister, Hanspeter and Zwicker, Matthias and van Baar, Jeroen and Gross, Markus},
  title     = {Surfels: Surface Elements as Rendering Primitives},
  year      = {2000},
  isbn      = {1581132085},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/344779.344936},
  abstract  = {Surface elements (surfels) are a powerful paradigm to efficiently render complex geometric
               objects at interactive frame rates. Unlike classical surface discretizations, i.e.,
               triangles or quadrilateral meshes, surfels are point primitives without explicit connectivity.
               Surfel attributes comprise depth, texture color, normal, and others. As a pre-process,
               an octree-based surfel representation of a geometric object is computed. During sampling,
               surfel positions and normals are optionally perturbed, and different levels of texture
               colors are prefiltered and stored per surfel. During rendering, a hierarchical forward
               warping algorithm projects surfels to a z-buffer. A novel method called visibility
               splatting determines visible surfels and holes in the z-buffer. Visible surfels are
               shaded using texture filtering, Phong illumination, and environment mapping using
               per-surfel normals. Several methods of image reconstruction, including supersampling,
               offer flexible speed-quality tradeoffs. Due to the simplicity of the operations, the
               surfel rendering pipeline is amenable for hardware implementation. Surfel objects
               offer complex shape, low rendering cost and high image quality, which makes them specifically
               suited for low-cost, real-time graphics, such as games.},
  booktitle = {Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {335-342},
  numpages  = {8},
  keywords  = {texture mapping, rendering systems},
  series    = {SIGGRAPH '00}
}

@inproceedings{10.1145/344779.344940,
  author    = {Rusinkiewicz, Szymon and Levoy, Marc},
  title     = {{QS}plat: A Multiresolution Point Rendering System for Large Meshes},
  year      = {2000},
  isbn      = {1581132085},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/344779.344940},
  abstract  = {Advances in 3D scanning technologies have enabled the practical creation of meshes
               with hundreds of millions of polygons. Traditional algorithms for display, simplification,
               and progressive transmission of meshes are impractical for data sets of this size.
               We describe a system for representing and progressively displaying these meshes that
               combines a multiresolution hierarchy based on bounding spheres with a rendering system
               based on points. A single data structure is used for view frustum culling, backface
               culling, level-of-detail selection, and rendering. The representation is compact and
               can be computed quickly, making it suitable for large data sets. Our implementation,
               written for use in a large-scale 3D digitization project, launches quickly, maintains
               a user-settable interactive frame rate regardless of object complexity or camera position,
               yields reasonable image quality during motion, and refines progressively when idle
               to a high final image quality. We have demonstrated the system on scanned models containing
               hundreds of millions of samples.},
  booktitle = {Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {343-352},
  numpages  = {10},
  keywords  = {level of detail algorithms, spatial data structures, compression algorithms, rendering systems},
  series    = {SIGGRAPH '00}
}

@inproceedings{10.1007/978-3-7091-6303-0_29,
  author    = {Schaufler, Gernot and Jensen, Henrik Wann},
  editor    = {P{\'e}roche, Bernard and Rushmeier, Holly},
  title     = {Ray Tracing Point Sampled Geometry},
  booktitle = {Rendering Techniques 2000},
  year      = {2000},
  publisher = {Springer Vienna},
  address   = {Vienna},
  pages     = {319-328},
  abstract  = {We present a novel technique for ray tracing geometry represented by points. Our approach makes it possible to render high quality ray traced images with global illumination using unstructured point-sampled data thus avoiding the time-consuming process of reconstructing the underlying surface or any topological information. Compared with previous point rendering methods, our approach allows for more complex illumination models while still maintaining the simplicity of the point primitive.},
  isbn      = {978-3-7091-6303-0}
}

@article{10.1145/357306.357310,
  author     = {Blinn, James F.},
  title      = {A Generalization of Algebraic Surface Drawing},
  year       = {1982},
  issue_date = {July 1982},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/357306.357310},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  pages      = {235-256},
  numpages   = {22}
}

@article{Wyvill1989,
  author  = {Wyvill, Brian and Wyvill, Geoff},
  title   = {Field functions for implicit surfaces},
  journal = {The Visual Computer},
  volume  = {5},
  number  = {1},
  year    = {1989},
  month   = {01},
  pages   = {75-82},
  issn    = {1432-2315},
  doi     = {10.1007/BF01901483}
}

@article{Hart1996,
  author  = {Hart, John C.},
  title   = {Sphere tracing: a geometric method for the antialiased ray tracing of implicit surfaces},
  journal = {The Visual Computer},
  volume  = {12},
  number  = {10},
  year    = {1996},
  month   = {12},
  pages   = {527-545},
  issn    = {1432-2315},
  doi     = {10.1007/s003710050084}
}

@inproceedings{10.1145/800031.808571,
  author    = {Smith, Alvy Ray},
  title     = {Plants, Fractals, and Formal Languages},
  year      = {1984},
  isbn      = {0897911385},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800031.808571},
  abstract  = {Although fractal models of natural phenomena have received much attention recently,
               there are other models of complex natural objects which have been around longer in
               Computer Imagery but are not widely known. These are procedural models of plants and
               trees. An interesting class of these models is presented here which handles plant
               growth, sports an efficient data representation, and has a high “database amplification”
               factor. It is based on an extension of the well-known formal languages of symbol strings
               to the lesser-known formal languages of labeled graphs. It is so tempting to describe
               these plant models as “fractal” that the similarities of this class of models with
               fractal models are explored in an attempt at rapprochement. The models are not fractal
               so the common parts of fractal theory and plant theory are abstracted to form a class
               of objects, the graftals. This class may prove to be of great interest to the future
               of Computer Imagery. Determinism is shown to provide adequate complexity, whereas
               randomness is only convenient and often inefficient. Finally, a nonfractal, nongraftal
               family of trees by Bill Reeves is introduced to emphasize some of the paper's nongrammatical
               themes.},
  booktitle = {Proceedings of the 11th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {1-10},
  numpages  = {10},
  keywords  = {Graftal, Tree, Plant, L-system, Database amplification, Parallel graph grammar, Fractal, Particle system, Computer imagery},
  series    = {SIGGRAPH '84}
}

@inproceedings{Prusinkiewicz:1986:10.20380/GI1986.44,
  author    = {Prusinkiewicz, Przemyslaw},
  title     = {Graphical applications of {L}-systems},
  booktitle = {Proceedings of Graphics Interface and Vision Interface '86},
  series    = {GI + VI 1986},
  year      = {1986},
  issn      = {0713-5424},
  location  = {Vancouver, British Columbia, Canada},
  pages     = {247-253},
  numpages  = {7},
  doi       = {10.20380/GI1986.44},
  publisher = {Canadian Information Processing Society},
  address   = {Toronto, Ontario, Canada}
}

@inproceedings{10.1145/192161.192254,
  author    = {Prusinkiewicz, Przemyslaw and James, Mark and M\v{e}ch, Radom\'{\i}r},
  title     = {Synthetic Topiary},
  year      = {1994},
  isbn      = {0897916670},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/192161.192254},
  abstract  = {The paper extends Lindenmayer systems in a manner suitable for simulating the interaction
               between a developing plant and its environment. The formalism is illustrated by modeling
               the response of trees to pruning, which yields synthetic images of sculptured plants
               found in topiary gardens.},
  booktitle = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {351-358},
  numpages  = {8},
  keywords  = {modeling of plants, topiary, L-system, image synthesis},
  series    = {SIGGRAPH '94}
}

@inproceedings{10.1145/280814.280898,
  author    = {Deussen, Oliver and Hanrahan, Pat and Lintermann, Bernd and M\v{e}ch, Radom\'{\i}r and Pharr, Matt and Prusinkiewicz, Przemyslaw},
  title     = {Realistic Modeling and Rendering of Plant Ecosystems},
  year      = {1998},
  isbn      = {0897919998},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/280814.280898},
  booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {275-286},
  numpages  = {12},
  keywords  = {self-thinning, ecosystem simulation, plant model, vector quantization, modeling of natural phenomena, realistic image synthesis, approximate instancing},
  series    = {SIGGRAPH '98}
}

@inproceedings{10.1145/383259.383291,
  author    = {Prusinkiewicz, Przemyslaw and M\"{u}ndermann, Lars and Karwowski, Radoslaw and Lane, Brendan},
  title     = {The Use of Positional Information in the Modeling of Plants},
  year      = {2001},
  isbn      = {158113374X},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/383259.383291},
  abstract  = {We integrate into plant models three elements of plant representation identified as
               important by artists: posture (manifested in curved stems and elongated leaves), gradual
               variation of features, and the progression of the drawing process from overall silhouette
               to local details. The resulting algorithms increase the visual realism of plant models
               by offering an intuitive control over plant form and supporting an interactive modeling
               process. The algorithms are united by the concept of expressing local attributes of
               plant architecture as functions of their location along the stems.},
  booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {289-300},
  numpages  = {12},
  keywords  = {phyllotaxis, differential turtle geometry, realistic image synthesis, plant, generalized cylinder, interactive procedural modeling, Chomsky grammar, L-system, positional information},
  series    = {SIGGRAPH '01}
}

@inproceedings{hurley2002fast,
  author    = {Hurley, Jim and Kapustin, Alexander and Reshetov, Alexander and Soupikov, Alexei},
  booktitle = {Proceedings of International Conference Graphicon 2002},
  title     = {Fast Ray Tracing for Modern General Purpose {CPU}},
  year      = {2002},
  address   = {Nizhny Novgorod, Russia}
}

% 4.5
@article{4056861,
  author  = {Fujimoto, Akira and Tanaka, Takayuki and Iwata, Kansei},
  journal = {IEEE Computer Graphics and Applications},
  title   = {{ARTS}: Accelerated Ray-Tracing System},
  year    = {1986},
  volume  = {6},
  number  = {4},
  pages   = {16-26},
  doi     = {10.1109/MCG.1986.276715}
}

@inproceedings{10.2312:egtp.19871000,
  booktitle = {EG 1987-Technical Papers},
  editor    = {},
  title     = {A Fast Voxel Traversal Algorithm for Ray Tracing},
  author    = {Amanatides, John and Woo, Andrew},
  year      = {1987},
  publisher = {Eurographics Association},
  issn      = {1017-4656},
  doi       = {10.2312/egtp.19871000}
}

@article{Cleary1988,
  author   = {Cleary, John G. and Wyvill, Geoff},
  journal  = {The Visual Computer},
  number   = {2},
  title    = {Analysis of an algorithm for fast ray tracing using uniform space subdivision},
  volume   = {4},
  year     = {1988},
  date     = {1988-03-01},
  pages    = {65-83},
  abstract = {Ray tracing is becoming popular as the best method of rendering high quality images from three dimensional models. Unfortunately, the computational cost is high. Recently, a number of authors have reported on ways to speed up this process by means of space subdivision which is used to minimize the number of intersection calculations. We describe such an algorithm together with an analysis of the factors which affect its performance. The critical operation of skipping an empty space subdivision can be done very quickly, using only integer addition and comparison. A theoretical analysis of the algorithm is developed. It shows how the space and time requirements vary with the number of objects in the scene.},
  issn     = {1432-2315},
  doi      = {10.1007/BF01905559}
}

@inproceedings{10.1145/37401.37417,
  author    = {Snyder, John M. and Barr, Alan H.},
  title     = {Ray Tracing Complex Models Containing Surface Tessellations},
  year      = {1987},
  isbn      = {0897912276},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/37401.37417},
  abstract  = {An approach to ray tracing complex models containing mathematically defined surfaces
               is presented. Parametric and implicit surfaces, and boolean combinations of these,
               are first tessellated into triangles. The resulting triangles from many such surfaces
               are organized in a hierachy of lists and 3D grids, allowing efficient calculation
               of ray/model intersections.The technique has been used to ray trace models containing
               billions of traiangles and surfaces never before ray traced. The organizing scheme
               developed is also independently useful for efficiently ray tracing any complex model,
               whether or not it contains surface tessellations.},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {119-128},
  numpages  = {10},
  series    = {SIGGRAPH '87}
}

@inproceedings{Jevans1989:23,
  author    = {David Jevans and Brian Wyvill},
  title     = {Adaptive Voxel Subdivision for Ray Tracing},
  booktitle = {Proceedings of Graphics Interface '89},
  series    = {GI '89},
  year      = {1989},
  issn      = {0713-S424},
  location  = {London, Ontario, Canada},
  pages     = {164-172},
  numpages  = {9},
  url       = {http://graphicsinterface.org/wp-content/uploads/gi1989-23.pdf},
  publisher = {Canadian Man-Computer Communications Society},
  address   = {Toronto, Ontario, Canada}
}

@article{cazals1995filtering,
  author   = {Cazals, Frédéric and Drettakis, George and Puech, Claude},
  title    = {Filtering, Clustering and Hierarchy Construction: a New Solution for Ray-Tracing Complex Scenes},
  journal  = {Computer Graphics Forum},
  volume   = {14},
  number   = {3},
  pages    = {371-382},
  doi      = {10.1111/j.1467-8659.1995.cgf143\_0371.x},
  abstract = {Abstract Data structures that handle very complex scenes (hundreds of thousands of objects) have in the past either been laboriously built by hand, or have required the determination of unintuitive parameter values by the user. It is often the case that an incorrect choice of these parameters can result in greedy memory requirements or severely degraded performance. As a remedy to this problem we propose a new data structure which is fully automatic since it does not require the user to determine any input parameters. The structure is built by first filtering the input objects by size, subsequently applying a clustering step to objects of the same size and finally building a hierarchy of uniform grids . We then show that this data structure can be efficiently constructed. The implementation of the shows that the new structure is stable since it's memory requirements grow linearly with the size of the scene, and that it presents a satisfactory compromise between memory usage and computational efficiency. A detailed comparison with previous data structures is also presented in the results.},
  year     = {1995}
}

@article{576857,
  author  = {Klimaszewski, Krzysztof S. and Sederberg, Thomas W.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Faster ray tracing using adaptive grids},
  year    = {1997},
  volume  = {17},
  number  = {1},
  pages   = {42-51},
  doi     = {10.1109/38.576857}
}

@inproceedings{4061545,
  author    = {Ize, Thiago and Wald, Ingo and Robertson, Chelsea and Parker, Steven G.},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {An Evaluation of Parallel Grid Construction for Ray Tracing Dynamic Scenes},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {47-55},
  doi       = {10.1109/RT.2006.280214}
}

@inproceedings{4342587,
  author    = {Ize, Thiago and Shirley, Peter and Parker, Steven},
  booktitle = {2007 IEEE Symposium on Interactive Ray Tracing},
  title     = {Grid Creation Strategies for Efficient Ray Tracing},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {27-32},
  doi       = {10.1109/RT.2007.4342587}
}

@article{lagae2008compact,
  author   = {Lagae, Ares and Dutré, Philip},
  title    = {Compact, Fast and Robust Grids for Ray Tracing},
  journal  = {Computer Graphics Forum},
  volume   = {27},
  number   = {4},
  pages    = {1235-1244},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism, ray tracing, acceleration structure, grid, row displacement compression, perfect hashing},
  doi      = {10.1111/j.1467-8659.2008.01262.x},
  abstract = {Abstract The focus of research in acceleration structures for ray tracing recently shifted from render time to time to image, the sum of build time and render time, and also the memory footprint of acceleration structures now receives more attention. In this paper we revisit the grid acceleration structure in this setting. We present two efficient methods for representing and building a grid. The compact grid method consists of a static data structure for representing a grid with minimal memory requirements, more specifically exactly one index per grid cell and exactly one index per object reference, and an algorithm for building that data structure in linear time. The hashed grid method reduces memory requirements even further, by using perfect hashing based on row displacement compression. We show that these methods are more efficient in both time and space than traditional methods based on linked lists and dynamic arrays. We also present a more robust grid traversal algorithm. We show that, for applications where time to image or memory usage is important, such as interactive ray tracing and rendering large models, the grid acceleration structure is an attractive alternative.},
  year     = {2008}
}

@inproceedings{4634613,
  author    = {Hunt, Warren and Mark, William R.},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Ray-specialized acceleration structures for ray tracing},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {3-10},
  doi       = {10.1109/RT.2008.4634613}
}

@article{10.1145/360349.360354,
  author     = {Clark, James H.},
  title      = {Hierarchical Geometric Models for Visible Surface Algorithms},
  year       = {1976},
  issue_date = {Oct. 1976},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {19},
  number     = {10},
  issn       = {0001-0782},
  doi        = {10.1145/360349.360354},
  abstract   = {The geometric structure inherent in the definition of the shapes of three-dimensional
                objects and environments is used not just to define their relative motion and placement,
                but also to assist in solving many other problems of systems for producing pictures
                by computer. By using an extension of traditional structure information, or a geometric
                hierarchy, five significant improvements to current techniques are possible. First,
                the range of complexity of an environment is greatly increased while the visible complexity
                of any given scene is kept within a fixed upper limit. Second, a meaningful way is
                provided to vary the amount of detail presented in a scene. Third, “clipping” becomes
                a very fast logarithmic search for the resolvable parts of the environment within
                the field of view. Fourth, frame to frame coherence and clipping define a graphical
                “working set,” or fraction of the total structure that should be present in primary
                store for immediate access by the visible surface algorithm. Finally, the geometric
                structure suggests a recursive descent, visible surface algorithm in which the computation
                time potentially grows linearly with the visible complexity of the scene.},
  journal    = {Commun. ACM},
  month      = {10},
  pages      = {547-554},
  numpages   = {8},
  keywords   = {hidden surface algorithms, hierarchical data structures, visible surface algorithms, geometric models}
}

@inproceedings{10.1145/800250.807479,
  author    = {Rubin, Steven M. and Whitted, Turner},
  title     = {A 3-Dimensional Representation for Fast Rendering of Complex Scenes},
  year      = {1980},
  isbn      = {0897910214},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800250.807479},
  abstract  = {Hierarchical representations of 3-dimensional objects are both time and space efficient.
               They typically consist of trees whose branches represent bounding volumes and whose
               terminal nodes represent primitive object elements (usually polygons). This paper
               describes a method whereby the object space is represented entirely by a hierarchical
               data structure consisting of bounding volumes, with no other form of representation.
               This homogencity allows the visible surface rendering to be performed simply and efficiently.The
               bounding volumes selected for this algorithm are parallelepipeds oriented to minimize
               their size. With this representation, any surface can be rendered since in the limit
               the bounding volumes make up a point representation of the object. The advantage is
               that the visibility calculations consist only of a search through the data structure
               to determine the correspondence between terminal level bounding volumes and the current
               pixel. For ray tracing algorithms, this means that a simplified operation will produce
               the point of intersection of each ray with the bounding volumes.Memory requirements
               are minimized by expanding or fetching the lower levels of the hierarchy only when
               required. Because the viewing process has a single operation and primitive type, the
               software or hardware chosen to implement the search can be highly optimized for very
               fast execution.},
  booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {110-116},
  numpages  = {7},
  keywords  = {Object descriptions, Hierarchical data structures, Visible surface algorithms, Computer graphics},
  location  = {Seattle, Washington, USA},
  series    = {SIGGRAPH '80}
}

@inproceedings{10.1145/15922.15916,
  author    = {Kay, Timothy L. and Kajiya, James T.},
  title     = {Ray Tracing Complex Scenes},
  year      = {1986},
  isbn      = {0897911962},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/15922.15916},
  abstract  = {A new algorithm for speeding up ray-object intersection calculations is presented.
               Objects are bounded by a new type of extent, which can be made to fit convex hulls
               arbitrarily tightly. The objects are placed into a hierarchy. A new hierarchy traversal
               algorithm is presented which is efficient in the sense that objects along the ray
               are queried in an efficient order.Results are presented which demonstrate that our
               technique is several times faster than other published algorithms. Furthermore, we
               demonstrate that it is currently possible to ray trace scenes containing hundreds
               of thousands of objects.},
  booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {269-278},
  numpages  = {10},
  series    = {SIGGRAPH '86}
}

@article{4057175,
  author  = {Goldsmith, Jeffrey and Salmon, John},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Automatic Creation of Object Hierarchies for Ray Tracing},
  year    = {1987},
  volume  = {7},
  number  = {5},
  pages   = {14-20},
  doi     = {10.1109/MCG.1987.276983}
}

@inproceedings{4342588,
  author    = {Wald, Ingo},
  booktitle = {2007 IEEE Symposium on Interactive Ray Tracing},
  title     = {On fast Construction of SAH-based Bounding Volume Hierarchies},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {33-40},
  doi       = {10.1109/RT.2007.4342588}
}

@inproceedings{4342598,
  author    = {Günther, Johannes and Popov, Stefan and Seidel, Hans-Peter and Slusallek, Philipp},
  booktitle = {2007 IEEE Symposium on Interactive Ray Tracing},
  title     = {Realtime Ray Tracing on {GPU} with {BVH}-based Packet Traversal},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {113-118},
  doi       = {10.1109/RT.2007.4342598}
}

@inproceedings{10.1145/1198555.1198748,
  author    = {Williams, Amy and Barrus, Steve and Morley, R. Keith and Shirley, Peter},
  title     = {An Efficient and Robust Ray-Box Intersection Algorithm},
  year      = {2005},
  isbn      = {9781450378338},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1198555.1198748},
  abstract  = {The computational bottleneck in a ray tracer using bounding volume hierarchies is
               often the ray intersection routine with axis-aligned bounding boxes. We describe a
               version of this routine that uses IEEE numerical properties to ensure that those tests
               are both robust and efficient. Sample source code is available online.},
  booktitle = {ACM SIGGRAPH 2005 Courses},
  pages     = {9-es},
  location  = {Los Angeles, California},
  series    = {SIGGRAPH '05}
}

@article{10.1080/2151237X.2007.10129248,
  author    = {Martin Eisemann and Marcus Magnor and Thorsten Grosch and Stefan Müller},
  title     = {Fast Ray/Axis-Aligned Bounding Box Overlap Tests using Ray Slopes},
  journal   = {Journal of Graphics Tools},
  volume    = {12},
  number    = {4},
  pages     = {35-46},
  year      = {2007},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2007.10129248}
}

@article{bouloshaines2006,
  author  = {Boulos, Solomon and Haines, Eric},
  journal = {Ray Tracing News},
  number  = {1},
  title   = {Ray-Box Sorting},
  url     = {http://www.realtimerendering.com/resources/RTNews/html/rtnv19n1.html#art4},
  volume  = {19},
  month   = {9},
  year    = {2006}
}

@inproceedings{10.1145/1071866.1071869,
  author    = {Foley, Tim and Sugerman, Jeremy},
  title     = {{KD}-Tree Acceleration Structures for a {GPU} Raytracer},
  year      = {2005},
  isbn      = {1595930868},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1071866.1071869},
  abstract  = {Modern graphics hardware architectures excel at compute-intensive tasks such as ray-triangle
               intersection, making them attractive target platforms for raytracing. To date, most
               GPU-based raytracers have relied upon uniform grid acceleration structures. In contrast,
               the kd-tree has gained widespread use in CPU-based raytracers and is regarded as the
               best general-purpose acceleration structure. We demonstrate two kd-tree traversal
               algorithms suitable for GPU implementation and integrate them into a streaming raytracer.
               We show that for scenes with many objects at different scales, our kd-tree algorithms
               are up to 8 times faster than a uniform grid. In addition, we identify load balancing
               and input data recirculation as two fundamental sources of inefficiency when raytracing
               on current graphics hardware.},
  booktitle = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware},
  pages     = {15-22},
  numpages  = {8},
  location  = {Los Angeles, California},
  series    = {HWWS '05}
}

@inproceedings{10.5555/1921479.1921496,
  author    = {Laine, Samuli},
  title     = {Restart Trail for Stackless {BVH} Traversal},
  year      = {2010},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {A ray cast algorithm utilizing a hierarchical acceleration structure needs to perform
               a tree traversal in the hierarchy. In its basic form, executing the traversal requires
               a stack that holds the nodes that are still to be processed. In some cases, such a
               stack can be prohibitively expensive to maintain or access, due to storage or memory
               bandwidth limitations. The stack can, however, be eliminated or replaced with a fixed-size
               buffer using so-called stackless or short stack algorithms. These require that the
               traversal can be restarted from root so that the already processed part of the tree
               is not entered again. For kd-tree ray casts, this is accomplished easily by ray shortening,
               but the approach does not extend to other kinds of hierarchies such as BVHs.In this
               paper, we introduce restart trail, a simple algorithmic method that makes restarts
               possible regardless of the type of hierarchy by storing one bit of data per level.
               This enables stackless and short stack traversal for BVH ray casts, where using a
               full stack or constraining the traversal order have so far been the only options.},
  booktitle = {Proceedings of the Conference on High Performance Graphics},
  pages     = {107-111},
  numpages  = {5},
  location  = {Saarbrucken, Germany},
  series    = {HPG '10}
}

@inproceedings{10.2312:EGWR:EGSR07:073-084,
  booktitle = {Rendering Techniques},
  editor    = {Jan Kautz and Sumanta Pattanaik},
  title     = {Ray Tracing Dynamic Scenes using Selective Restructuring},
  author    = {Yoon, Sung-Eui and Curtis, Sean and Manocha, Dinesh},
  year      = {2007},
  publisher = {The Eurographics Association},
  issn      = {1727-3463},
  isbn      = {978-3-905673-52-4},
  doi       = {10.2312/EGWR/EGSR07/073-084}
}

@inproceedings{4634624,
  author    = {Kensler, Andrew},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Tree rotations for improving bounding volume hierarchies},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {73-76},
  doi       = {10.1109/RT.2008.4634624}
}

@inproceedings{10.1145/2159616.2159649,
  author    = {Kopta, Daniel and Ize, Thiago and Spjut, Josef and Brunvand, Erik and Davis, Al and Kensler, Andrew},
  title     = {Fast, Effective {BVH} Updates for Animated Scenes},
  year      = {2012},
  isbn      = {9781450311946},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2159616.2159649},
  abstract  = {Bounding volume hierarchies (BVHs) are a popular acceleration structure choice for
               animated scenes rendered with ray tracing. This is due to the relative simplicity
               of refitting bounding volumes around moving geometry. However, the quality of such
               a refitted tree can degrade rapidly if objects in the scene deform or rearrange significantly
               as the animation progresses, resulting in dramatic increases in rendering times and
               a commensurate reduction in the frame rate. The BVH could be rebuilt on every frame,
               but this could take significant time. We present a method to efficiently extend refitting
               for animated scenes with tree rotations, a technique previously proposed for off-line
               improvement of BVH quality for static scenes. Tree rotations are local restructuring
               operations which can mitigate the effects that moving primitives have on BVH quality
               by rearranging nodes in the tree during each refit rather than triggering a full rebuild.
               The result is a fast, lightweight, incremental update algorithm that requires negligible
               memory, has minor update times, parallelizes easily, avoids significant degradation
               in tree quality or the need for rebuilding, and maintains fast rendering times. We
               show that our method approaches or exceeds the frame rates of other techniques and
               is consistently among the best options regardless of the animated scene.},
  booktitle = {Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  pages     = {197-204},
  numpages  = {8},
  keywords  = {acceleration structures, tree rotations, ray tracing, parallel update, dynamic scenes, bounding volume hierarchies},
  location  = {Costa Mesa, California},
  series    = {I3D '12}
}

@article{BittnerFast2013,
  author   = {Bittner, Ji$\check{\text{r}}$í and Hapala, Michal and Havran, Vlastimil},
  title    = {Fast Insertion-Based Optimization of Bounding Volume Hierarchies},
  journal  = {Computer Graphics Forum},
  volume   = {32},
  number   = {1},
  pages    = {85-100},
  keywords = {BVH, surface area heuristics, ray tracing, I.3.7Computer Graphics: Three-Dimensional Graphics and Realism-Ray Tracing},
  doi      = {10.1111/cgf.12000},
  abstract = {Abstract We present an algorithm for fast optimization of bounding volume hierarchies (BVH) for efficient ray tracing. We perform selective updates of the hierarchy driven by the cost model derived from the surface area heuristic. In each step, the algorithm updates a fraction of the hierarchy nodes to minimize the overall hierarchy cost. The updates are realized by simple operations on the tree nodes: removal, search and insertion. Our method can quickly reduce the cost of the hierarchy constructed by the traditional techniques, such as the surface area heuristic. We evaluate the properties of the proposed method on fourteen test scenes of different complexity including individual objects and architectural scenes. The results show that our method can improve a BVH initially constructed with the surface area heuristic by up to 27\% and a BVH constructed with the spatial median split by up to 88\%.},
  year     = {2013}
}

@inproceedings{10.1145/2492045.2492055,
  author    = {Karras, Tero and Aila, Timo},
  title     = {Fast Parallel Construction of High-Quality Bounding Volume Hierarchies},
  year      = {2013},
  isbn      = {9781450321358},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2492045.2492055},
  booktitle = {Proceedings of the 5th High-Performance Graphics Conference},
  pages     = {89-99},
  numpages  = {11},
  keywords  = {bounding volume hierarchies, ray tracing},
  location  = {Anaheim, California},
  series    = {HPG '13}
}

@article{BITTNER2015135,
  title    = {Incremental {BVH} construction for ray tracing},
  journal  = {Computers \& Graphics},
  volume   = {47},
  pages    = {135-144},
  year     = {2015},
  issn     = {0097-8493},
  doi      = {10.1016/j.cag.2014.12.001},
  author   = {Ji$\check{\text{r}}$í Bittner and Michal Hapala and Vlastimil Havran},
  keywords = {Bounding volume hierarchies, Ray tracing},
  abstract = {We propose a new method for incremental construction of Bounding Volume Hierarchies (BVHs). Despite the wide belief that the incremental construction of BVH is inefficient we show that our method incrementally constructs a BVH with quality comparable to the best SAH builders. We illustrate the versatility of the proposed method using a flexible parallelization scheme that opens new possibilities for combining different BVH construction heuristics. We demonstrate the usage of the method in a proof-of-concept application for real-time preview of data streamed over the network. We believe that our method will renew the interest in incremental BVH construction and it will find its applications in ray tracing based remote visualizations and fast previews or in interactive scene editing applications handling very large data sets.}
}

@inproceedings{4634626,
  author    = {Walter, Bruce and Bala, Kavita and Kulkarni, Milind and Pingali, Keshav},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Fast agglomerative clustering for rendering},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {81-86},
  doi       = {10.1109/RT.2008.4634626}
}

@inproceedings{10.1145/2492045.2492054,
  author    = {Gu, Yan and He, Yong and Fatahalian, Kayvon and Blelloch, Guy},
  title     = {Efficient {BVH} Construction via Approximate Agglomerative Clustering},
  year      = {2013},
  isbn      = {9781450321358},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2492045.2492054},
  abstract  = {We introduce Approximate Agglomerative Clustering (AAC), an efficient, easily parallelizable
               algorithm for generating high-quality bounding volume hierarchies using agglomerative
               clustering. The main idea of AAC is to compute an approximation to the true greedy
               agglomerative clustering solution by restricting the set of candidates inspected when
               identifying neighboring geometry in the scene. The result is a simple algorithm that
               often produces higher quality hierarchies (in terms of subsequent ray tracing cost)
               than a full sweep SAH build yet executes in less time than the widely used top-down,
               approximate SAH build algorithm based on binning.},
  booktitle = {Proceedings of the 5th High-Performance Graphics Conference},
  pages     = {81-88},
  numpages  = {8},
  keywords  = {ray tracing, agglomerative clustering, bounding-volume hierarchy},
  location  = {Anaheim, California},
  series    = {HPG '13}
}

@inproceedings{4342593,
  author    = {Ernst, Manfred and Greiner, Gunther},
  booktitle = {2007 IEEE Symposium on Interactive Ray Tracing},
  title     = {Early Split Clipping for Bounding Volume Hierarchies},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {73-78},
  doi       = {10.1109/RT.2007.4342593}
}

@inproceedings{4634636,
  author    = {Dammertz, Holger and Keller, Alexander},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {The edge volume heuristic - robust triangle subdivision for improved {BVH} performance},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {155-158},
  doi       = {10.1109/RT.2008.4634636}
}

@inproceedings{10.1145/1572769.1572771,
  author    = {Stich, Martin and Friedrich, Heiko and Dietrich, Andreas},
  title     = {Spatial Splits in Bounding Volume Hierarchies},
  year      = {2009},
  isbn      = {9781605586038},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1572769.1572771},
  abstract  = {Bounding volume hierarchies (BVH) have become a widely used alternative to kD-trees
               as the acceleration structure of choice in modern ray tracing systems. However, BVHs
               adapt poorly to non-uniformly tessellated scenes, which leads to increased ray shooting
               costs. This paper presents a novel and practical BVH construction algorithm, which
               addresses the issue by utilizing spatial splitting similar to kD-trees. In contrast
               to previous preprocessing approaches, our method uses the surface area heuristic to
               control primitive splitting during tree construction. We show that our algorithm produces
               significantly more efficient hierarchies than other techniques. In addition, user
               parameters that directly influence splitting are eliminated, making the algorithm
               easily controllable.},
  booktitle = {Proceedings of the Conference on High Performance Graphics 2009},
  pages     = {7-13},
  numpages  = {7},
  keywords  = {ray tracing, bounding volume hierarchy},
  location  = {New Orleans, Louisiana},
  series    = {HPG '09}
}

@inproceedings{10.1145/1572769.1572772,
  author    = {Popov, Stefan and Georgiev, Iliyan and Dimov, Rossen and Slusallek, Philipp},
  title     = {Object Partitioning Considered Harmful: Space Subdivision for {BVH}s},
  year      = {2009},
  isbn      = {9781605586038},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1572769.1572772},
  abstract  = {A major factor for the efficiency of ray tracing is the use of good acceleration structures.
               Recently, bounding volume hierarchies (BVHs) have become the preferred acceleration
               structures, due to their competitive performance and greater flexibility compared
               to KD trees. In this paper, we present a study on algorithms for the construction
               of optimal BVHs.Due to the exponential nature of the problem, constructing optimal
               BVHs for ray tracing remains an open topic. By exploiting the linearity of the surface
               area heuristic (SAH), we develop an algorithm that can find optimal partitions in
               polynomial time. We further generalize this algorithm and show that every SAH-based
               KD tree or BVH construction algorithm is a special case of the generic algorithm.Based
               on a number of experiments with the generic algorithm, we conclude that the assumption
               of non-terminating rays in the surface area cost model becomes a major obstacle for
               using the full potential of BVHs. We also observe that enforcing space partitioning
               helps to improve BVH performance. Finally, we develop a simple space partitioning
               algorithm for building efficient BVHs.},
  booktitle = {Proceedings of the Conference on High Performance Graphics 2009},
  pages     = {15-22},
  numpages  = {8},
  keywords  = {construction, ray tracing, bounding volume hierarchies, surface area heuristic, acceleration structures},
  location  = {New Orleans, Louisiana},
  series    = {HPG '09}
}

@inproceedings{10.5555/2980009.2980014,
  author    = {Woop, Sven and Benthin, Carsten and Wald, Ingo and Johnson, Gregory S. and Tabellion, Eric},
  title     = {Exploiting Local Orientation Similarity for Efficient Ray Traversal of Hair and Fur},
  year      = {2014},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {Hair and fur typically consist of a large number of thin, curved, and densely packed
               strands which are difficult to ray trace efficiently. A tight fitting spatial data
               structure, such as a bounding volume hierarchy (BVH), is needed to quickly determine
               which hair a ray hits. However, the large number of hairs can yield a BVH with a large
               memory footprint (particularly when hairs are pre-tessellated), and curved or diagonal
               hairs cannot be tightly bounded within axis aligned bounding boxes. In this paper,
               we describe an approach to ray tracing hair and fur with improved efficiency, by combining
               parametrically defined hairs with a BVH that uses both axis-aligned and oriented bounding
               boxes. This BVH exploits similarity in the orientation of neighboring hairs to increase
               ray culling efficiency compared to purely axis-aligned BVHs. Our approach achieves
               about 2x the performance of ray tracing pre-tessellated hair models, while requiring
               significantly less memory.},
  booktitle = {Proceedings of High Performance Graphics},
  pages     = {41-49},
  numpages  = {9},
  location  = {Lyon, France},
  series    = {HPG '14}
}

@inproceedings{10.5555/2383894.2383909,
  author    = {Cline, David and Egbert, Parris K. and Talbot, Justin F. and Cardon, David L.},
  title     = {Two Stage Importance Sampling for Direct Lighting},
  year      = {2006},
  isbn      = {3905673355},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {We describe an importance sampling method to generate samples based on the product
               of a BRDF and an environment map or large light source. The method works by creating
               a hierarchical partition of the light source based on the BRDF function for each primary
               (eye) ray in a ray tracer. This partition, along with a summed area table of the light
               source, form an approximation to the product function that is suitable for importance
               sampling. The partition is used to guide a sample warping algorithm to transform a
               uniform distribution of points so that they approximate the product distribution.
               The technique is unbiased, requires little precomputation, and we demonstrate that
               it works well for a variety of BRDF types. Further, we present an adaptive method
               which allocates varying numbers of samples to different image pixels to reduce shadow
               artifacts.},
  booktitle = {Proceedings of the 17th Eurographics Conference on Rendering Techniques},
  pages     = {103-113},
  numpages  = {11},
  location  = {Nicosia, Cyprus},
  series    = {EGSR '06}
}

@inproceedings{10.2312:PE:VMV:VMV10:227-234,
  booktitle = {Vision, Modeling, and Visualization (2010)},
  editor    = {Reinhard Koch and Andreas Kolb and Christof Rezk-Salama},
  title     = {The Minimal Bounding Volume Hierarchy},
  author    = {Bauszat, Pablo and Eisemann, Martin and Magnor, Marcus},
  year      = {2010},
  publisher = {The Eurographics Association},
  isbn      = {978-3-905673-79-1},
  doi       = {10.2312/PE/VMV/VMV10/227-234}
}

@inproceedings{10.5555/1839214.1839242,
  author    = {Segovia, Benjamin and Ernst, Manfred},
  title     = {Memory Efficient Ray Tracing with Hierarchical Mesh Quantization},
  year      = {2010},
  isbn      = {9781568817125},
  publisher = {Canadian Information Processing Society},
  address   = {CAN},
  abstract  = {We present a lossily compressed acceleration structure for ray tracing that encodes
               the bounding volume hierarchy (BVH) and the triangles of a scene together in a single
               unified data structure. Total memory consumption of our representation is smaller
               than previous comparable methods by a factor of 1.7 to 4.8, and it achieves performance
               similar to the fastest uncompressed data structures. We store quantized vertex positions
               as local offsets to the leaf bounding box planes and encode them in bit strings. Triangle
               connectivity is represented as a sequence of strips inside the leaf nodes. The BVH
               is stored in a compact quantized format. We describe techniques for efficient implementation
               using register SIMD instructions (SSE). Hierarchical mesh quantization (HMQ) with
               16 bits of accuracy achieves an average compression rate of 5.7: 1 in comparison to
               a BVH and an indexed face set. The performance impact is only 11 percent for packet
               tracing and 17 percent for single ray path tracing on average.},
  booktitle = {Proceedings of Graphics Interface 2010},
  pages     = {153-160},
  numpages  = {8},
  location  = {Ottawa, Ontario, Canada},
  series    = {GI '10}
}

@article{10.1111/j.1467-8659.2006.00970.x,
  author   = {Yoon, Sung-Eui and Manocha, Dinesh},
  title    = {Cache-Efficient Layouts of Bounding Volume Hierarchies},
  journal  = {Computer Graphics Forum},
  volume   = {25},
  number   = {3},
  pages    = {507-516},
  doi      = {10.1111/j.1467-8659.2006.00970.x},
  abstract = {Abstract We present a novel algorithm to compute cache-efficient layouts of bounding volume hierarchies (BVHs) of polygonal models. Our approach does not make any assumptions about the cache parameters or block sizes of the memory hierarchy. We introduce a new probabilistic model to predict the runtime access patterns of a BVH. Our layout computation algorithm utilizes parent-child and spatial localities between the accessed nodes to reduce both the number of cache misses and the size of the working set. Our algorithm also works well for spatial partitioning hierarchies including kd-trees. We use our algorithm to compute layouts of BVHs and spatial partitioning hierarchies of large models composed of millions of triangles. We compare our cache-efficient layouts with other layouts in the context of collision detection and ray tracing. In our benchmarks, our layouts consistently show better performance over other layouts and improve the performance of these applications by 26\%-300\%without any modification of the underlying algorithms or runtime applications. Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Hierarchy and Geometric Transformations},
  year     = {2006}
}

@book{10.5555/1121584,
  author    = {Ericson, Christer},
  title     = {Real-Time Collision Detection},
  year      = {2004},
  isbn      = {1558607323},
  publisher = {CRC Press, Inc.},
  address   = {USA},
  abstract  = {Written by an expert in the game industry, Christer Ericson's new book is a comprehensive
               guide to the components of efficient real-time collision detection systems. The book
               provides the tools and know-how needed to implement industrial-strength collision
               detection for the highly detailed dynamic environments of applications such as 3D
               games, virtual reality applications, and physical simulators.Of the many topics covered,
               a key focus is on spatial and object partitioning through a wide variety of grids,
               trees, and sorting methods. The author also presents a large collection of intersection
               and distance tests for both simple and complex geometric shapes. Sections on vector
               and matrix algebra provide the background for advanced topics such as Voronoi regions,
               Minkowski sums, and linear and quadratic programming.Of utmost importance to programmers
               but rarely discussed in this much detail in other books are the chapters covering
               numerical and geometric robustness, both essential topics for collision detection
               systems. Also unique are the chapters discussing how graphics hardware can assist
               in collision detection computations and on advanced optimization for modern computer
               architectures. All in all, this comprehensive book will become the industry standard
               for years to come.}
}

@article{10.1111/j.1467-8659.2009.01377.x,
  author   = {Lauterbach, C. and Garland, M. and Sengupta, S. and Luebke, D. and Manocha, D.},
  title    = {Fast {BVH} Construction on {GPU}s},
  journal  = {Computer Graphics Forum},
  volume   = {28},
  number   = {2},
  pages    = {375-384},
  doi      = {10.1111/j.1467-8659.2009.01377.x},
  abstract = {Abstract We present two novel parallel algorithms for rapidly constructing bounding volume hierarchies on manycore GPUs. The first uses a linear ordering derived from spatial Morton codes to build hierarchies extremely quickly and with high parallel scalability. The second is a top-down approach that uses the surface area heuristic (SAH) to build hierarchies optimized for fast ray tracing. Both algorithms are combined into a hybrid algorithm that removes existing bottlenecks in the algorithm for GPU construction performance and scalability leading to significantly decreased build time. The resulting hierarchies are close in to optimized SAH hierarchies, but the construction process is substantially faster, leading to a significant net benefit when both construction and traversal cost are accounted for. Our preliminary results show that current GPU architectures can compete with CPU implementations of hierarchy construction running on multicore systems. In practice, we can construct hierarchies of models with up to several million triangles and use them for fast ray tracing or other applications.},
  year     = {2009}
}

@inproceedings{10.5555/1921479.1921493,
  author    = {Pantaleoni, J. and Luebke, D.},
  title     = {{HLBVH}: Hierarchical {LBVH} Construction for Real-Time Ray Tracing of Dynamic Geometry},
  year      = {2010},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {We present HLBVH and SAH-optimized HLBVH, two high performance BVH construction algorithms
               targeting real-time ray tracing of dynamic geometry. HLBVH provides a novel hierarchical
               formulation of the LBVH algorithm [LGS*09] and SAH-optimized HLBVH uses a new combination
               of HLBVH and the greedy surface area heuristic algorithm. These algorithms minimize
               work and memory bandwidth usage by extracting and exploiting coarse-grained spatial
               coherence already available in the input meshes. As such, they are well-suited for
               sorting dynamic geometry, in which the mesh to be sorted at a given time step can
               be defined as a transformation of a mesh that has been already sorted at the previous
               time step. Our algorithms always perform full resorting, unlike previous approaches
               based on refitting. As a result they remain efficient even during chaotic and discontinuous
               transformations, such as fracture or explosion.},
  booktitle = {Proceedings of the Conference on High Performance Graphics},
  pages     = {87-95},
  numpages  = {9},
  location  = {Saarbrucken, Germany},
  series    = {HPG '10}
}

@inproceedings{10.1145/2018323.2018333,
  author    = {Garanzha, Kirill and Pantaleoni, Jacopo and McAllister, David},
  title     = {Simpler and Faster {HLBVH} with Work Queues},
  year      = {2011},
  isbn      = {9781450308960},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2018323.2018333},
  abstract  = {A recently developed algorithm called Hierachical Linear Bounding Volume Hierarchies
               (HLBVH) has demonstrated the feasibility of reconstructing the spatial index needed
               for ray tracing in real-time, even in the presence of millions of fully dynamic triangles.
               In this work we present a simpler and faster variant of HLBVH, where all the complex
               book-keeping of prefix sums, compaction and partial breadth-first tree traversal needed
               for spatial partitioning has been replaced with an elegant pipeline built on top of
               efficient work queues and binary search. The new algorithm is both faster and more
               memory efficient, removing the need for temporary storage of geometry data for intermediate
               computations. Finally, the same pipeline has been extended to parallelize the construction
               of the top-level SAH optimized tree on the GPU, eliminating round-trips to the CPU,
               accelerating the overall construction speed by a factor of 5 to 10x.},
  booktitle = {Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics},
  pages     = {59-64},
  numpages  = {6},
  keywords  = {real-time, ray tracing, spatial index},
  location  = {Vancouver, British Columbia, Canada},
  series    = {HPG '11}
}

@article{5669303,
  author  = {Wald, Ingo},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Fast Construction of {SAH} {BVH}s on the Intel Many Integrated Core ({MIC}) Architecture},
  year    = {2012},
  volume  = {18},
  number  = {1},
  pages   = {47-57},
  doi     = {10.1109/TVCG.2010.251}
}

@article{6429331,
  author  = {Glassner, Andrew S.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Space subdivision for fast ray tracing},
  year    = {1984},
  volume  = {4},
  number  = {10},
  pages   = {15-24},
  doi     = {10.1109/MCG.1984.6429331}
}

@inproceedings{kaplan1985use,
  title        = {The use of spatial coherence in ray tracing},
  author       = {Kaplan, Michael R},
  year         = {1985},
  booksubtitle = {ACM SIGGRAPH Course Notes 11}
}

@article{MacDonald1990,
  author   = {MacDonald, J. David and Booth, Kellogg S.},
  journal  = {The Visual Computer},
  number   = {3},
  title    = {Heuristics for ray tracing using space subdivision},
  volume   = {6},
  year     = {1990},
  pages    = {153-166},
  date     = {1990-05-01},
  abstract = {Ray tracing requires testing of many rays to determine intersections with objects. A way of reducing the computation is to organize objects into hierarchical data structures. We examine two heuristics for space subdivisions using bintrees, one based on the intuition that surface area is a good estimate of intersection probability, one based on the fact that the optimal splitting plane lies between the spatial median and the object median planes of a volume. Traversal algorithms using cross links between nodes are presented as generalizations of ropes in octrees. Simulations of the surface area heuristic and the cross link scheme are presented. These results generalize to other hierarchical data structures.},
  issn     = {1432-2315},
  doi      = {10.1007/BF01911006}
}

@inproceedings{Naylor1993:27,
  author    = {Bruce Naylor},
  title     = {Constructing good partitioning trees},
  booktitle = {Proceedings of Graphics Interface '93},
  series    = {GI '93},
  year      = {1993},
  isbn      = {0-9695338-2-9},
  issn      = {0713-5424},
  location  = {Toronto, Ontario, Canada},
  pages     = {181-191},
  numpages  = {11},
  url       = {http://graphicsinterface.org/wp-content/uploads/gi1993-27.pdf},
  publisher = {Canadian Human-Computer Communications Society},
  address   = {Toronto, Ontario, Canada}
}

@inproceedings{HavranImproving2002,
  author       = {Havran, Vlastimil and Bittner, Ji$\check{\text{r}}$í},
  booktitle    = {10th International Conference on Computer Graphics, Visualization and Computer Vision 2002},
  editor       = {Skala, V},
  title        = {On improving kd-trees for ray shooting},
  booksubtitle = {WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS},
  year         = {2002},
  pages        = {209-216}
}

@phdthesis{Havran2000:PhD,
  author = {Vlastimil Havran},
  title  = {Heuristic Ray Shooting Algorithms},
  school = {Department of Computer Science and Engineering,
            Faculty of Electrical Engineering,
            Czech Technical University in Prague},
  type   = {Ph.D. Thesis},
  year   = {2000},
  month  = {11},
  url    = {http://www.cgg.cvut.cz/~havran/phdthesis.html}
}

@inproceedings{10.1007/978-3-642-71071-1_4,
  author    = {Jansen, Frederik W.},
  editor    = {Kessener, Laurens R. A.
               and Peters, Frans J.
               and van Lierop, Marloes L. P.},
  title     = {Data structures for ray tracing},
  booktitle = {Data Structures for Raster Graphics},
  year      = {1986},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {57-73},
  abstract  = {Methods to improve the efficiency of the ray tracing process are reviewed. Special attention is given to algorithms for tracing a ray through box and cell structures of hierarchical box and spatial subdivision methods.},
  isbn      = {978-3-642-71071-1}
}

@article{ArvoRay1988,
  author  = {Arvo, Jim},
  journal = {Ray Tracing News},
  number  = {5},
  title   = {Linear-time Voxel Walking for Octrees},
  volume  = {1},
  month   = {3},
  year    = {1988},
  url     = {http://www.realtimerendering.com/resources/RTNews/html/rtnews2d.html#art5}
}

@incollection{SUNG1992271,
  title     = {VI.1 - RAY TRACING WITH THE {BSP} TREE},
  editor    = {DAVID KIRK},
  booktitle = {Graphics Gems III (IBM Version)},
  publisher = {Morgan Kaufmann},
  address   = {San Francisco},
  pages     = {271-274},
  year      = {1992},
  isbn      = {978-0-12-409673-8},
  doi       = {10.1016/B978-0-08-050755-2.50061-0},
  author    = {Kelvin Sung and Peter Shirley},
  abstract  = {Publisher Summary
               In order to speed up the intersection calculation in ray-tracing programs, people have implemented divide-and-conquer strategies such as hierarchical bounding volumes and octrees. Uniform subdivision has also been used to speed up that calculation. Uniform subdivision is undesirable for applications where the objects may be unevenly distributed in space. This is because the amount of memory needed for uniform subdivision is proportional to the highest density of objects, rather than the total number. Hierarchical-bounding volumes can be difficult to implement effectively but can be used to good effect. Hierarchical space subdivision techniques do not suffer the memory problems of uniform subdivision and are also relatively easy to implement. This chapter discusses the best overall hierarchical subdivision technique currently known. There are two basic modules in a BSP tree intersection code. The first module builds the tree by recursively cutting the bounding box of all objects along a median spatial plane. The second module tracks a ray through the leaf nodes of the BSP tree checking for intersections. The BSP tree is built by InitBinTree( ) and Subdivide( ). RayTreeIntersect( ) is the actual tree walking traversal of the BSP tree following a ray.}
}

@inproceedings{4061547,
  author    = {Wald, Ingo and Havran, Vlastimil},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {On building fast kd-Trees for Ray Tracing, and on doing that in {O}({N} log {N})},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {61-69},
  doi       = {10.1109/RT.2006.280216}
}

@inproceedings{4634623,
  author    = {Soupikov, Alexei and Shevtsov, Maxim and Kapustin, Alexander},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Improving {K}d-tree quality at a reasonable construction cost},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {67-72},
  doi       = {10.1109/RT.2008.4634623}
}

@article{10.1111/cgf.12241,
  author   = {Choi, B. and Chang, B. and Ihm, I.},
  title    = {Improving Memory Space Efficiency of {K}d-tree for Real-time Ray Tracing},
  journal  = {Computer Graphics Forum},
  volume   = {32},
  number   = {7},
  pages    = {335-344},
  keywords = {I.3.6 Computer Graphics: Methodology and Techniques—Graphics data structures and data types., I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing},
  doi      = {10.1111/cgf.12241},
  abstract = {Abstract Compared with its competitors such as the bounding volume hierarchy, a drawback of the kd-tree structure is that a large number of triangles are repeatedly duplicated during its construction, which often leads to inefficient, large and tall binary trees with high triangle redundancy. In this paper, we propose a space-efficient kd-tree representation where, unlike commonly used methods, an inner node is allowed to optionally store a reference to a triangle, so highly redundant triangles in a kd-tree can be culled from the leaf nodes and moved to the inner nodes. To avoid the construction of ineffective kd-trees entailing computational inefficiencies due to early, possibly unnecessary, ray-triangle intersection calculations that now have to be performed in the inner nodes during the kd-tree traversal, we present heuristic measures for determining when and how to choose triangles for inner nodes during kd-tree construction. Based on these metrics, we describe how the new form of kd-tree is constructed and stored compactly using a carefully designed data layout. Our experiments with several example scenes showed that our kd-tree representation technique significantly reduced the memory requirements for storing the kd-tree structure, while effectively suppressing the unavoidable frame-rate degradation observed during ray tracing.},
  year     = {2013}
}

@article{10.1111/j.1467-8659.2007.01062.x,
  author   = {Shevtsov, Maxim and Soupikov, Alexei and Kapustin, Alexander},
  title    = {Highly Parallel Fast {KD}-tree Construction for Interactive Ray Tracing of Dynamic Scenes},
  journal  = {Computer Graphics Forum},
  volume   = {26},
  number   = {3},
  pages    = {395-404},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism: Ray tracing; Color; Shading; Shadowing and texture, I.3.1 Hardware Architecture: Parallel processing},
  doi      = {10.1111/j.1467-8659.2007.01062.x},
  abstract = {Abstract We present a highly parallel, linearly scalable technique of kd-tree construction for ray tracing of dynamic geometry. We use conventional kd-tree compatible with the high performing algorithms such as MLRTA or frustum tracing. Proposed technique offers exceptional construction speed maintaining reasonable kd-tree quality for rendering stage. The algorithm builds a kd-tree from scratch each frame, thus prior knowledge of motion /deformation or motion constraints are not required. We achieve nearly real-time performance of 7-12 FPS for models with 200K of dynamic triangles at 1024x1024 resolution with shadows and textures.},
  year     = {2007}
}

@inproceedings{10.5555/1921479.1921492,
  author    = {Choi, Byn and Komuravelli, Rakesh and Lu, Victor and Sung, Hyojin and Bocchino, Robert L. and Adve, Sarita V. and Hart, John C.},
  title     = {Parallel {SAH} {K}-{D} Tree Construction},
  year      = {2010},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {The k-D tree is a well-studied acceleration data structure for ray tracing. It is
               used to organize primitives in a scene to allow efficient execution of intersection
               operations between rays and the primitives. The highest quality k-D tree can be obtained
               using greedy cost optimization based on a surface area heuristc (SAH). While the high
               quality enables very fast ray tracing times, a key drawback is that the k-D tree construction
               time remains prohibitively expensive. This cost is unreasonable for rendering dynamic
               scenes for future visual computing applications on emerging multicore systems. Much
               work has therefore been focused on faster parallel k-D tree construction performance
               at the expense of approximating or ignoring SAH computation, which produces k-D trees
               that degrade rendering time. In this paper, we present two new parallel algorithms
               for building precise SAH-optimized k-D trees, with different tradeoffs between the
               total work done and parallel scalability. The algorithms achieve up to 8x speedup
               on 32 cores, without degrading tree quality and rendering time, yielding the best
               reported speedups so far for precise-SAH k-D tree construction.},
  booktitle = {Proceedings of the Conference on High Performance Graphics},
  pages     = {77-86},
  numpages  = {10},
  location  = {Saarbrucken, Germany},
  series    = {HPG '10}
}

@inproceedings{10.2312:egs.20091046,
  booktitle = {Eurographics 2009 - Short Papers},
  editor    = {P. Alliez and M. Magnor},
  title     = {A Cost Metric for Scene-Interior Ray Origins},
  author    = {Fabianowski, Bartosz and Fowler, Colin and Dingliana, John},
  year      = {2009},
  publisher = {The Eurographics Association},
  doi       = {10.2312/egs.20091046},
  pages     = {49-52}
}

@inproceedings{4634614,
  author    = {Hunt, Warren and Mark, William R.},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Adaptive acceleration structures in perspective space},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {11-17},
  doi       = {10.1109/RT.2008.4634614}
}

@inproceedings{4634625,
  author    = {Hunt, Warren A.},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Corrections to the surface area metric with respect to mail-boxing},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {77-80},
  doi       = {10.1109/RT.2008.4634625}
}

@article{VINKLER2012283,
  title    = {Visibility driven {BVH} build up algorithm for ray tracing},
  journal  = {Computers \& Graphics},
  volume   = {36},
  number   = {4},
  pages    = {283-296},
  year     = {2012},
  note     = {Applications of Geometry Processing},
  issn     = {0097-8493},
  doi      = {10.1016/j.cag.2012.02.013},
  author   = {Marek Vinkler and Vlastimil Havran and Ji$\check{\text{r}}$í Sochor},
  keywords = {Ray tracing, Bounding volume hierarchies, BVH build algorithm, Surface area heuristic}
}

@article{10.1111/j.1467-8659.2011.01861.x,
  author   = {Ize, Thiago and Hansen, Charles},
  title    = {{RTSAH} Traversal Order for Occlusion Rays},
  journal  = {Computer Graphics Forum},
  volume   = {30},
  number   = {2},
  pages    = {297-305},
  doi      = {10.1111/j.1467-8659.2011.01861.x},
  abstract = {Abstract We accelerate the finding of occluders in tree based acceleration structures, such as a packetized BVH and a single ray kd-tree, by deriving the ray termination surface area heuristic (RTSAH) cost model for traversing an occlusion ray through a tree and then using the RTSAH to determine which child node a ray should traverse first instead of the traditional choice of traversing the near node before the far node. We further extend RTSAH to handle materials that attenuate light instead of fully occluding it, so that we can avoid superfluous intersections with partially transparent objects. For scenes with high occlusion, we substantially lower the number of traversal steps and intersection tests and achieve up to 2 × speedups.},
  year     = {2011}
}

@inproceedings{10.2312:sre.20151164,
  booktitle = {Eurographics Symposium on Rendering - Experimental Ideas \& Implementations},
  editor    = {Jaakko Lehtinen and Derek Nowrouzezahrai},
  title     = {Efficient Visibility Heuristics for kd-trees Using the {RTSAH}},
  author    = {Moulin, Matthias and Billen, Niels and Dutr\'{e}, Philip},
  year      = {2015},
  publisher = {The Eurographics Association},
  doi       = {10.2312/sre.20151164}
}

@inproceedings{4061550,
  author    = {Popov, Stefan and Gunther, Johannes and Seidel, Hans-peter and Slusallek, Philipp},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {Experiences with Streaming Construction of {SAH} {KD}-Trees},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {89-94},
  doi       = {10.1109/RT.2006.280219}
}

@inproceedings{4061549,
  author    = {Hunt, Warren and Mark, William R. and Stoll, Gordon},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {Fast kd-tree Construction with an Adaptive Error-Bounded Heuristic},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {81-88},
  doi       = {10.1109/RT.2006.280218}
}

@inproceedings{10.1145/2492045.2492056,
  author    = {Aila, Timo and Karras, Tero and Laine, Samuli},
  title     = {On Quality Metrics of Bounding Volume Hierarchies},
  year      = {2013},
  isbn      = {9781450321358},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2492045.2492056},
  abstract  = {The surface area heuristic (SAH) is widely used as a predictor for ray tracing performance,
               and as a heuristic to guide the construction of spatial acceleration structures. We
               investigate how well SAH actually predicts ray tracing performance of a bounding volume
               hierarchy (BVH), observe that this relationship is far from perfect, and then propose
               two new metrics that together with SAH almost completely explain the measured performance.
               Our observations shed light on the increasingly common situation that a supposedly
               good tree construction algorithm produces trees that are slower to trace than expected.
               We also note that the trees constructed using greedy top-down algorithms are consistently
               faster to trace than SAH indicates and are also more SIMD-friendly than competing
               approaches.},
  booktitle = {Proceedings of the 5th High-Performance Graphics Conference},
  pages     = {101-107},
  numpages  = {7},
  keywords  = {quality metrics, acceleration structures, ray tracing},
  location  = {Anaheim, California},
  series    = {HPG '13}
}

@article{10.1145/357332.357335,
  author     = {Weghorst, Hank and Hooper, Gary and Greenberg, Donald P.},
  title      = {Improved Computational Methods for Ray Tracing},
  year       = {1984},
  issue_date = {Jan. 1984},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/357332.357335},
  journal    = {ACM Trans. Graph.},
  month      = {1},
  pages      = {52-69},
  numpages   = {18}
}

@inproceedings{4342591,
  author    = {Kammaje, Ravi P. and Mora, Benjamin},
  booktitle = {2007 IEEE Symposium on Interactive Ray Tracing},
  title     = {A Study of Restricted {BSP} Trees for Ray Tracing},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {55-62},
  doi       = {10.1109/RT.2007.4342591}
}

@inproceedings{4634637,
  author    = {Ize, Thiago and Wald, Ingo and Parker, Steven G.},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Ray tracing with the {BSP} tree},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {159-166},
  doi       = {10.1109/RT.2008.4634637}
}

@inproceedings{10.2312:egst.20071056,
  booktitle = {Eurographics 2007 - State of the Art Reports},
  editor    = {Dieter Schmalstieg and Jiri Bittner},
  title     = {State of the Art in Ray Tracing Animated Scenes},
  author    = {Wald, Ingo and Mark, William R. and G\"{u}nther, Johannes and Boulos, Solomon and Ize, Thiago and Hunt, Warren and Parker, Steven G. and Shirley, Peter},
  year      = {2007},
  publisher = {The Eurographics Association},
  doi       = {10.2312/egst.20071056}
}

@article{10.1111/j.1467-8659.2009.01497.x,
  author   = {Garanzha, Kirill},
  title    = {The Use of Precomputed Triangle Clusters for Accelerated Ray Tracing in Dynamic Scenes},
  journal  = {Computer Graphics Forum},
  volume   = {28},
  number   = {4},
  pages    = {1199-1206},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-Raytracing},
  doi      = {10.1111/j.1467-8659.2009.01497.x},
  abstract = {Abstract In this paper we present a hybrid algorithm for building the bounding volume hierarchy (BVH) that is used in accelerating ray tracing of animated models. This algorithm precomputes densely packed clusters of triangles on surfaces. Folowing that, a set of clusters is used to rebuild the BVH in every frame. Our approach utilizes the assumption that groups of connected triangles remain connected throughout the course of the animation. We introduce a novel heuristic to create triangle clusters that are designed for high performance ray tracing. This heuristic combines the density of connectivity, geometric size and the shape of the cluster. Our approach accelerates the BVH builder by an order of magnitude rebuilding only the set of clusters that is much smaller than the original set of triangles. The speed-up is achieved against a ‘brute-force’ BVH builder that repartitions all triangles in every frame of animation without using any pre-clustering. The rendering performance is not affected when a cluster contains a few dozen triangles. We demonstrate the real-time/interactive ray tracing performance for highly-dynamic complex models.},
  year     = {2009}
}

@article{504,
  author  = {Glassner, Andrew S.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Spacetime ray tracing for animation},
  year    = {1988},
  volume  = {8},
  number  = {2},
  pages   = {60-70},
  doi     = {10.1109/38.504}
}

@inproceedings{10.1145/2018323.2018334,
  author    = {Gr\"{u}nschlo\ss{}, Leonhard and Stich, Martin and Nawaz, Sehera and Keller, Alexander},
  title     = {{MSBVH}: An Efficient Acceleration Data Structure for Ray Traced Motion Blur},
  year      = {2011},
  isbn      = {9781450308960},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2018323.2018334},
  abstract  = {When a bounding volume hierarchy is used for accelerating the intersection of rays
               and scene geometry, one common way to incorporate motion blur is to interpolate node
               bounding volumes according to the time of the ray. However, such hierarchies typically
               exhibit large overlap between bounding volumes, which results in an inefficient traversal.
               This work builds upon the concept of spatially partitioning nodes during tree construction
               in order to reduce overlap in the presence of moving objects. The resulting hierarchies
               are often significantly cheaper to traverse than those generated by classic approaches.},
  booktitle = {Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics},
  pages     = {65-70},
  numpages  = {6},
  keywords  = {bounding volume hierarchies, ray tracing, motion blur},
  location  = {Vancouver, British Columbia, Canada},
  series    = {HPG '11}
}

@article{10.1145/37402.37409,
  author     = {Arvo, James and Kirk, David},
  title      = {Fast Ray Tracing by Ray Classification},
  year       = {1987},
  issue_date = {July 1987},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {21},
  number     = {4},
  issn       = {0097-8930},
  doi        = {10.1145/37402.37409},
  abstract   = {We describe a new approach to ray tracing which drastically reduces the number of
                ray-object and ray-bounds intersection calculations by means of 5-dimensional space
                subdivision. Collections of rays originating from a common 3D rectangular volume and
                directed through a 2D solid angle are represented as hypercubes in 5-space. A 5D volume
                bounding the space of rays is dynamically subdivided into hypercubes, each linked
                to a set of objects which are candidates for intersection. Rays are classified into
                unique hypercubes and checked for intersection with the associated candidate object
                set. We compare several techniques for object extent testing, including boxes, spheres,
                plane-sets, and convex polyhedra. In addition, we examine optimizations made possible
                by the directional nature of the algorithm, such as sorting, caching and backface
                culling. Results indicate that this algorithm significantly outperforms previous ray
                tracing techniques, especially for comples environments.},
  journal    = {SIGGRAPH Comput. Graph.},
  month      = {8},
  pages      = {55-64},
  numpages   = {10}
}

@inproceedings{10.1145/37401.37409,
  author    = {Arvo, James and Kirk, David},
  title     = {Fast Ray Tracing by Ray Classification},
  year      = {1987},
  isbn      = {0897912276},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/37401.37409},
  abstract  = {We describe a new approach to ray tracing which drastically reduces the number of
               ray-object and ray-bounds intersection calculations by means of 5-dimensional space
               subdivision. Collections of rays originating from a common 3D rectangular volume and
               directed through a 2D solid angle are represented as hypercubes in 5-space. A 5D volume
               bounding the space of rays is dynamically subdivided into hypercubes, each linked
               to a set of objects which are candidates for intersection. Rays are classified into
               unique hypercubes and checked for intersection with the associated candidate object
               set. We compare several techniques for object extent testing, including boxes, spheres,
               plane-sets, and convex polyhedra. In addition, we examine optimizations made possible
               by the directional nature of the algorithm, such as sorting, caching and backface
               culling. Results indicate that this algorithm significantly outperforms previous ray
               tracing techniques, especially for comples environments.},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {55-64},
  numpages  = {10},
  series    = {SIGGRAPH '87}
}

@article{10.1111/j.1467-8659.2008.01269.x,
  author   = {Lagae, Ares and Dutré, Philip},
  title    = {Accelerating Ray Tracing using Constrained Tetrahedralizations},
  journal  = {Computer Graphics Forum},
  volume   = {27},
  number   = {4},
  pages    = {1303-1312},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism},
  doi      = {10.1111/j.1467-8659.2008.01269.x},
  abstract = {Abstract In this paper we introduce the constrained tetrahedralization as a new acceleration structure for ray tracing. A constrained tetrahedralization of a scene is a tetrahedralization that respects the faces of the scene geometry. The closest intersection of a ray with a scene is found by traversing this tetrahedralization along the ray, one tetrahedron at a time. We show that constrained tetrahedralizations are a viable alternative to current acceleration structures, and that they have a number of unique properties that set them apart from other acceleration structures: constrained tetrahedralizations are not hierarchical yet adaptive; the complexity of traversing them is a function of local geometric complexity rather than global geometric complexity; constrained tetrahedralizations support deforming geometry without any effort; and they have the potential to unify several data structures currently used in global illumination.},
  year     = {2008}
}

@inproceedings{10.1007/978-3-642-72617-0_17,
  author    = {Ooi, Beng C.},
  editor    = {Schek, H.-J. and Schlageter, G.},
  title     = {Spatial kd-Tree: A Data Structure for Geographic Database},
  booktitle = {Datenbanksysteme in B{\"u}ro, Technik und Wissenschaft},
  year      = {1987},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {247-258},
  abstract  = {Geographic objects in two dimensional space are usually represented as points, lines, and regions. To retrieve these data objects from the database efficiently according to their spatial locations and spatial relationships, an efficient indexing mechanism is necessary. The kd-trees proposed in the literature are either unsuitable for indexing non-zero size objects such as line and region or require duplication of indexes. In this paper an alternative index structure called spatial kd-tree is proposed to facilitate the processing of queries concerning geographic information. The spatial kd-tree partitions a set of records on two dimensional space into small groups based on their spatial proximity. The structure not only provides efficient retrieval of objects but also maintains high storage efficiency.},
  isbn      = {978-3-642-72617-0}
}

@inproceedings{10.1145/585740.585761,
  author    = {Zachmann, Gabriel},
  title     = {Minimal Hierarchical Collision Detection},
  year      = {2002},
  isbn      = {1581135300},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/585740.585761},
  abstract  = {We present a novel bounding volume hierarchy that allows for extremely small data
               structure sizes while still performing collision detection as fast as other classical
               hierarchical algorithms in most cases. The hierarchical data structure is a variation
               of axis-aligned bounding box trees. In addition to being very memory efficient, it
               can be constructed efficiently and very fast.We also propose a criterion to be used
               during the construction of the BV hierarchies is more formally established than previous
               heuristics. The idea of the argument is general and can be applied to other bounding
               volume hierarchies as well. Furthermore, we describe a general optimization technique
               that can be applied to most hierarchical collision detection algorithms.Finally, we
               describe several box overlap tests that exploit the special features of our new BV
               hierarchy. These are compared experimentally among each other and with the DOP tree
               using a benchmark suite of real-world CAD data.},
  booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology},
  pages     = {121-128},
  numpages  = {8},
  keywords  = {virtual prototyping, interference detection, R-trees, physically-based modeling, hierarchical data structures, hierarchical partitioning},
  location  = {Hong Kong, China},
  series    = {VRST '02}
}

@inproceedings{10.1145/1283900.1283912,
  author    = {Woop, Sven and Marmitt, Gerd and Slusallek, Philipp},
  title     = {{B}-{KD} Trees for Hardware Accelerated Ray Tracing of Dynamic Scenes},
  year      = {2006},
  isbn      = {3905673371},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1283900.1283912},
  abstract  = {This paper introduces a new spatial index structure, called Bounded KD tree (B-KD
               tree), for realtime ray tracing of dynamic scenes. By presenting hardware units of
               all time critical B-KD tree algorithms in the context of a custom realtime ray tracing
               chip we show that this spatial index structure is well suited for hardware implementation.
               B-KD trees are a hybrid spatial index structure that combine the advantages of KD
               trees and Bounding Volume Hierarchies into a single, simple to handle spatial index
               structure. Similar to KD trees, B-KD trees are binary trees where each node considers
               only a single spatial dimension. However, instead of a single splitting plane that
               divides space into two disjoint sub-spaces, each node in B-KD trees contains two pairs
               of axis aligned planes that bound the geometry of its two child nodes. As a bounding
               volume approach B-KD trees allow for simple and efficient updates when changing geometry
               while maintaining the fast traversal operations and simple hardware implementation
               known from KD trees. This enables the support for dynamic scenes with constant mesh
               topology and coherent dynamic changes, like typical skinned meshes.Our hardware architecture
               contains several fixed-function units that completely handle skinning, updating, and
               ray tracing of dynamic scenes using B-KD trees. An FPGA prototype of this architecture
               already delivers realtime performance of up to 35 frames per second even when clocked
               at only 66 MHz.},
  booktitle = {Proceedings of the 21st ACM SIGGRAPH/EUROGRAPHICS Symposium on Graphics Hardware},
  pages     = {67-77},
  numpages  = {11},
  location  = {Vienna, Austria},
  series    = {GH '06}
}

@inproceedings{10.5555/2383894.2383912,
  author    = {W\"{a}chter, Carsten and Keller, Alexander},
  title     = {Instant Ray Tracing: The Bounding Interval Hierarchy},
  year      = {2006},
  isbn      = {3905673355},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {We introduce a new ray tracing algorithm that exploits the best of previous methods:
               Similar to bounding volume hierarchies the memory of the acceleration data structure
               is linear in the number of objects to be ray traced and can be predicted prior to
               construction, while the traversal of the hierarchy is as efficient as the one of kd-trees.
               The construction algorithm can be considered a variant of quicksort and for the first
               time is based on a global space partitioning heuristic, which is much cheaper to evaluate
               than the classic surface area heuristic. Compared to spatial partitioning schemes
               only a fraction of the memory is used and a higher numerical precision is intrinsic.
               The new method is simple to implement and its high performance is demonstrated by
               extensive measurements including massive as well as dynamic scenes, where we focus
               on the total time to image including the construction cost rather than on only frames
               per second.},
  booktitle = {Proceedings of the 17th Eurographics Conference on Rendering Techniques},
  pages     = {139-149},
  numpages  = {11},
  location  = {Nicosia, Cyprus},
  series    = {EGSR '06}
}

@inproceedings{4061548,
  author    = {Havran, Vlastimil and Herzog, Robert and Seidel, Hans-peter},
  booktitle = {2006 IEEE Symposium on Interactive Ray Tracing},
  title     = {On the Fast Construction of Spatial Hierarchies for Ray Tracing},
  year      = {2006},
  volume    = {},
  number    = {},
  pages     = {71-80},
  doi       = {10.1109/RT.2006.280217}
}

@article{2151237X.2006.10129224,
  author    = {Miguel R. Zuniga and Jeffrey K. Uhlmann},
  title     = {Ray Queries with Wide Object Isolation and the {DE}-Tree},
  journal   = {Journal of Graphics Tools},
  volume    = {11},
  number    = {3},
  pages     = {27-45},
  year      = {2006},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2006.10129224}
}

@article{Arnaldi1987,
  author  = {Arnaldi, Bruno and Priol, Thierry and Bouatouch, Kadi},
  journal = {The Visual Computer},
  number  = {2},
  title   = {A new space subdivision method for ray tracing {CSG} modelled scenes},
  volume  = {3},
  year    = {1987},
  date    = {1987-08-01},
  pages   = {98-108},
  issn    = {1432-2315},
  doi     = {10.1007/BF02153666}
}
@phdthesis{Benthin_2006,
  title  = {Realtime ray tracing on current {CPU} architectures},
  author = {Benthin, Carsten},
  doi    = {http://dx.doi.org/10.22028/D291-25853},
  year   = {2006},
  school = {Computer Graphics Group, Saarland University}
}

@article{doi:10.1080/10867651.2001.10487535,
  author    = {Tomas Akenine-Möllser},
  title     = {Fast {3D} Triangle-Box Overlap Testing},
  journal   = {Journal of Graphics Tools},
  volume    = {6},
  number    = {1},
  pages     = {29-33},
  year      = {2001},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.2001.10487535}
}

@inproceedings{4634616,
  author    = {Lacewell, Dylan and Burley, Brent and Boulos, Solomon and Shirley, Peter},
  booktitle = {2008 IEEE Symposium on Interactive Ray Tracing},
  title     = {Raytracing prefiltered occlusion for aggregate geometry},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {19-26},
  doi       = {10.1109/RT.2008.4634616}
}

% 5
@article{10.1080/10867651.1999.10487511,
  author    = {Brian Smits},
  title     = {An {RGB}-to-Spectrum Conversion for Reflectances},
  journal   = {Journal of Graphics Tools},
  volume    = {4},
  number    = {4},
  pages     = {11-22},
  year      = {1999},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.1999.10487511}
}

@book{PREISENDORFER19653,
  author    = {Rudolph W. Preisendorfer},
  editor    = {Rudolph W. Preisendorfer},
  publisher = {Pergamon},
  title     = {Radiative Transfer on Discrete Spaces},
  issn      = {978-0-08-010592-5},
  year      = {1965},
  series    = {International Series of Monographs on Pure and Applied Mathematics},
  doi       = {10.1016/C2013-0-05368-6},
  volume    = {74}
}

@article{Fante:81,
  author    = {Ronald L. Fante},
  journal   = {Journal of the Optical Society of America},
  keywords  = {Coherence; Electric fields; Fourier transforms; Laser beams; Radiative transfer},
  number    = {4},
  pages     = {460-468},
  publisher = {OSA},
  title     = {Relationship between radiative-transport theory and {M}axwell's equations in dielectric media},
  volume    = {71},
  month     = {4},
  year      = {1981},
  doi       = {10.1364/JOSA.71.000460},
  abstract  = {The relationship between Maxwell's equations and radiative-transport theory is studied for isotropic, nondispersive media that have arbitrary permittivity variations. It is demonstrated that the postulates of transport theory are consistent with Maxwell's equations if the characteristics of the medium and the fields are such that the field-correlation tensor possesses certain properties and if the relative permittivity fluctuations in the medium are small in comparison with unity and have correlation lengths that satisfy appropriate requirements.}
}

@inproceedings{10.1145/800250.807502,
  author    = {Meyer, Gary W. and Greenberg, Donald P.},
  title     = {Perceptual Color Spaces for Computer Graphics},
  year      = {1980},
  isbn      = {0897910214},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800250.807502},
  abstract  = {Perceptually uniform color spaces can be a useful tool for solving computer graphics color selection problems. However, before they can be used effectively some basic principles of tristimulus colorimetry must be understood and the color reproduction device on which they are to be used must be properly adjusted. The Munsell Book of Color and the Optical Society of America (OSA) Uniform Color Scale are two uniform color spaces which provide a useful way of organizing the colors of a digitally controlled color television monitor. The perceptual uniformity of these color spaces can be used to select color scales to encode the variations of parameters such as temperature or stress.},
  booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {254-261},
  numpages  = {8},
  keywords  = {Color television, Computer graphics, Uniform color spaces, Color, Pseudo color, False color, Color science, Colorimetry},
  location  = {Seattle, Washington, USA},
  series    = {SIGGRAPH '80}
}

@article{10.1145/7529.7920,
  author     = {Meyer, Gary W. and Rushmeier, Holly E. and Cohen, Michael F. and Greenberg, Donald P. and Torrance, Kenneth E.},
  title      = {An Experimental Evaluation of Computer Graphics Imagery},
  year       = {1986},
  issue_date = {Jan. 1986},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {5},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/7529.7920},
  abstract   = {Accurate simulation of light propagation within an environment and perceptually based imaging techniques are necessary for the creation of realistic images. A physical experiment that verifies the simulation of reflected light intensities for diffuse environments was conducted. Measurements of radiant energy flux densities are compared with predictions using the radiosity method for those physical environments. By using color science procedures the results of the light model simulation are then transformed to produce a color television image. The final image compares favorably with the original physical model. The experiment indicates that, when the physical model and the simulation were viewed through a view camera, subjects could not distinguish between them. The results and comparison of both test procedures are presented within this paper.},
  journal    = {ACM Trans. Graph.},
  month      = {1},
  pages      = {30-50},
  numpages   = {21}
}

@article{773962,
  author  = {Hall, Roy A.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Comparing spectral color computation methods},
  year    = {1999},
  volume  = {19},
  number  = {4},
  pages   = {36-45},
  doi     = {10.1109/38.773962}
}

@article{773963,
  author  = {Johnson, Graham and Fairchild, Mark D.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Full-spectral color calculations in realistic image synthesis},
  year    = {1999},
  volume  = {19},
  number  = {4},
  pages   = {47-53},
  doi     = {10.1109/38.773963}
}

@inproceedings{10.2312:egst.20021054,
  booktitle = {Eurographics 2002 - STARs},
  title     = {Tone Reproduction and Physically Based Spectral Rendering},
  author    = {Devlin, Kate and Chalmers, Alan and Wilkie, Alexander and Purgathofer, Werner},
  year      = {2002},
  publisher = {Eurographics Association},
  issn      = {1017-4656},
  doi       = {10.2312/egst.20021054}
}

@inproceedings{10.1145/122718.122729,
  author    = {Borges, Carlos F.},
  title     = {Trichromatic Approximation for Computer Graphics Illumination Models},
  year      = {1991},
  isbn      = {0897914368},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/122718.122729},
  abstract  = {The complexity of computer graphics illumination models and the associated need to find ways of reducing evaluation time has led to the use of two methods for simplifying the spectral data needed for an exact solution. The first method, where spectral data is sampled at a number of discrete points, has been extensively investigated and bounds for the error are known. Unfortunately, the second method, where spectral data is replaced with tristimulus values (such as RGB values), is very little understood even though it is widely used. In this paper we examine the error incurred by the use of this method by investigating the problem of approximating the tristimulus coordinates of light reflected from a surface from those of the source and the surface. A variation on a well known and widely used approximation is presented. This variation used the XYZ primaries which have unique properties that yield straightforward analytic bounds for the approximation error. This analysis is important because it gives a sound mathematical footing to the widely used method of trichromatic approximation. The error bounds will give some insights into the factors that affect accuracy and will indicate why this method often works quite well in practice.},
  booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {101-104},
  numpages  = {4},
  keywords  = {spectral power density (SPD), illumination models, trichromatic approximation, spectral reflectance, Seminorm, tristimulus coordinates},
  series    = {SIGGRAPH '91}
}

@inproceedings{10.1145/166117.166142,
  author    = {Peercy, Mark S.},
  title     = {Linear Color Representations for Full Speed Spectral Rendering},
  year      = {1993},
  isbn      = {0897916018},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/166117.166142},
  booktitle = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {191-198},
  numpages  = {8},
  keywords  = {linear models, linear color representations, tristimulus values, full spectral rendering},
  location  = {Anaheim, CA},
  series    = {SIGGRAPH '93}
}

@inproceedings{10.1007/978-3-7091-6858-5_12,
  author    = {Rougeron, Gilles and P{\'e}roche, Bernard},
  editor    = {Dorsey, Julie and Slusallek, Philipp},
  title     = {An adaptive representation of spectral data for reflectance computations},
  booktitle = {Rendering Techniques '97},
  year      = {1997},
  publisher = {Springer Vienna},
  address   = {Vienna},
  pages     = {127-138},
  abstract  = {This paper deals with the representation of spectral data so as to control the colorimetric error committed during rendering computations. These data are projected on a set of hierarchical basis functions called scaling functions leading to a representation by means of binary trees. An adaptive algorithm is proposed in which refinement and merge steps managed by an estimation of the error made in the X Y Z color space allows to control the representation of spectra},
  isbn      = {978-3-7091-6858-5}
}

@inproceedings{10.2312:EGWR:EGWR02:117-124,
  booktitle = {Eurographics Workshop on Rendering},
  editor    = {P. Debevec and S. Gibson},
  title     = {Picture Perfect {RGB} Rendering Using Spectral Prefiltering and Sharp Color Primaries},
  author    = {Ward, Greg and Eydelberg-Vileshin, Elena},
  year      = {2002},
  publisher = {The Eurographics Association},
  issn      = {1727-3463},
  isbn      = {1-58113-534-3},
  doi       = {10.2312/EGWR/EGWR02/117-124}
}

@article{Sun2001,
  author  = {Sun, Yinlong and Fracchia, F. David and Drew, Mark S. and Calvert, Thomas W.},
  journal = {The Visual Computer},
  number  = {7},
  title   = {A spectrally based framework for realistic image synthesis},
  volume  = {17},
  year    = {2001},
  pages   = {429-444},
  doi     = {10.1007/s003710100116}
}

@article{Drew:03,
  author    = {Mark S. Drew and Graham D. Finlayson},
  journal   = {Journal of the Optical Society of America},
  keywords  = {Illumination; Color; Digital photography; Image metrics; Image processing; Light propagation; Multispectral imaging; Virtual reality},
  number    = {7},
  pages     = {1181-1193},
  publisher = {OSA},
  title     = {Multispectral processing without spectra},
  volume    = {20},
  month     = {7},
  year      = {2003},
  doi       = {10.1364/JOSAA.20.001181},
  abstract  = {It is often the case that multiplications of whole spectra, component by component, must be carried out, for example when light reflects from or is transmitted through materials. This leads to particularly taxing calculations, especially in spectrally based ray tracing or radiosity in graphics, making a full-spectrum method prohibitively expensive. Nevertheless, using full spectra is attractive because of the many important phenomena that can be modeled only by using all the physics at hand. We apply to the task of spectral multiplication a method previously used in modeling RGB-based light propagation. We show that we can often multiply spectra without carrying out spectral multiplication. In previous work \[J. Opt. Soc. Am. A11, 1553 (1994)\] we developed a method called spectral sharpening, which took camera RGBs to a special sharp basis that was designed to render illuminant change simple to model. Specifically, in the new basis, one can effectively model illuminant change by using a diagonal matrix rather than the 3{\texttimes}3 linear transform that results from a three-component finite-dimensional model \[{\textless}author order$=$"1"{\textgreater}  {\textless}name{\textgreater}    {\textless}first{\textgreater}G.{\textless}/first{\textgreater}    {\textless}last{\textgreater}Healey{\textless}/last{\textgreater}  {\textless}/name{\textgreater}{\textless}/author{\textgreater}{\textless}author order$=$"2"{\textgreater}  {\textless}name{\textgreater}    {\textless}first{\textgreater}D.{\textless}/first{\textgreater}    {\textless}last{\textgreater}Slater{\textless}/last{\textgreater}  {\textless}/name{\textgreater}{\textless}/author{\textgreater}, J. Opt. Soc. Am. A11, 3003 (1994)\]. We apply this idea of sharpening to the set of principal components vectors derived from a representative set of spectra that might reasonably be encountered in a given application. With respect to the sharp spectral basis, we show that spectral multiplications can be modeled as the multiplication of the basis coefficients. These new product coefficients applied to the sharp basis serve to accurately reconstruct the spectral product. Although the method is quite general, we show how to use spectral modeling by taking advantage of metameric surfaces, ones that match under one light but not another, for tasks such as volume rendering. The use of metamers allows a user to pick out or merge different volume structures in real time simply by changing the lighting.}
}

@article{Lehtonen:06,
  author    = {Juha Lehtonen and Jussi Parkkinen and Timo Jaaskelainen},
  journal   = {Journal of the Optical Society of America},
  keywords  = {ABCD transforms ; Spectrum analysis; Continuous optical signal processing ; CIE color spaces; Color imaging; Color spaces; Discrete Fourier transforms; Fourier transforms; Light sources},
  number    = {12},
  pages     = {2983-2988},
  publisher = {OSA},
  title     = {Optimal sampling of color spectra},
  volume    = {23},
  month     = {12},
  year      = {2006},
  doi       = {10.1364/JOSAA.23.002983},
  abstract  = {We explain a method for calculating the optimal sampling interval of color spectra. The 1269 measured Munsell matt reflectance spectra set is used as the test set. The effect of light sources on the required sampling interval with different types of spectra is studied. It is shown that a 20 nm interval is enough for the smooth Munsell set alone, but 10 nm is not enough for the same set matched with a fluorescent light source. However, 5 nm is shown to be enough in most situations.}
}

@inproceedings{Evans:1999:10.20380/GI1999.07,
  author    = {Evans, Glenn F. and McCool, Michael D.},
  title     = {Stratified Wavelength Clusters for Efficient Spectral {M}onte {C}arlo Rendering},
  booktitle = {Proceedings of Graphics Interface '99},
  series    = {GI 1999},
  year      = {1999},
  month     = {6},
  issn      = {0713-5424},
  isbn      = {0-9695338-8-8},
  location  = {Kingston, Ontario, Canada},
  pages     = {42-49},
  numpages  = {8},
  doi       = {10.20380/GI1999.07},
  publisher = {Canadian Human-Computer Communications Society},
  address   = {Toronto, Ontario, Canada},
  url       = {http://graphicsinterface.org/wp-content/uploads/gi1999-7.pdf}
}

@article{10.1145/256157.256158,
  author     = {Walter, Bruce and Hubbard, Philip M. and Shirley, Peter and Greenberg, Donald P.},
  title      = {Global Illumination Using Local Linear Density Estimation},
  year       = {1997},
  issue_date = {July 1997},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {16},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/256157.256158},
  abstract   = {This article presents the density estimation framework for generating view-independent global illumination solutions. It works by probabilistically simulating the light flow in an environment with light particles that trace random walks origination at luminaires and then using statistical density estimation techniques to reconstruct the lighting on each surface. By splitting the computation into separate transport and reconstruction stages, we gain many advantages including reduced memory usage, the ability to simulate nondiffuse transport, and natural parallelism. Solutions to several theoretical and practical difficulties in implementing this framework are also described. Light sources that vary spectrally and directionally are integrated into a spectral particle tracer using  nonuniform rejection. A new local linear density estimation technique eliminates boundary bias and extends to arbitrary polygons. A mesh decimation algorithm with perceptual calibration is introduced to simplify the Gouraud-shaded representation of the solution for interactive display.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  pages      = {217-259},
  numpages   = {43},
  keywords   = {density estimation, realistic image synthesis, decimation, particle tracing, regression}
}

@inproceedings{Morley:2006:,
  author    = {Morley, Keith and Boulos, Solomon and Johnson, Jared and Edwards, David and Shirley, Peter and Ashikhmin, Michael and Premo{\v z}e, Simon},
  title     = {Image synthesis using adjoint photons},
  booktitle = {Proceedings of Graphics Interface 2006},
  series    = {GI 2006},
  year      = {2006},
  issn      = {0713-5424},
  isbn      = {1-56881-308-2},
  location  = {Qu{\'e}bec, Qu{\'e}bec, Canada},
  pages     = {179-186},
  numpages  = {8},
  publisher = {Canadian Human-Computer Communications Society},
  address   = {Toronto, Ontario, Canada}
}

@article{Radziszewski2009,
  author  = {Radziszewski, Michal and Boryczko, Krzysztof and Alda, Witold},
  journal = {Journal of WSCG {(JWSCG)}},
  number  = {1-3},
  title   = {An Improved Technique for Full Spectral Rendering},
  volume  = {17},
  year    = {2009},
  issn    = {1213-6972},
  editor  = {V{\'a}clav Skala},
  pages   = {9-16}
}

@article{10.1111/cgf.12419,
  author   = {Wilkie, Alexander and Nawaz, Sehera and Droske, Marc and Weidlich, Andrea and Hanika, Johannes},
  title    = {Hero Wavelength Spectral Sampling},
  journal  = {Computer Graphics Forum},
  volume   = {33},
  number   = {4},
  pages    = {123-131},
  keywords = {Categories and Subject Descriptors (according to ACM CCS), I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Color, shading, shadowing, and texture},
  doi      = {10.1111/cgf.12419},
  abstract = {Abstract We present a spectral rendering technique that offers a compelling set of advantages over existing approaches. The key idea is to propagate energy along paths for a small, constant number of changing wavelengths. The first of these, the hero wavelength, is randomly sampled for each path, and all directional sampling is solely based on it. The additional wavelengths are placed at equal distances from the hero wavelength, so that all path wavelengths together always evenly cover the visible range. A related technique, spectral multiple importance sampling, was already introduced a few years ago. We propose a simplified and optimised version of this approach which is easier to implement, has good performance characteristics, and is actually more powerful than the original method. Our proposed method is also superior to techniques which use a static spectral representation, as it does not suffer from any inherent representation bias. We demonstrate the performance of our method in several application areas that are of critical importance for production work, such as fidelity of colour reproduction, sub-surface scattering, dispersion and volumetric effects. We also discuss how to couple our proposed approach with several technologies that are important in current production systems, such as photon maps, bidirectional path tracing, environment maps, and participating media.},
  year     = {2014}
}

@article{31468,
  author  = {Glassner, Andrew S.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {How to derive a spectrum from an {RGB} triplet},
  year    = {1989},
  volume  = {9},
  number  = {4},
  pages   = {95-99},
  doi     = {10.1109/38.31468}
}

@article{10.1111/cgf.12676,
  author   = {Meng, Johannes and Simon, Florian and Hanika, Johannes and Dachsbacher, Carsten},
  title    = {Physically Meaningful Rendering using Tristimulus Colours},
  journal  = {Computer Graphics Forum},
  volume   = {34},
  number   = {4},
  pages    = {31-40},
  keywords = {Categories and Subject Descriptors (according to ACM CCS), Computer Graphics I.3.7: Three-Dimensional Graphics and Realism—Color, shading, shadowing, and texture},
  doi      = {10.1111/cgf.12676},
  abstract = {Abstract In photorealistic image synthesis the radiative transfer equation is often not solved by simulating every wavelength of light, but instead by computing tristimulus transport, for instance using sRGB primaries as a basis. This choice is convenient, because input texture data is usually stored in RGB colour spaces. However, there are problems with this approach which are often overlooked or ignored. By comparing to spectral reference renderings, we show how rendering in tristimulus colour spaces introduces colour shifts in indirect light, violation of energy conservation, and unexpected behaviour in participating media. Furthermore, we introduce a fast method to compute spectra from almost any given XYZ input colour. It creates spectra that match the input colour precisely. Additionally, like in natural reflectance spectra, their energy is smoothly distributed over wide wavelength bands. This method is both useful to upsample RGB input data when spectral transport is used and as an intermediate step for corrected tristimulus-based transport. Finally, we show how energy conservation can be enforced in RGB by mapping colours to valid reflectances.},
  year     = {2015}
}

@book{9100708,
  author  = {McCluney, William Ross},
  title   = {Introduction to Radiometry and Photometry},
  edition = {2},
  year    = {2014},
  isbn    = {9781608078332},
  pages   = {480}
}

@book{Nicodemus1977,
  author    = {Nicodemus, F. E. and Richmond, J. C. and Hsia, J. J. and Ginsberg, I. W. and Limperis, T.},
  title     = {Geometrical Considerations and Nomenclature for Reflectance},
  subtitle  = {NBS Monograph 160},
  year      = {1977},
  month     = {10},
  publisher = {National Bureau of Standards, U.S. Department of Commerce},
  address   = {Washington, D.C.},
  url       = {https://nvlpubs.nist.gov/nistpubs/Legacy/MONO/nbsmonograph160.pdf}
}

@book{Moon1936,
  author    = {Moon, Parry Hiram},
  publisher = {McGraw-Hill},
  title     = {The Scientific Basis of Illuminating Engineering},
  edition   = {1},
  year      = {1936},
  address   = {New York and London},
  url       = {https://archive.org/details/in.ernet.dli.2015.284487/page/n1/mode/2up?view=theater}
}

@book{Moon1948,
  author    = {Moon, Parry Hiram and Spencer, Domina Eberle},
  publisher = {Addison Wesley Press},
  title     = {Lighting Design},
  year      = {1948},
  address   = {Cambridge, Masschusetts}
}

@article{10.1002/sapm193918151,
  author  = {Gershun, A.},
  title   = {The Light Field},
  journal = {Journal of Mathematics and Physics},
  volume  = {18},
  number  = {1-4},
  pages   = {51-151},
  doi     = {10.1002/sapm193918151},
  year    = {1939}
}

@book{Lambert1760,
  author     = {Lambert, Johann Heinrich},
  publisher  = {The Illuminating Engineering Society of North America},
  title      = {Photometry, or, On the Measure and Gradations of Light, Colors, and Shade},
  year       = {1760},
  translator = {David L. Dilaura},
  note       = {in 2001}
}

@article{10.1111/j.1467-8659.2010.01722.x,
  author   = {Ou, Jiawei and Pellacini, Fabio},
  title    = {{S}afe{GI}: Type Checking to Improve Correctness in Rendering System Implementation},
  journal  = {Computer Graphics Forum},
  volume   = {29},
  number   = {4},
  pages    = {1269-1277},
  keywords = {I.3.2 Computer Graphics: Graphics Systems},
  doi      = {10.1111/j.1467-8659.2010.01722.x},
  abstract = {Abstract Historically, rendering system development has been mainly focused on improving the numerical accuracy of the rendering algorithms and their runtime efficiency. In this paper, we propose a method to improve the correctness not of the algorithms themselves, but of their implementation. Specifically, we show that by combining static type checking and generic programming, rendering system and shader development can take advantage of compile-time checking to perform dimensional analysis, i.e. to enforce the correctness of physical dimensions and units in light transport, and geometric space analysis, i.e. to ensure that geometric computations respect the spaces in which points, vectors and normals were defined. We demonstrate our methods by implementing a CPU path tracer and a GPU renderer which previews direct illumination. While we build on prior work to develop our implementations, the main contribution of our work is to show that dimensional analysis and geometric space checking can be successfully integrated into the development of rendering systems and shaders.},
  year     = {2010}
}

@book{978-7-5640-0658-7,
  author    = {金伟其 and 胡威捷},
  publisher = {北京理工大学出版社},
  title     = {辐射度 光度与色度及其测量},
  year      = {2006},
  isbn      = {978-7-5640-0658-7},
  address   = {北京},
  series    = {国防科工委“十五”规划教材.光学工程}
}

 @misc{wiki:solidangle,
  author = {维基百科},
  title  = {立體角 --- 维基百科{,} 自由的百科全书},
  year   = {2021},
  url    = {https://zh.wikipedia.org/w/index.php?title=%E7%AB%8B%E9%AB%94%E8%A7%92&oldid=68030781},
  note   = {[Online; accessed 17-December-2021]}
}

@techreport{GB3102.6-93,
  type        = {中华人民共和国国家标准},
  author      = {徐大刚 and 夏学江 and 麦伟麟},
  subtitle    = {GB 3102.6-93},
  title       = {光及有关电磁辐射的量和单位},
  date        = {1994-07-01},
  institution = {国家技术监督局},
  editor      = {全国量和单位标准化技术委员会第三分委员会},
  publisher   = {中国标准出版社},
  address     = {北京}
}

@misc{enwiki:1052681830,
  author = {{Wikipedia contributors}},
  title  = {Bidirectional reflectance distribution function --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2021},
  url    = {https://en.wikipedia.org/w/index.php?title=Bidirectional_reflectance_distribution_function&oldid=1052681830},
  note   = {[Online; accessed 17-December-2021]}
}

 @misc{wiki:candela,
  author = {维基百科},
  title  = {坎德拉 --- 维基百科{,} 自由的百科全书},
  year   = {2021},
  url    = {https://zh.wikipedia.org/w/index.php?title=%E5%9D%8E%E5%BE%B7%E6%8B%89&oldid=67519054},
  note   = {[Online; accessed 17-December-2021]}
}

@techreport{Hoffmann2015,
  author = {Gernot Hoffmann},
  title  = {{CIE} Color Space},
  year   = {2015},
  url    = {http://docs-hoffmann.de/ciexyz29082000.pdf}
}

 @misc{wiki:eye,
  author = {维基百科},
  title  = {眼 --- 维基百科{,} 自由的百科全书},
  year   = {2021},
  url    = {https://zh.wikipedia.org/w/index.php?title=%E7%9C%BC&oldid=67642524},
  note   = {[Online; accessed 19-December-2021]}
}

@incollection{SETCHELL2012219,
  title     = {8 - Colour description and communication},
  editor    = {Janet Best},
  booktitle = {Colour Design},
  publisher = {Woodhead Publishing},
  pages     = {219-253},
  year      = {2012},
  series    = {Woodhead Publishing Series in Textiles},
  isbn      = {978-1-84569-972-7},
  doi       = {10.1533/9780857095534.2.219},
  author    = {J.S. Setchell},
  keywords  = {colour communication, colour measurement, colour order systems, named colour, fluorescence},
  abstract  = {Abstract: This chapter discusses the problems involved with describing and communicating colour. Colour order systems, named colour systems, colour naming, and instrumental measurement of colour are then described, including conditions of illumination and viewing and the problem of fluorescence. Digital imaging systems and their need for colour management are described. A discussion of colour constancy, metamerism, and colour difference follows, with explanations of computation of colour co-ordinates, and derivation of the CIE Standard Observer providing more detail on these topics. A short section on future trends rounds out the discussion, and helpful sources of information are listed, followed by references.}
}

@incollection{BERTALMIO2020131,
  title     = {Chapter 6 - Colour representation and colour gamuts},
  editor    = {Marcelo Bertalmío},
  booktitle = {Vision Models for High Dynamic Range and Wide Colour Gamut Imaging},
  publisher = {Academic Press},
  pages     = {131-155},
  year      = {2020},
  series    = {Computer Vision and Pattern Recognition},
  isbn      = {978-0-12-813894-6},
  doi       = {10.1016/B978-0-12-813894-6.00011-9},
  author    = {Marcelo Bertalmío},
  keywords  = {Trichromacy, color spaces, color gamuts, brightness, hue, saturation},
  abstract  = {This chapter deals with colour. There are models that for simple stimuli in controlled environments can predict very accurately the colour appearance of objects, as well as the magnitude of their colour differences. These models were developed and validated for SDR images, and their extension to the HDR case is not straightforward. For the general case of natural images in arbitrary viewing conditions, there are many perceptual phenomena that come into play and no comprehensive vision model that is capable of handling them all in an effective way. As a result, the colour appearance problem remains very much open, and this affects all aspects of colour representation and processing.}
}

  @misc{enwiki:SRGB,
  author = {{Wikipedia contributors}},
  title  = {{SRGB} --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2021},
  url    = {https://en.wikipedia.org/w/index.php?title=SRGB&oldid=1059659271},
  note   = {[Online; accessed 22-December-2021]}
}

% 06
@inproceedings{10.1145/1461551.1461591,
  author    = {Sutherland, Ivan E.},
  title     = {Sketchpad: A Man-Machine Graphical Communication System},
  year      = {1963},
  isbn      = {9781450378802},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1461551.1461591},
  abstract  = {The Sketchpad system makes it possible for a man and a computer to converse rapidly through the medium of line drawings. Heretofore, most interaction between man and computers has been slowed down by the need to reduce all communication to written statements that can be typed; in the past, we have been writing letters to rather than conferring with our computers. For many types of communication, such as describing the shape of a mechanical part or the connections of an electrical circuit, typed statements can prove cumbersome. The Sketchpad system, by eliminating typed statements (except for legends) in favor of line drawings, opens up a new area of man-machine communication.},
  booktitle = {Proceedings of the May 21-23, 1963, Spring Joint Computer Conference},
  pages     = {329-346},
  numpages  = {18},
  location  = {Detroit, Michigan},
  series    = {AFIPS '63 (Spring)}
}

@book{10.1201/b22086,
  author    = {Tomas Akenine-Möller, Eric Haines, Naty Hoffman},
  publisher = {A. K. Peters/CRC Press},
  title     = {Real-Time Rendering},
  year      = {2018},
  edition   = {4},
  address   = {New York, USA},
  doi       = {10.1201/b22086},
  pages     = {1198},
  isbn      = {978-1-1386-2700-0}
}

@book{EBERLY2007,
  author    = {David H. Eberly},
  editor    = {David H. Eberly},
  title     = {3{D} Game Engine Design},
  edition   = {2},
  publisher = {Morgan Kaufmann},
  address   = {San Francisco},
  year      = {2007},
  series    = {The Morgan Kaufmann Series in Interactive 3D Technology},
  isbn      = {978-0-12-229063-3}
}

@article{4056910,
  author  = {Greene, Ned and Heckbert, Paul S.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical Weighted Average Filter},
  year    = {1986},
  volume  = {6},
  number  = {6},
  pages   = {21-27},
  doi     = {10.1109/MCG.1986.276738}
}

@incollection{KENTON1992288,
  title     = {VI.4 - A Panoramic Virtual Screen for Ray Tracing},
  editor    = {David Kirk},
  booktitle = {Graphics Gems III (IBM Version)},
  publisher = {Morgan Kaufmann},
  address   = {San Francisco},
  pages     = {288-294},
  year      = {1992},
  isbn      = {978-0-12-409673-8},
  doi       = {10.1016/B978-0-08-050755-2.50064-6},
  author    = {Musgrave F. Kenton},
  abstract  = {Publisher Summary 
               The standard imaging model used in ray tracing is that of a pinhole camera with a flat virtual screen. That model can be supplemented with a cylindrical virtual screen to obtain a 360°, or greater, lateral field of view. By using appropriate angular distribution of samples on the vertical axis, a 180° vertical field of view can be obtained as well. This chapter describes a scheme for sampling a virtual screen in such a way that the entire celestial sphere can be mapped onto a rectilinear image plane, with acceptable distortion. It discusses the construction of a panoramic virtual screen for ray tracing. That projection maps the entire view-dependent celestial sphere to a rectilinear screen. Introduction of distortion is unavoidable in that sphere-to-plane mapping; the distortion in that construction of the viewing projection is of a different character than that of a standard virtual screen, taking the form of horizontal stretching of the image as one approaches the poles of the sphere. The resulting panoramic images may be useful for interactive viewing of static imagery in a virtual reality system.}
}

@inproceedings{10.1145/800224.806818,
  author    = {Potmesil, Michael and Chakravarty, Indranil},
  title     = {A Lens and Aperture Camera Model for Synthetic Image Generation},
  year      = {1981},
  isbn      = {0897910451},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800224.806818},
  abstract  = {This paper extends the traditional pin-hole camera projection geometry, used in computer graphics, to a more realistic camera model which approximates the effects of a lens and an aperture function of an actual camera. This model allows the generation of synthetic images which have a depth of field, can be focused on an arbitrary plane, and also permits selective modeling of certain optical characteristics of a lens. The model can be expanded to include motion blur and special effect filters. These capabilities provide additional tools for highlighting important areas of a scene and for portraying certain physical characteristics of an object in an image.},
  booktitle = {Proceedings of the 8th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {297-305},
  numpages  = {9},
  keywords  = {Raster displays, Camera model, Computer graphics, Lens and aperture, Visible surface algorithms},
  location  = {Dallas, Texas, USA},
  series    = {SIGGRAPH '81}
}

@article{10.1145/357299.357300,
  author     = {Potmesil, Michael and Chakravarty, Indranil},
  title      = {Synthetic Image Generation with a Lens and Aperture Camera Model},
  year       = {1982},
  issue_date = {April 1982},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {2},
  issn       = {0730-0301},
  doi        = {10.1145/357299.357300},
  journal    = {ACM Trans. Graph.},
  month      = {4},
  pages      = {85-108},
  numpages   = {24},
  keywords   = {lens and aperture, defocused optical system, camera model, point-spread function}
}

@inproceedings{10.1145/800059.801169,
  author    = {Potmesil, Michael and Chakravarty, Indranil},
  title     = {Modeling Motion Blur in Computer-Generated Images},
  year      = {1983},
  isbn      = {0897911091},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800059.801169},
  abstract  = {This paper describes a procedure for modeling motion blur in computer-generated images. Motion blur in photography or cinematography is caused by the motion of objects during the finite exposure time the camera shutter remains open to record the image on film. In computer graphics, the simulation of motion blur is useful both in animated sequences where the blurring tends to remove temporal aliasing effects and in static images where it portrays the illusion of speed or movement among the objects in the scene.The camera model developed for simulating motion blur is described in terms of a generalized image-formation equation. This equation describes the relationship between the object and corresponding image points in terms of the optical system-transfer function. The use of the optical system-transfer function simplifies the description of time-dependent variations of object motion that may occur during the exposure time of a camera. This approach allows us to characterize the motion of objects by a set of system-transfer functions which are derived from the path and velocity of objects in the scene and the exposure time of a camera.},
  booktitle = {Proceedings of the 10th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {389-399},
  numpages  = {11},
  keywords  = {Image restoration, Camera model, Digital optics, Motion blur, Point-spread function},
  location  = {Detroit, Michigan, USA},
  series    = {SIGGRAPH '83}
}

@article{10.1145/7529.8927,
  author     = {Cook, Robert L.},
  title      = {Stochastic Sampling in Computer Graphics},
  year       = {1986},
  issue_date = {Jan. 1986},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {5},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/7529.8927},
  abstract   = {Ray tracing, ray casting, and other forms of point sampling are important techniques in computer graphics, but their usefulness has been undermined by aliasing artifacts. In this paper it is shown that these artifacts are not an inherent part of point sampling, but a consequence of using regularly spaced samples. If the samples occur at appropriate nonuniformly spaced locations, frequencies above the Nyquist limit do not alias, but instead appear as noise of the correct average intensity. This noise is much less objectionable to our visual system than aliasing. In ray tracing, the rays can be stochastically distributed to perform a Monte Carlo evaluation of integrals in the rendering equation. This is called distributed ray tracing and can be used to simulate motion blur, depth of field, penumbrae, gloss, and translucency.},
  journal    = {ACM Trans. Graph.},
  month      = {1},
  pages      = {51-72},
  numpages   = {22}
}

@inproceedings{10.2312:EGWR:EGSR07:121-126,
  booktitle = {Rendering Techniques},
  editor    = {Jan Kautz and Sumanta Pattanaik},
  title     = {General Linear Cameras with Finite Aperture},
  author    = {Adams, Andrew and Levoy, Marc},
  year      = {2007},
  publisher = {The Eurographics Association},
  issn      = {1727-3463},
  isbn      = {978-3-905673-52-4},
  doi       = {10.2312/EGWR/EGSR07/121-126}
}

@inproceedings{10.1145/218380.218463,
  author    = {Kolb, Craig and Mitchell, Don and Hanrahan, Pat},
  title     = {A Realistic Camera Model for Computer Graphics},
  year      = {1995},
  isbn      = {0897917014},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/218380.218463},
  booktitle = {Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {317-324},
  numpages  = {8},
  keywords  = {ray tracing, sampling, camera modeling, lens simulation},
  series    = {SIGGRAPH '95}
}

@article{10.1111/j.1467-8659.2011.01851.x,
  author   = {Steinert, B. and Dammertz, H. and Hanika, J. and Lensch, H. P. A.},
  title    = {General Spectral Camera Lens Simulation},
  journal  = {Computer Graphics Forum},
  volume   = {30},
  number   = {6},
  pages    = {1643-1654},
  keywords = {spectral light transport, diffraction, lens aberrations, I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Color, shading, shadowing, and texture},
  doi      = {10.1111/j.1467-8659.2011.01851.x},
  abstract = {Abstract We present a camera lens simulation model capable of producing advanced photographic phenomena in a general spectral Monte Carlo image rendering system. Our approach incorporates insights from geometrical diffraction theory, from optical engineering and from glass science. We show how to efficiently simulate all five monochromatic aberrations, spherical and coma aberration, astigmatism, field curvature and distortion. We also consider chromatic aberration, lateral colour and aperture diffraction. The inclusion of Fresnel reflection generates correct lens flares and we present an optimized sampling method for path generation.},
  year     = {2011}
}

@book{0321188780,
  author    = {Hecht, Eugene},
  publisher = {Addison-Wesley},
  title     = {Optics},
  year      = {2002},
  edition   = {4},
  isbn      = {0321188780}
}

@book{9780071476874,
  author    = {Smith, Warren J.},
  publisher = {McGraw-Hill Education},
  address   = {New York},
  title     = {Modern Optical Engineering: The Design of Optical Systems},
  year      = {2007},
  edition   = {4},
  isbn      = {9780071476874}
}

@article{10.1111/j.1467-8659.2012.03132.x,
  author   = {Hullin, Matthias B. and Hanika, Johannes and Heidrich, Wolfgang},
  title    = {Polynomial Optics: A Construction Kit for Efficient Ray-Tracing of Lens Systems},
  journal  = {Computer Graphics Forum},
  volume   = {31},
  number   = {4},
  pages    = {1375-1383},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing},
  doi      = {10.1111/j.1467-8659.2012.03132.x},
  abstract = {Abstract Simulation of light transport through lens systems plays an important role in graphics. While basic imaging properties can be conveniently derived from linear models (like ABCD matrices), these approximations fail to describe nonlinear effects and aberrations that arise in real optics. Such effects can be computed by proper ray tracing, for which, however, finding suitable sampling and filtering strategies is often not a trivial task. Inspired by aberration theory, which describes the deviation from the linear ray transfer in terms of wavefront distortions, we propose a ray-space formulation for nonlinear effects. In particular, we approximate the analytical solution to the ray tracing problem by means of a Taylor expansion in the ray parameters. This representation enables a construction-kit approach to complex optical systems in the spirit of matrix optics. It is also very simple to evaluate, which allows for efficient execution on CPU and GPU alike, including the computation of mixed derivatives of any order. We evaluate fidelity and performance of our polynomial model, and show applications in high-quality offline rendering and at interactive frame rates.},
  year     = {2012}
}

@article{10.1111/cgf.12301,
  author   = {Hanika, Johannes and Dachsbacher, Carsten},
  title    = {Efficient {M}onte {C}arlo rendering with realistic lenses},
  journal  = {Computer Graphics Forum},
  volume   = {33},
  number   = {2},
  pages    = {323-332},
  keywords = {Categories and Subject Descriptors (according to ACM CCS):, I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing},
  doi      = {10.1111/cgf.12301},
  abstract = {Abstract In this paper we present a novel approach to simulate image formation for a wide range of real world lenses in the Monte Carlo ray tracing framework. Our approach sidesteps the overhead of tracing rays through a system of lenses and requires no tabulation. To this end we first improve the precision of polynomial optics to closely match ground-truth ray tracing. Second, we show how the Jacobian of the optical system enables efficient importance sampling, which is crucial for difficult paths such as sampling the aperture which is hidden behind lenses on both sides. Our results show that this yields converged images significantly faster than previous methods and accurately renders complex lens systems with negligible overhead compared to simple models, e.g. the thin lens model. We demonstrate the practicality of our method by incorporating it into a bidirectional path tracing framework and show how it can provide information needed for sophisticated light transport algorithms.},
  year     = {2014}
}

@article{5280315,
  author  = {Chen, Junqing and Venkataraman, Kartik and Bakin, Dmitry and Rodricks, Brian and Gravelle, Robert and Rao, Pravin and Ni, Yongshen},
  journal = {IEEE Transactions on Electron Devices},
  title   = {Digital Camera Imaging System Simulation},
  year    = {2009},
  volume  = {56},
  number  = {11},
  pages   = {2496-2505},
  doi     = {10.1109/TED.2009.2030995}
}

@article{761554,
  author  = {Glassner, Andrew S.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {An open and shut case},
  year    = {1999},
  volume  = {19},
  number  = {3},
  pages   = {82-92},
  doi     = {10.1109/38.761554}
}

@article{10.1080/2151237X.2007.10129235,
  author    = {Ian Stephenson},
  title     = {Improving Motion Blur: Shutter Efficiency and Temporal Sampling},
  journal   = {Journal of Graphics Tools},
  volume    = {12},
  number    = {1},
  pages     = {9-15},
  year      = {2007},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2007.10129235}
}

@inproceedings{10.1145/1242073.1242155,
  author    = {Buhler, Juan and Wexler, Dan},
  title     = {A Phenomenological Model for Bokeh Rendering},
  year      = {2002},
  isbn      = {1581135254},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1242073.1242155},
  abstract  = {"Bokeh" is a Japanese word used to describe the quality of the out-of-focus areas as rendered on film by a physical lens. In areas that are out of focus, the circle of confusion (i.e., the distribution of light absorbed onto film from a single point of light in the scene) is bigger than in areas that are focused. Different lenses distribute light within the circle of confusion differently, depending on a number of factors, like the shape and number of diaphragm blades and the optical design of the lens itself. For example, lenses that are designed to correct for optical aberrations tend to render a circle of confusion that is more intense on the edges and slightly less so in the center. Other lenses, like the so called "mirror" lenses, which include reflective elements besides refractive ones, typically produce donut-shaped circles of confusion since some of the light paths are cut from the center by the reflective element.Moreover, in a real lens the circle of confusion sometimes becomes elliptical on the areas outside of the center of the image, with the shorter axis of the ellipsis oriented radially from it.Standard rendering techniques model depth of field using point sampling techniques which converge towards a bokeh model with uniform density across the circle of confusion. This represents an idealized lens that does not exist in reality. Real lenses have non-uniform bokeh distributions. For example, a smooth, or "creamy" lens will have a Gaussian distribution across the circle of confusion. Real lenses may have different distributions at different points on the film plane.Our technique allows the animator to specify an arbitrary probability density function to represent the distribution of intensity within the circle of confusion. The probability curve is used by the renderer to jitter the location of the sample point on the lens. For example, if the density function is a Gaussian, more samples will be taken towards the center of the lens than at the edges. Conversely, for a density function that simulates a mirror lens, fewer samples are taken near the center of the lens because the mirror blocks light as it moves through the lens. By generating enough sample points, the model converges on the true bokeh density function.We will also show the effect of specifying two shapes for the light distribution, one for close and the other for far focused areas, and the deformation of the circle of confusion so it becomes elliptical on the edges of the image.Future work includes the specification of the diaphragm shape, and the possible implementation of this technique as a particle renderer, which would provide efficient sampling at a much lower cost.Additional work to add support for stratified sampling is also possible.},
  booktitle = {ACM SIGGRAPH 2002 Conference Abstracts and Applications},
  pages     = {142},
  numpages  = {1},
  location  = {San Antonio, Texas},
  series    = {SIGGRAPH '02}
}

@article{5740919,
  author  = {Hasinoff, Samuel W. and Kutulakos, Kiriakos N.},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Light-Efficient Photography},
  year    = {2011},
  volume  = {33},
  number  = {11},
  pages   = {2203-2214},
  doi     = {10.1109/TPAMI.2011.62}
}

@techreport{Jacobs2012,
  author      = {Jacobs, David E. and	Baek, Jongmin and Levoy, Marc },
  title       = {Focal Stack Compositing for Depth of Field Control},
  institution = {Stanford University},
  year        = {2012},
  month       = {10},
  series      = {Stanford Computer Graphics Laboratory Technical Report 2012-1}
}

@techreport{ng:hal-02551481,
  title       = {Light Field Photography with a Hand-held Plenoptic Camera},
  author      = {Ng, Ren and Levoy, Marc and Br{\'e}dif, Mathieu and Duval, Gene and Horowitz, Mark and Hanrahan, Pat},
  type        = {Research Report},
  number      = {CSTR 2005-02},
  pages       = {Stanford University Computer Science Tech Report},
  institution = {Stanford University},
  year        = {2005},
  month       = {4},
  keywords    = {Digital photography; light field; microlens array; synthetic photography; refocusing},
  url         = {https://hal.archives-ouvertes.fr/hal-02551481/file/lfcamera-150dpi.pdf}
}

@book{hecht2016optics,
  author    = {Hecht, Eugene},
  publisher = {Pearson Education},
  title     = {Optics},
  year      = {2016},
  edition   = {5th global edition},
  isbn      = {9781292096933}
}

# 7.1.7
@techreport{Smith95apixel,
  author      = {Alvy Ray Smith},
  title       = {A Pixel Is Not A Little Square, A Pixel Is Not A Little Square, A Pixel Is Not A Little Square! (And a Voxel is Not a Little Cube)},
  institution = {Technical Memo 6, Microsoft Research},
  year        = {1995},
  url         = {http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf}
}

@incollection{HECKBERT1990246,
  title     = {What are the Coordinates of a Pixel?},
  editor    = {Andrew S. Glassner},
  booktitle = {Graphics Gems},
  publisher = {Morgan Kaufmann},
  address   = {San Diego},
  pages     = {246-248},
  year      = {1990},
  isbn      = {978-0-08-050753-8},
  doi       = {10.1016/B978-0-08-050753-8.50053-X},
  author    = {Paul S. Heckbert}
}

# 7.4.1
@book{10.5555/2462741,
  author    = {Warren, Henry S.},
  title     = {Hacker's Delight},
  year      = {2012},
  isbn      = {0321842685},
  publisher = {Addison-Wesley Professional},
  edition   = {2},
  abstract  = {In Hackers Delight, Second Edition, Hank Warren once again compiles an irresistible collection of programming hacks: timesaving techniques, algorithms, and tricks that help programmers build more elegant and efficient software, while also gaining deeper insights into their craft. Warrens hacks are eminently practical, but theyre also intrinsically interesting, and sometimes unexpected, much like the solution to a great puzzle. They are, in a word, a delight to any programmer who is excited by the opportunity to improve. Extensive additions in this edition include A new chapter on cyclic redundancy checking (CRC), including routines for the commonly used CRC-32 code A new chapter on error correcting codes (ECC), including routines for the Hamming code More coverage of integer division by constants, including methods using only shifts and adds Computing remainders without computing a quotient More coverage of population count and counting leading zeros Array population count New algorithms for compress and expand An LRU algorithm Floating-point to/from integer conversions Approximate floating-point reciprocal square root routine A gallery of graphs of discrete functions Now with exercises and answers}
}

@inproceedings{10.1007/978-3-642-04107-5_25,
  author    = {Gr\"{u}nschlo\ss{}, Leonhard and Keller, Alexander},
  editor    = {L' Ecuyer, Pierre and Owen, Art B.},
  title     = {(t,m,s)-Nets and Maximized Minimum Distance, Part II},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2008},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {395-409},
  abstract  = {The quality parameter t of (t,m,s)-nets controls extensive stratification properties of the generated sample points. However, the definition allows for points that are arbitrarily close across strata boundaries. We continue the investigation of (t,m,s)-nets under the constraint of maximizing the mutual distance of the points on the unit torus and present two new constructions along with algorithms. The first approach is based on the fact that reordering (t,s)-sequences can result in (t,m,s+1)-nets with varying toroidal distance, while the second algorithm generates points by permutations instead of matrices.},
  isbn      = {978-3-642-04107-5}
}

@article{LARCHER2016546,
  title    = {On the discrepancy of sequences in the unit-interval},
  journal  = {Indagationes Mathematicae},
  volume   = {27},
  number   = {2},
  pages    = {546-558},
  year     = {2016},
  note     = {In Memoriam J.G. Van der Corput (1890-1975) Part 2},
  issn     = {0019-3577},
  doi      = {10.1016/j.indag.2015.11.003},
  author   = {Gerhard Larcher},
  keywords = {Discrepancy, Uniform distribution of sequences},
  abstract = {In the first part of this paper we give an overview on known general bounds for the most important types of discrepancies of sequences in the unit-interval. It is pointed out that for all these types the van der Corput sequence, or a variant of it, provides an example with lowest possible order of discrepancy. In the second part we slightly improve the until now best known lower bound for the one-dimensional discrepancy constant with respect to extreme discrepancy given by R. Béjian in 1982.}
}

# 7.5
@article{10.1111/1467-8659.00706,
  author   = {Kollig, Thomas and Keller, Alexander},
  title    = {Efficient Multidimensional Sampling},
  journal  = {Computer Graphics Forum},
  volume   = {21},
  number   = {3},
  pages    = {557-563},
  doi      = {10.1111/1467-8659.00706},
  abstract = {Abstract Image synthesis often requires the Monte Carlo estimation of integrals. Based on a generalized concept of stratification we present an efficient sampling scheme that consistently outperforms previous techniques. This is achieved by assembling sampling patterns that are stratified in the sense of jittered sampling and N-rooks sampling at the same time. The faster convergence and improved anti-aliasing are demonstrated by numerical experiments. Categories and Subject Descriptors (according to ACM CCS): G.3 [Probability and Statistics]: Probabilistic Algorithms (including Monte Carlo); I.3.2 [Computer Graphics]: Picture/Image Generation; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism.},
  year     = {2002}
}

# 7.8
@article{843002,
  author  = {Unser, Michael},
  journal = {Proceedings of the IEEE},
  title   = {Sampling-50 years after {S}hannon},
  year    = {2000},
  volume  = {88},
  number  = {4},
  pages   = {569-587},
  doi     = {10.1109/5.843002}
}

@inproceedings{10.1145/54852.378514,
  author    = {Mitchell, Don P. and Netravali, Arun N.},
  title     = {Reconstruction Filters in Computer-Graphics},
  year      = {1988},
  isbn      = {0897912756},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/54852.378514},
  abstract  = {Problems of signal processing arise in image synthesis because of transformations between continuous and discrete representations of 2D images. Aliasing introduced by sampling has received much attention in graphics, but reconstruction of samples into a continuous representation can also cause aliasing as well as other defects in image quality. The problem of designing a filter for use on images is discussed, and a new family of piecewise cubic filters are investigated as a practical demonstration. Two interesting cubic filters are found, one having good antialiasing properties and the other having good image-quality properties. It is also shown that reconstruction using derivative as well as amplitude values can greatly reduce aliasing.},
  booktitle = {Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {221-228},
  numpages  = {8},
  keywords  = {cubic filters, antialiasing, sampling, reconstruction, filters, derivative reconstruction},
  series    = {SIGGRAPH '88}
}

# 7.10
@book{91250711,
  title     = {The {F}ourier Transform and Its Applications},
  author    = {Bracewell, Ronald N.},
  publisher = {McGraw Hill},
  isbn      = {9780071160438; 0071160434; 0073039381; 9780073039381},
  year      = {2000},
  edition   = {3},
  address   = {New York}
}

@article{993400,
  author  = {Meijering, Erik H. W.},
  journal = {Proceedings of the IEEE},
  title   = {A chronology of interpolation: from ancient astronomy to modern signal and image processing},
  year    = {2002},
  volume  = {90},
  number  = {3},
  pages   = {319-342},
  doi     = {10.1109/5.993400}
}

@article{4815542,
  author  = {Eldar, Yonina C. and Michaeli, Tomer},
  journal = {IEEE Signal Processing Magazine},
  title   = {Beyond bandlimited sampling},
  year    = {2009},
  volume  = {26},
  number  = {3},
  pages   = {48-68},
  doi     = {10.1109/MSP.2009.932125}
}

@article{10.1145/359863.359869,
  author     = {Crow, Franklin C.},
  title      = {The Aliasing Problem in Computer-Generated Shaded Images},
  year       = {1977},
  issue_date = {Nov. 1977},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {20},
  number     = {11},
  issn       = {0001-0782},
  doi        = {10.1145/359863.359869},
  abstract   = {Certain defects, such as jagged edges and disappearing detail, have long been an annoyance in digitally generated shaded images. Although increasing the resolution or defocusing the display can attenuate them, an understanding of these defects leads to more effective methods. This paper explains the observed defects in terms of the aliasing phenomenon inherent in sampled signals and discusses prefiltering as a recognized cure. A method for evaluating filters is presented, the application of prefiltering to hidden-surface algorithms is discussed, and an implementation of a filtering tiler is shown accompanied by examples of its effectiveness.},
  journal    = {Commun. ACM},
  month      = {11},
  pages      = {799-805},
  numpages   = {7},
  keywords   = {aliasing, hidden-surface removal, sampling, convolutional filtering, computer graphics}
}

@inproceedings{10.1145/325334.325182,
  author    = {Dipp\'{e}, Mark A. Z. and Wold, Erling Henry},
  title     = {Antialiasing through Stochastic Sampling},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325182},
  abstract  = {Stochastic sampling techniques, in particular Poisson and fittered sampling, are developed and analyzed. These approaches allow the construction of alias-free approximations to continuous functions using discrete calculations. Stochastic sampling scatters high frequency information into broadband noise rather than generating the false patterne produced by regular sampling. The type of randomness used in the sampling process controls the spectral character of the noise. The average sampling rate and the function being sampled determine the amount of noise that is produced. Stochastic sampling is applied adaptively so that a greater number of samples are taken where the function varies most. An estimate is used to determine how many samples to take over a given region. Noise reducing filters are used to increase the efficacy of a given sampling rate. The filter width is adaptively controlled to further improve performance. Stochastic sampling can be applied spatiotemporally as well as to other aspects of scene simulation. Ray tracing is one example of an image synthesis approach that can be antialiased by stochastic sampling.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {69-78},
  numpages  = {10},
  keywords  = {ray tracing, antialiasing, aliasing, filtering, adaptive, stochastic sampling, noise},
  series    = {SIGGRAPH '85}
}

@article{10.1126/science.6867716,
  author   = {John I. Yellott},
  title    = {Spectral Consequences of Photoreceptor Sampling in the Rhesus Retina},
  journal  = {Science},
  volume   = {221},
  number   = {4608},
  pages    = {382-385},
  year     = {1983},
  doi      = {10.1126/science.6867716},
  abstract = {Optical transforms were used to compute the power spectra of rhesus cones treated as arrays of image sampling points. Spectra were obtained for the central fovea, parafovea, periphery, and far periphery. All were consistent with a novel spatial sampling principle that introduces minimal noise for spatial frequencies below the Nyquist limits implied by local receptor densities, while frequencies above the nominal Nyquist limits are not converted into conspicuous moire patterns, but instead are scattered into broadband noise. This sampling scheme allows the visual system to escape aliasing distortion despite a large mismatch between retinal image bandwidth and the Nyquist limits implied by extrafoveal cone densities.}
}

@inproceedings{10.1145/325334.325179,
  author    = {Lee, Mark E. and Redner, Richard A. and Uselton, Samuel P.},
  title     = {Statistically Optimized Sampling for Distributed Ray Tracing},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325179},
  abstract  = {Cook, Porter, and Carpenter coined the phrase "distributed ray tracing" to describe a technique for using each ray of a super-sampled ray tracing procedure as a sample in several dimensions to achieve effects such as penumbras and motion blur in addition to spatial anti-aliasing. The shade to be displayed at a pixel is a weighted integral of the image function. The purpose of using many rays per pixel is to estimate the value of this integral. In this work, a relationship between the number of sample rays and the quality of the estimate of this integral is derived. Furthermore, the number of rays required does not depend on the dimensionality of the space being sampled, but only on the variance of the multi-dimensional image function. The algorithm has been optimized through the use of statistical testing and stratified sampling.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {61-68},
  numpages  = {8},
  keywords  = {shadows, ray tracing, transparency, penumbras, translucency, anti-aliasing},
  series    = {SIGGRAPH '85}
}

@inproceedings{10.1145/37401.37410,
  author    = {Mitchell, Don P.},
  title     = {Generating Antialiased Images at Low Sampling Densities},
  year      = {1987},
  isbn      = {0897912276},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/37401.37410},
  abstract  = {Ray tracing produces point samples of an image from a 3-D model. Constructing an antialiased digital picture from point samples is difficult without resorting to extremely high sampling densities. This paper describes a program that focuses on that problem. While it is impossible to eliminate aliasing totally, it has been shown that nonuniform sampling yields aliasing that is less conspicuous to the observer. An algorithm is presented for fast generation of nonuniform sampling patterns that are optimal in some sense. Some regions of an image may require extra sampling to avoid strong aliasing. Deciding where to do extra sampling can be guided by knowledge of how the eye perceives noise as a function of contrast and color. Finally, to generate the digital picture, the image must be reconstructed from the samples and resampled at the display pixel rate. The nonuniformity of the samples complicates this process, and a new nonuniform reconstruction filter is presented which solves this problem efficiently.},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {65-72},
  numpages  = {8},
  series    = {SIGGRAPH '87}
}

@inproceedings{10.1145/122718.122736,
  author    = {Mitchell, Don P.},
  title     = {Spectrally Optimal Sampling for Distribution Ray Tracing},
  year      = {1991},
  isbn      = {0897914368},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/122718.122736},
  abstract  = {Nonuniform sampling of images is a useful technique in computer graphics, because a properly designed pattern of samples can make aliasing take the form of high-frequency random noise. In this paper, the technique of nonuniform sampling is extended from two dimensions to include the extra parameter dimensions of distribution ray tracing. A condition for optimality is suggested, and algorithms for approximating optimal sampling are developed. The technique is demonstrated at low sampling densities, so the characteristics of aliasing noise are clearly visible. At supersampling rates, this technique should move noise into frequencies above the passband of the pixel-reconstruction filter.},
  booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {157-164},
  numpages  = {8},
  keywords  = {noise perception, nonuniform sampling, distribution Ray tracing, antialiasing},
  series    = {SIGGRAPH '91}
}

@inproceedings{10.1145/237170.237265,
  author    = {Mitchell, Don P.},
  title     = {Consequences of Stratified Sampling in Graphics},
  year      = {1996},
  isbn      = {0897917464},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/237170.237265},
  booktitle = {Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {277-280},
  numpages  = {4},
  keywords  = {variance reduction, antialiasing, discrepancy, sampling, stratification},
  series    = {SIGGRAPH '96}
}
@incollection{CHIU1994370,
  title     = {V.4. - Multi-Jittered Sampling},
  editor    = {Paul S. Heckbert},
  booktitle = {Graphics Gems},
  publisher = {Academic Press},
  pages     = {370-374},
  year      = {1994},
  isbn      = {978-0-12-336156-1},
  doi       = {10.1016/B978-0-12-336156-1.50045-8},
  author    = {Kenneth Chiu and Changyaw Wang and Peter Shirley},
  abstract  = {Jittered sampling patterns perform better than random sampling patterns because they limit the degree of clumping that can occur. Clumping can still be present in one-dimensional projections of jittered patterns, however. We present a simple method to reduce the clumping of the X-axis and Y-axis projections by imposing an additional N-rooks constraint on the jittered sampling pattern. The resulting sampling pattern can reduce the number of rays necessary for a satisfactory image when ray-tracing.}
}

@manual{Kensler2013Pixar,
  author = {Andrew Kensler},
  title  = {Correlated Multi-Jittered Sampling},
  year   = {2013},
  url    = {https://graphics.pixar.com/library/MultiJitteredSampling},
  note   = {Pixar Technical Memo},
  number = {13-01}
}

@article{10.1111/j.1467-8659.2007.01100.x,
  author   = {Lagae, Ares and Dutré, Philip},
  title    = {A Comparison of Methods for Generating Poisson Disk Distributions},
  journal  = {Computer Graphics Forum},
  volume   = {27},
  number   = {1},
  pages    = {114-129},
  keywords = {Poisson disk distributions, spectral analysis, I.3.3 Computer Graphics: Picture/Image Generation},
  doi      = {10.1111/j.1467-8659.2007.01100.x},
  abstract = {Abstract Poisson disk distributions have many applications in the field of computer graphics. Besides sampling, Poisson disk distributions are used in object distribution, non-photorealistic rendering and procedural texturing. Over the years, a large number of methods for generating Poisson disk distributions have been proposed, making it difficult to choose the right method for a given application. In this paper, we present a detailed comparison of most techniques for generating Poisson disk distributions. The methods we study include dart throwing, relaxation dart throwing, Lloyd's relaxation, Shade's Poisson disk tiles, tiled blue noise samples, fast hierarchical importance sampling with blue noise properties, edge-based Poisson disk tiles, template Poisson disk tiles, corner-based Poisson disk tiles and recursive Wang tiles for real-time blue noise. Analysing all of these methods within a single framework is one of the major contributions of this work.},
  year     = {2008}
}

@article{10.1080/2151237X.2006.10129217,
  author    = {Thouis R. Jones},
  title     = {Efficient Generation of Poisson-Disk Sampling Patterns},
  journal   = {Journal of Graphics Tools},
  volume    = {11},
  number    = {2},
  pages     = {27-36},
  year      = {2006},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/2151237X.2006.10129217}
}

@inproceedings{10.1145/1179352.1141915,
  author    = {Dunbar, Daniel and Humphreys, Greg},
  title     = {A Spatial Data Structure for Fast Poisson-Disk Sample Generation},
  year      = {2006},
  isbn      = {1595933646},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1179352.1141915},
  abstract  = {Sampling distributions with blue noise characteristics are widely used in computer graphics. Although Poisson-disk distributions are known to have excellent blue noise characteristics, they are generally regarded as too computationally expensive to generate in real time. We present a new method for sampling by dart-throwing in O(N log N) time and introduce a novel and efficient variation for generating Poisson-disk distributions in O(N) time and space.},
  booktitle = {ACM SIGGRAPH 2006 Papers},
  pages     = {503-508},
  numpages  = {6},
  keywords  = {Poisson disk, blue noise, sampling},
  location  = {Boston, Massachusetts},
  series    = {SIGGRAPH '06}
}

@inproceedings{10.1145/1399504.1360619,
  author    = {Wei, Li-Yi},
  title     = {Parallel Poisson Disk Sampling},
  year      = {2008},
  isbn      = {9781450301121},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1399504.1360619},
  abstract  = {Sampling is important for a variety of graphics applications include rendering, imaging, and geometry processing. However, producing sample sets with desired efficiency and blue noise statistics has been a major challenge, as existing methods are either sequential with limited speed, or are parallel but only through pre-computed datasets and thus fall short in producing samples with blue noise statistics. We present a Poisson disk sampling algorithm that runs in parallel and produces all samples on the fly with desired blue noise properties. Our main idea is to subdivide the sample domain into grid cells and we draw samples concurrently from multiple cells that are sufficiently far apart so that their samples cannot conflict one another. We present a parallel implementation of our algorithm running on a GPU with constant cost per sample and constant number of computation passes for a target number of samples. Our algorithm also works in arbitrary dimension, and allows adaptive sampling from a user-specified importance field. Furthermore, our algorithm is simple and easy to implement, and runs faster than existing techniques.},
  booktitle = {ACM SIGGRAPH 2008 Papers},
  articleno = {20},
  numpages  = {9},
  keywords  = {sampling, GPU techniques, Poisson disk, parallel computation, blue noise, texture synthesis},
  location  = {Los Angeles, California},
  series    = {SIGGRAPH '08}
}

@inproceedings{10.1145/1866158.1866189,
  author    = {Li, Hongwei and Wei, Li-Yi and Sander, Pedro V. and Fu, Chi-Wing},
  title     = {Anisotropic Blue Noise Sampling},
  year      = {2010},
  isbn      = {9781450304399},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1866158.1866189},
  abstract  = {Blue noise sampling is widely employed for a variety of imaging, geometry, and rendering applications. However, existing research so far has focused mainly on isotropic sampling, and challenges remain for the anisotropic scenario both in sample generation and quality verification. We present anisotropic blue noise sampling to address these issues. On the generation side, we extend dart throwing and relaxation, the two classical methods for isotropic blue noise sampling, for the anisotropic setting, while ensuring both high-quality results and efficient computation. On the verification side, although Fourier spectrum analysis has been one of the most powerful and widely adopted tools, so far it has been applied only to uniform isotropic samples. We introduce approaches based on warping and sphere sampling that allow us to extend Fourier spectrum analysis for adaptive and/or anisotropic samples; thus, we can detect problems in alternative anisotropic sampling techniques that were not yet found via prior verification. We present several applications of our technique, including stippling, visualization, surface texturing, and object distribution.},
  booktitle = {ACM SIGGRAPH Asia 2010 Papers},
  articleno = {167},
  numpages  = {12},
  keywords  = {relaxation, dart throwing, stippling, blue noise sampling, anisotropy, texturing, spectrum analysis, rendering},
  location  = {Seoul, South Korea},
  series    = {SIGGRAPH ASIA '10}
}

@inproceedings{10.1145/1964921.1964944,
  author    = {Ebeida, Mohamed S. and Davidson, Andrew A. and Patney, Anjul and Knupp, Patrick M. and Mitchell, Scott A. and Owens, John D.},
  title     = {Efficient Maximal Poisson-Disk Sampling},
  year      = {2011},
  isbn      = {9781450309431},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1964921.1964944},
  abstract  = {We solve the problem of generating a uniform Poisson-disk sampling that is both maximal and unbiased over bounded non-convex domains. To our knowledge this is the first provably correct algorithm with time and space dependent only on the number of points produced. Our method has two phases, both based on classical dart-throwing. The first phase uses a background grid of square cells to rapidly create an unbiased, near-maximal covering of the domain. The second phase completes the maximal covering by calculating the connected components of the remaining uncovered voids, and by using their geometry to efficiently place unbiased samples that cover them. The second phase converges quickly, overcoming a common difficulty in dart-throwing methods. The deterministic memory is O(n) and the expected running time is O(n log n), where n is the output size, the number of points in the final sample. Our serial implementation verifies that the log n dependence is minor, and nearly O(n) performance for both time and memory is achieved in practice. We also present a parallel implementation on GPUs to demonstrate the parallel-friendly nature of our method, which achieves 2.4x the performance of our serial version.},
  booktitle = {ACM SIGGRAPH 2011 Papers},
  articleno = {49},
  numpages  = {12},
  keywords  = {linear complexity, sampling, maximal, Poisson disk, blue noise, provable convergence},
  location  = {Vancouver, British Columbia, Canada},
  series    = {SIGGRAPH '11}
}

@article{10.1111/j.1467-8659.2012.03059.x,
  author   = {Ebeida, Mohamed S. and Mitchell, Scott A. and Patney, Anjul and Davidson, Andrew A. and Owens, John D.},
  title    = {A Simple Algorithm for Maximal Poisson-Disk Sampling in High Dimensions},
  journal  = {Computer Graphics Forum},
  volume   = {31},
  number   = {2pt4},
  pages    = {785-794},
  keywords = {Computing Methodologies I.3.5: Computer Graphics—Computational Geometry and Object Modeling},
  doi      = {10.1111/j.1467-8659.2012.03059.x},
  abstract = {Abstract We provide a simple algorithm and data structures for d-dimensional unbiased maximal Poisson-disk sampling. We use an order of magnitude less memory and time than the alternatives. Our results become more favorable as the dimension increases. This allows us to produce bigger samplings. Domains may be non-convex with holes. The generated point cloud is maximal up to round-off error. The serial algorithm is provably bias-free. For an output sampling of size n in fixed dimension d, we use a linear memory budget and empirical θ(n) runtime. No known methods scale well with dimension, due to the “curse of dimensionality.” The serial algorithm is practical in dimensions up to 5, and has been demonstrated in 6d. We have efficient GPU implementations in 2d and 3d. The algorithm proceeds through a finite sequence of uniform grids. The grids guide the dart throwing and track the remaining disk-free area. The top-level grid provides an efficient way to test if a candidate dart is disk-free. Our uniform grids are like quadtrees, except we delay splits and refine all leaves at once. Since the quadtree is flat it can be represented using very little memory: we just need the indices of the active leaves and a global level. Also it is very simple to sample from leaves with uniform probability.},
  year     = {2012}
}

@article{10.1111/cgf.12725,
  author   = {Reinert, Bernhard and Ritschel, Tobias and Seidel, Hans-Peter and Georgiev, Iliyan},
  title    = {Projective Blue-Noise Sampling},
  journal  = {Computer Graphics Forum},
  volume   = {35},
  number   = {1},
  pages    = {285-295},
  keywords = {sampling, blue-noise, Monte Carlo rendering, image reconstruction, primitive placement, I.3.3 Computer Graphics: Picture/Image Generation—Antialiasing; I.4.1 Image Processing and Computer Vision: Digitization and Image Capture—Sampling},
  doi      = {10.1111/cgf.12725},
  abstract = {Abstract We propose projective blue-noise patterns that retain their blue-noise characteristics when undergoing one or multiple projections onto lower dimensional subspaces. These patterns are produced by extending existing methods, such as dart throwing and Lloyd relaxation, and have a range of applications. For numerical integration, our patterns often outperform state-of-the-art stochastic and low-discrepancy patterns, which have been specifically designed only for this purpose. For image reconstruction, our method outperforms traditional blue-noise sampling when the variation in the signal is concentrated along one dimension. Finally, we use our patterns to distribute primitives uniformly in 3D space such that their 2D projections retain a blue-noise distribution.},
  year     = {2016}
}

@article{PURGATHOFER1987157,
  title    = {A statistical method for adaptive stochastic sampling},
  journal  = {Computers \& Graphics},
  volume   = {11},
  number   = {2},
  pages    = {157-162},
  year     = {1987},
  issn     = {0097-8493},
  doi      = {10.1016/0097-8493(87)90029-X},
  author   = {Werner Purgathofer},
  abstract = {Stochastic sampling is a good alternative to pure oversampling in terms of image quality. A method for adaptively controlling the number of required samples to the complexity of the picture is presented. The quality of the obtained picture can be controlled by two well-understandable parameters, these parameters define an error interval size and the probability that a pixel lies within it. The usefulness of the method is described by applying it to distributed ray-tracing.}
}

@article{10.1145/1360612.1360632,
  author     = {Hachisuka, Toshiya and Jarosz, Wojciech and Weistroffer, Richard Peter and Dale, Kevin and Humphreys, Greg and Zwicker, Matthias and Jensen, Henrik Wann},
  title      = {Multidimensional Adaptive Sampling and Reconstruction for Ray Tracing},
  year       = {2008},
  issue_date = {August 2008},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {27},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/1360612.1360632},
  abstract   = {We present a new adaptive sampling strategy for ray tracing. Our technique is specifically designed to handle multidimensional sample domains, and it is well suited for efficiently generating images with effects such as soft shadows, motion blur, and depth of field. These effects are problematic for existing image based adaptive sampling techniques as they operate on pixels, which are possibly noisy results of a Monte Carlo ray tracing process. Our sampling technique operates on samples in the multidimensional space given by the rendering equation and as a consequence the value of each sample is noise-free. Our algorithm consists of two passes. In the first pass we adaptively generate samples in the multidimensional space, focusing on regions where the local contrast between samples is high. In the second pass we reconstruct the image by integrating the multidimensional function along all but the image dimensions. We perform a high quality anisotropic reconstruction by determining the extent of each sample in the multidimensional space using a structure tensor. We demonstrate our method on scenes with a 3 to 5 dimensional space, including soft shadows, motion blur, and depth of field. The results show that our method uses fewer samples than Mittchell's adaptive sampling technique while producing images with less noise.},
  journal    = {ACM Trans. Graph.},
  month      = {8},
  pages      = {1-10},
  numpages   = {10},
  keywords   = {global illumination, rendering equation, sampling and reconstruction, ray tracing}
}

@inproceedings{10.1145/166117.166154,
  author    = {Shinya, Mikio},
  title     = {Spatial Anti-Aliasing for Animation Sequences with Spatio-Temporal Filtering},
  year      = {1993},
  isbn      = {0897916018},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/166117.166154},
  booktitle = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {289-296},
  numpages  = {8},
  keywords  = {computer animation, anti-aliasing, spatio-temporal filtering},
  location  = {Anaheim, CA},
  series    = {SIGGRAPH '93}
}

@article{10.1145/1618452.1618486,
  author     = {Overbeck, Ryan S. and Donner, Craig and Ramamoorthi, Ravi},
  title      = {Adaptive Wavelet Rendering},
  year       = {2009},
  issue_date = {December 2009},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {28},
  number     = {5},
  issn       = {0730-0301},
  doi        = {10.1145/1618452.1618486},
  abstract   = {Effects such as depth of field, area lighting, antialiasing and global illumination require evaluating a complex high-dimensional integral at each pixel of an image. We develop a new adaptive rendering algorithm that greatly reduces the number of samples needed for Monte Carlo integration. Our method renders directly into an image-space wavelet basis. First, we adaptively distribute Monte Carlo samples to reduce the variance of the wavelet basis' scale coefficients, while using the wavelet coefficients to find edges. Working in wavelets, rather than pixels, allows us to sample not only image-space edges but also other features that are smooth in the image plane but have high variance in other integral dimensions. In the second stage, we reconstruct the image from these samples by using a suitable wavelet approximation. We achieve this by subtracting an estimate of the error in each wavelet coefficient from its magnitude, effectively producing the smoothest image consistent with the rendering samples. Our algorithm renders scenes with significantly fewer samples than basic Monte Carlo or adaptive techniques. Moreover, the method introduces minimal overhead, and can be efficiently included in an optimized ray-tracing system.},
  journal    = {ACM Trans. Graph.},
  month      = {12},
  pages      = {1-12},
  numpages   = {12}
}

@article{10.1145/2487228.2487239,
  author     = {Belcour, Laurent and Soler, Cyril and Subr, Kartic and Holzschuch, Nicolas and Durand, Fredo},
  title      = {{5D} Covariance Tracing for Efficient Defocus and Motion Blur},
  year       = {2013},
  issue_date = {June 2013},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {32},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/2487228.2487239},
  abstract   = {The rendering of effects such as motion blur and depth-of-field requires costly 5D integrals. We accelerate their computation through adaptive sampling and reconstruction based on the prediction of the anisotropy and bandwidth of the integrand. For this, we develop a new frequency analysis of the 5D temporal light-field, and show that first-order motion can be handled through simple changes of coordinates in 5D. We further introduce a compact representation of the spectrum using the covariance matrix and Gaussian approximations. We derive update equations for the 5 \texttimes{} 5 covariance matrices for each atomic light transport event, such as transport, occlusion, BRDF, texture, lens, and motion. The focus on atomic operations makes our work general, and removes the need for special-case formulas. We present a new rendering algorithm that computes 5D covariance matrices on the image plane by tracing paths through the scene, focusing on the single-bounce case. This allows us to reduce sampling rates when appropriate and perform reconstruction of images with complex depth-of-field and motion blur effects.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {31},
  numpages   = {18},
  keywords   = {global illumination, Fourier analysis, motion blur}
}

@article{10.1145/2641762,
  author     = {Moon, Bochang and Carr, Nathan and Yoon, Sung-Eui},
  title      = {Adaptive Rendering Based on Weighted Local Regression},
  year       = {2014},
  issue_date = {August 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {5},
  issn       = {0730-0301},
  doi        = {10.1145/2641762},
  abstract   = {Monte Carlo ray tracing is considered one of the most effective techniques for rendering photo-realistic imagery, but requires a large number of ray samples to produce converged or even visually pleasing images. We develop a novel image-plane adaptive sampling and reconstruction method based on local regression theory. A novel local space estimation process is proposed for employing the local regression, by robustly addressing noisy high-dimensional features. Given the local regression on estimated local space, we provide a novel two-step optimization process for selecting bandwidths of features locally in a data-driven way. Local weighted regression is then applied using the computed bandwidths to produce a smooth image reconstruction with well-preserved details. We derive an error analysis to guide our adaptive sampling process at the local space. We demonstrate that our method produces more accurate and visually pleasing results over the state-of-the-art techniques across a wide range of rendering effects. Our method also allows users to employ an arbitrary set of features, including noisy features, and robustly computes a subset of them by ignoring noisy features and decorrelating them for higher quality.},
  journal    = {ACM Trans. Graph.},
  month      = {9},
  articleno  = {170},
  numpages   = {14},
  keywords   = {image-space reconstruction, Monte Carlo ray tracing, Adaptive rendering}
}

@article{5432169,
  author  = {Sen, Pradeep and Darabi, Soheil},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Compressive Rendering: A Rendering Application of Compressed Sensing},
  year    = {2011},
  volume  = {17},
  number  = {4},
  pages   = {487-499},
  doi     = {10.1109/TVCG.2010.46}
}

@inproceedings{10.2312:egtp.19911013,
  booktitle = {EG 1991-Technical Papers},
  title     = {Discrepancy as a Quality Measure for Sample Distributions},
  author    = {Shirley, Peter S.},
  year      = {1991},
  publisher = {Eurographics Association},
  issn      = {1017-4656},
  doi       = {10.2312/egtp.19911013}
}

@inproceedings{Mitchell92raytracing,
  author    = {Mitchell, Don P.},
  title     = {Ray Tracing and Irregularities of Distribution},
  booktitle = {In Third Eurographics Workshop on Rendering},
  year      = {1992},
  pages     = {61-69}
}

@inproceedings{Dobkin1993:9,
  author    = {Dobkin, David P. and Mitchell, Don P.},
  title     = {Random-edge discrepancy of supersampling patterns},
  booktitle = {Proceedings of Graphics Interface '93},
  series    = {GI '93},
  year      = {1993},
  isbn      = {0-9695338-2-9},
  issn      = {0713-5424},
  location  = {Toronto, Ontario, Canada},
  pages     = {62-69},
  numpages  = {8},
  doi       = {10.20380/GI1993.09},
  publisher = {Canadian Human-Computer Communications Society},
  address   = {Toronto, Ontario, Canada}
}

@article{10.1145/234535.234536,
  author     = {Dobkin, David P. and Eppstein, David and Mitchell, Don P.},
  title      = {Computing the Discrepancy with Applications to Supersampling Patterns},
  year       = {1996},
  issue_date = {Oct. 1996},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {15},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/234535.234536},
  abstract   = {Patterns used for supersampling in graphics have been analyzed from statistical and signal-processing viewpoints. We present an analysis based on a type of isotropic discrepancy—how good patterns are at estimating the area in a region of defined type. We present algorithms for computing discrepancy relative to regions that are defined by rectangles, halfplanes, and higher-dimensional figures. Experimental evidence shows that popular supersampling patterns have discrepancies with better asymptotic behavior than random sampling, which is not inconsistent with theoretical bounds on discrepancy.},
  journal    = {ACM Trans. Graph.},
  month      = {10},
  pages      = {354-376},
  numpages   = {23},
  keywords   = {supersampling, discrepancy}
}


@book{10.1137/1.9781611970081,
  author    = {Niederreiter, Harald},
  title     = {Random Number Generation and Quasi-{M}onte {C}arlo Methods},
  publisher = {Society for Industrial and Applied Mathematics},
  year      = {1992},
  doi       = {10.1137/1.9781611970081}
}

@book{dick_pillichshammer_2010,
  place     = {Cambridge},
  title     = {Digital Nets and Sequences: Discrepancy Theory and Quasi-{M}onte {C}arlo Integration},
  doi       = {10.1017/CBO9780511761188},
  publisher = {Cambridge University Press},
  author    = {Dick, Josef and Pillichshammer, Friedrich},
  year      = {2010}
}

@article{FAURE199247,
  title    = {Good permutations for extreme discrepancy},
  journal  = {Journal of Number Theory},
  volume   = {42},
  number   = {1},
  pages    = {47-56},
  year     = {1992},
  issn     = {0022-314X},
  doi      = {10.1016/0022-314X(92)90107-Z},
  author   = {Henri Faure},
  abstract = {The asymptotic behaviour of the discrepancy of the usual van der Corput sequences in arbitrary base b is known; and the implied constants tend to infinity with the base b. The aim of this paper is, first, to prove that for every base b there exist permutations of the digits such that the constants are less than 1Log 2 = 1.442… and, second, to produce a permutation, in base b = 36, giving the smallest discrepancy presently known: lim sup(D(N)Log N) = 23(35 Log 6) = 0.366….}
}

@inproceedings{10.1007/978-3-642-27440-4_21,
  author    = {Gr\"{u}nschlo\ss{}, Leonhard and Raab, Matthias and Keller, Alexander},
  editor    = {Plaskota, Leszek and Wo{\'{z}}niakowski, Henryk},
  title     = {Enumerating Quasi-{M}onte {C}arlo Point Sequences in Elementary Intervals},
  booktitle = {Monte Carlo and  Quasi-Monte Carlo Methods 2010},
  year      = {2012},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {399-408},
  abstract  = {Low discrepancy sequences, which are based on radical inversion, expose an intrinsic stratification. New algorithms are presented to efficiently enumerate the points of the Halton and (t, s)-sequences per stratum. This allows for consistent and adaptive integro-approximation as for example in image synthesis.},
  isbn      = {978-3-642-27440-4}
}

@inproceedings{10.1007/978-3-7091-7484-5_11,
  author    = {Keller, Alexander},
  editor    = {Pueyo, Xavier and Schr{\"o}der, Peter},
  title     = {Quasi-Monte Carlo Radiosity},
  booktitle = {Rendering Techniques '96},
  year      = {1996},
  publisher = {Springer Vienna},
  address   = {Vienna},
  pages     = {101-110},
  abstract  = {The problem of global illumination in computer graphics is described by a second kind Fredholm integral equation. Due to the complexity of this equation, Monte Carlo methods provide an interesting tool for approximating solutions to this transport equation. For the case of the radiosity equation, we present the deterministic method of quasi-random walks. This method very efficiently uses low discrepancy sequences for integrating the Neumann series and consistently outperforms stochastic techniques. The method of quasi-random walks is also applicable to transport problems in settings other than computer graphics.},
  isbn      = {978-3-7091-7484-5}
}

@inproceedings{10.1145/258734.258769,
  author    = {Keller, Alexander},
  title     = {Instant Radiosity},
  year      = {1997},
  isbn      = {0897918967},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/258734.258769},
  booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {49-56},
  numpages  = {8},
  keywords  = {Monte Carlo integration, radiance equation, quasi-random walk, quasi-Monte Carlo integration, photorealism, shading, realtime rendering algorithms, jittered low discrepany sampling, radiosity, hardware, accumulation buffer},
  series    = {SIGGRAPH '97}
}

@techreport{Keller03strictlydeterministic,
  author      = {Keller, Alexander},
  title       = {Strictly Deterministic Sampling Methods in Computer Graphics},
  institution = {SIGGRAPH 2003 Course Notes, Course \#44: Monte Carlo Ray Tracing},
  year        = {2003}
}

@inproceedings{10.1007/978-3-642-56046-0_17,
  author    = {Friedel, Ilja and Keller, Alexander},
  editor    = {Fang, Kai-Tai and Niederreiter, Harald and Hickernell, Fred J.},
  title     = {Fast Generation of Randomized Low-Discrepancy Point Sets},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2000},
  year      = {2002},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {257-273},
  abstract  = {We introduce two novel techniques for speeding up the generation of digital (t,s)-sequences. Based on these results a new algorithm for the construction of Owen's randomly permuted (t,s)---sequences is developed and analyzed. An implementation is available at http://www. mcqmc. org/Sof tware. html.},
  isbn      = {978-3-642-56046-0}
}

@inproceedings{10.1007/978-3-540-74496-2_23,
  author    = {Gr\"{u}nschlo\ss{}, Leonhard and Hanika, Johannes and Schwede, Ronnie and Keller, Alexander},
  editor    = {Keller, Alexander and Heinrich, Stefan and Niederreiter, Harald},
  title     = {(t, m, s)-Nets and Maximized Minimum Distance},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2006},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {397-412},
  abstract  = {Many experiments in computer graphics imply that the average quality of quasi-Monte Carlo integro-approximation is improved as the minimal distance of the point set grows. While the definition of (t, m, s)-nets in base b guarantees extensive stratification properties, which are best for t = 0, sampling points can still lie arbitrarily close together. We remove this degree of freedom, report results of two computer searches for (0, m, 2)-nets in base 2 with maximized minimum distance, and present an inferred construction for general m. The findings are especially useful in computer graphics and, unexpectedly, some (0, m, 2)-nets with the best minimum distance properties cannot be generated in the classical way using generator matrices.},
  isbn      = {978-3-540-74496-2}
}

@article{SOBOL196786,
  title   = {On the distribution of points in a cube and the approximate evaluation of integrals},
  journal = {USSR Computational Mathematics and Mathematical Physics},
  volume  = {7},
  number  = {4},
  pages   = {86-112},
  year    = {1967},
  issn    = {0041-5553},
  doi     = {10.1016/0041-5553(67)90144-9},
  author  = {Sobol', I.M}
}

@article{10.1137/070709359,
  author   = {Joe, Stephen and Kuo, Frances Y.},
  title    = {Constructing Sobol Sequences with Better Two-Dimensional Projections},
  journal  = {SIAM Journal on Scientific Computing},
  volume   = {30},
  number   = {5},
  pages    = {2635-2654},
  year     = {2008},
  doi      = {10.1137/070709359},
  abstract = { Direction numbers for generating Sobol\$'\$ sequences that satisfy the so-called Property A in up to 1111 dimensions have previously been given in Joe and Kuo [ACM Trans. Math. Software, 29 (2003), pp. 49–57]. However, these Sobol\$'\$ sequences may have poor two-dimensional projections. Here we provide a new set of direction numbers alleviating this problem. These are obtained by treating Sobol\$'\$ sequences in d dimensions as \$(t,d)\$-sequences and then optimizing the t-values of the two-dimensional projections. Our target dimension is 21201. }
}

@inproceedings{10.1145/800224.806784,
  author    = {Kajiya, James T. and Ullner, Michael Karl},
  title     = {Filtering High Quality Text for Display on Raster Scan Devices},
  year      = {1981},
  isbn      = {0897910451},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/800224.806784},
  abstract  = {Recently several investigators have studied the problem of displaying text characters on grey level raster scan displays. Despite arguments suggesting that grey level displays are equivalent to very high resolution bitmaps, the performance of grey level displays has been disappointing. This paper will show that much of the problem can be traced to inappropriate antialiasing procedures. Instead of the classical (sin x)/x filter, the situation calls for a filter with characteristics matched both to the nature of display on CRTs and to the human visual system. We give examples to illustrate the problems of the existing methods and the advantages of the new methods. Although the techniques are described in terms of text, the results have application to the general antialiasing problem—at least in theory if not in practice.},
  booktitle = {Proceedings of the 8th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {7-15},
  numpages  = {9},
  location  = {Dallas, Texas, USA},
  series    = {SIGGRAPH '81}
}

@article{10.1889/1.1832941,
  author   = {Betrisey, Claude and Blinn, James F. and Dresevic, Bodin and Hill, Bill and Hitchcock, Greg and Keely, Bert and Mitchell, Don P. and Platt, John C. and Whitted, Turner},
  title    = {Displaced Filtering for Patterned Displays},
  journal  = {SID Symposium Digest of Technical Papers},
  volume   = {31},
  number   = {1},
  pages    = {296-299},
  doi      = {10.1889/1.1832941},
  abstract = {Abstract This paper describes the filtering used in Microsoft ClearType. ClearType is a software system than enhances the resolution and readability of fonts on displays that contain a repeating pattern of addressable colored sub-pixels. The filtering in ClearType is based on a perceptual model of human vision. The perceptual model leads to an optimization technique for finding the best output values. The results of the optimization can be approximated by pre-filtering each color channel of an input image and then sampling each filtered color image at the spatial locations of the same colored sub-pixels in the display. We refer to this filtering followed by displaced sampling as RGB decimation. RGB decimation eliminates the phase error caused by standard anti-aliasing. A further approximation of the optimal filter yields RGB decimation with displaced box filters. Fourier analysis demonstrates that both the optimization technique and the displaced box filter suppress frequencies that contribute most to color fringing in unfiltered displaced sampling.},
  year     = {2000}
}

@inproceedings{10.5555/2532129.2532161,
  author    = {Alim, Usman R.},
  title     = {Rendering in Shift-Invariant Spaces},
  year      = {2013},
  isbn      = {9781482216806},
  publisher = {Canadian Information Processing Society},
  address   = {CAN},
  abstract  = {We present a novel image representation method based on shift-invariant spaces. Unlike existing rendering methods, our proposed approach consists of two steps: an analog acquisition step that traces rays through the scene, and a subsequent digital processing step that filters the intermediate digital image to obtain the coefficients of a minimum-error continuous image approximation. Our approach can be easily incorporated in existing renderers with very little change and with little-to-no computational overhead. Additionally, we introduce the necessary tools needed to analyze the smoothing and post-aliasing properties of the minimum-error approximations.We provide examples of spaces --- generated by the uniform B-splines --- that can be readily used in conjunction with the two-dimensional Cartesian grid. Our experimental results demonstrate that minimum-error approximations significantly enhance image quality by preserving high-frequency details that are usually smoothed out by existing image anti-aliasing approaches.},
  booktitle = {Proceedings of Graphics Interface 2013},
  pages     = {189-196},
  numpages  = {8},
  location  = {Regina, Sascatchewan, Canada},
  series    = {GI '13}
}

@inbook{10.5555/90767.90805,
  author    = {Turkowski, Ken},
  title     = {Filters for Common Resampling Tasks},
  year      = {1990},
  isbn      = {0122861695},
  publisher = {Academic Press Professional, Inc.},
  address   = {San Diego, USA},
  booktitle = {Graphics Gems},
  pages     = {147-165},
  numpages  = {19}
}

@inproceedings{10.1007/10704282_23,
  author    = {Meijering, Erik H. W. and Niessen, Wiro J. and Pluim, Josien P. W. and Viergever, Max A.},
  editor    = {Taylor, Chris and Colchester, Alain},
  title     = {Quantitative Comparison of Sinc-Approximating Kernels for Medical Image Interpolation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI'99},
  year      = {1999},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {210-217},
  abstract  = {Interpolation is required in many medical image processing operations. From sampling theory, it follows that the ideal interpolation kernel is the sinc function, which is of infinite extent. In the attempt to obtain practical and computationally efficient image processing algorithms, many sinc-approximating interpolation kernels have been devised. In this paper we present the results of a quantitative comparison of 84 different sinc-approximating kernels, with spatial extents ranging from 2 to 10 grid points in each dimension. The evaluation involves the application of geometrical transformations to medical images from different modalities (CT, MR, and PET), using the different kernels. The results show very clearly that, of all kernels with a spatial extent of 2 grid points, the linear interpolation kernel performs best. Of all kernels with an extent of 4 grid points, the cubic convolution kernel is the best (28{\%} -- 75{\%} reduction of the errors as compared to linear interpolation). Even better results (44{\%} -- 95{\%} reduction) are obtained with kernels of larger extent, notably the Welch, Cosine, Lanczos, and Kaiser windowed sinc kernels. In general, the truncated sinc kernel is one of the worst performing kernels.},
  isbn      = {978-3-540-48232-1}
}

@article{597800,
  author  = {Moller, Torsten and Machiraju, Raghu and Mueller, Klaus and Yagel, Roni},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Evaluation and design of filters using a {T}aylor series expansion},
  year    = {1997},
  volume  = {3},
  number  = {2},
  pages   = {184-199},
  doi     = {10.1109/2945.597800}
}

@article{556504,
  author  = {Machiraju, Raghu and Yagel, Roni},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title   = {Reconstruction error characterization and control: a sampling theory approach},
  year    = {1996},
  volume  = {2},
  number  = {4},
  pages   = {364-378},
  doi     = {10.1109/2945.556504}
}

@inproceedings{10.1145/1572769.1572787,
  author    = {Reshetov, Alexander},
  title     = {Morphological Antialiasing},
  year      = {2009},
  isbn      = {9781605586038},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1572769.1572787},
  abstract  = {We present a new algorithm that creates plausibly antialiased images by looking for certain patterns in an original image and then blending colors in the neighborhood of these patterns according to a set of simple rules. We construct these rules to work as a post-processing step in ray tracing applications, allowing approximate, yet fast and robust antialiasing. The algorithm works for any rendering technique and scene complexity. It does not require casting any additional rays and handles all possible effects, including reflections and refractions.},
  booktitle = {Proceedings of the Conference on High Performance Graphics 2009},
  pages     = {109-116},
  numpages  = {8},
  keywords  = {antialiasing, rendering, morphological analysis, image enhancement},
  location  = {New Orleans, Louisiana},
  series    = {HPG '09}
}

@inproceedings{Guertin2014MotionBlur,
  author    = {Guertin, Jean-Philippe and McGuire, Morgan and Nowrouzezahrai, Derek},
  title     = {A Fast and Stable Feature-Aware Motion Blur Filter},
  booktitle = {Proceedings of the {ACM} {SIGGRAPH}/{EuroGraphics} High Performance Graphics 2014 ({HPG'14})},
  note      = {HPG},
  month     = {6},
  day       = {24},
  year      = {2014},
  pages     = {10},
  url       = {https://casual-effects.com/research/Guertin2014MotionBlur/index.html},
  publisher = {{ACM}/Eurographics}
}

@article{55149,
  author  = {Lee, Mark E. and Redner, Richard A.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {A note on the use of nonlinear filtering in computer graphics},
  year    = {1990},
  volume  = {10},
  number  = {3},
  pages   = {23-29},
  doi     = {10.1109/38.55149}
}

@article{10.1145/2010324.1964950,
  author     = {Lehtinen, Jaakko and Aila, Timo and Chen, Jiawen and Laine, Samuli and Durand, Fr\'{e}do},
  title      = {Temporal Light Field Reconstruction for Rendering Distribution Effects},
  year       = {2011},
  issue_date = {July 2011},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {30},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/2010324.1964950},
  abstract   = {Traditionally, effects that require evaluating multidimensional integrals for each pixel, such as motion blur, depth of field, and soft shadows, suffer from noise due to the variance of the high-dimensional integrand. In this paper, we describe a general reconstruction technique that exploits the anisotropy in the temporal light field and permits efficient reuse of samples between pixels, multiplying the effective sampling rate by a large factor. We show that our technique can be applied in situations that are challenging or impossible for previous anisotropic reconstruction methods, and that it can yield good results with very sparse inputs. We demonstrate our method for simultaneous motion blur, depth of field, and soft shadows.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {55},
  numpages   = {12},
  keywords   = {depth of field, light field, motion blur, reconstruction, soft shadows}
}

@article{10.1145/2185520.2185547,
  author     = {Lehtinen, Jaakko and Aila, Timo and Laine, Samuli and Durand, Fr\'{e}do},
  title      = {Reconstructing the Indirect Light Field for Global Illumination},
  year       = {2012},
  issue_date = {July 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/2185520.2185547},
  abstract   = {Stochastic techniques for rendering indirect illumination suffer from noise due to the variance in the integrand. In this paper, we describe a general reconstruction technique that exploits anisotropy in the light field and permits efficient reuse of input samples between pixels or world-space locations, multiplying the effective sampling rate by a large factor. Our technique introduces visibility-aware anisotropic reconstruction to indirect illumination, ambient occlusion and glossy reflections. It operates on point samples without knowledge of the scene, and can thus be seen as an advanced image filter. Our results show dramatic improvement in image quality while using very sparse input samplings.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {51},
  numpages   = {10},
  keywords   = {reconstruction, ambient occlusion, defocus, indirect illumination, light field, motion blur}
}

@article{10.1111/cgf.12029,
  author   = {Kalantari, Nima Khademi and Sen, Pradeep},
  title    = {Removing the Noise in {M}onte {C}arlo Rendering with General Image Denoising Algorithms},
  journal  = {Computer Graphics Forum},
  volume   = {32},
  number   = {2pt1},
  pages    = {93-102},
  keywords = {Computing Methodologies I.3.7: Computer Graphics—Three-Dimensional Graphics and Realism},
  doi      = {10.1111/cgf.12029},
  abstract = {Abstract Monte Carlo rendering systems can produce important visual effects such as depth of field, motion blur, and area lighting, but the rendered images suffer from objectionable noise at low sampling rates. Although years of research in image processing has produced powerful denoising algorithms, most of them assume that the noise is spatially-invariant over the entire image and cannot be directly applied to denoise Monte Carlo rendering. In this paper, we propose a new approach that enables the use of any spatially-invariant image denoising technique to remove the noise in Monte Carlo renderings. Our key insight is to use a noise estimation metric to locally identify the amount of noise in different parts of the image, coupled with a multilevel algorithm that denoises the image in a spatially-varying manner using a standard denoising technique. We also propose a new way to perform adaptive sampling that uses the noise estimation metric to identify the noisy regions in which to place more samples. We show that our framework runs in a few seconds with modern denoising algorithms and produces results that outperform state-of-the-art techniques in Monte Carlo rendering.},
  year     = {2013}
}

@article{10.1145/2366145.2366214,
  author     = {Rousselle, Fabrice and Knaus, Claude and Zwicker, Matthias},
  title      = {Adaptive Rendering with Non-Local Means Filtering},
  year       = {2012},
  issue_date = {November 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {6},
  issn       = {0730-0301},
  doi        = {10.1145/2366145.2366214},
  abstract   = {We propose a novel approach for image space adaptive sampling and filtering in Monte Carlo rendering. We use an iterative scheme composed of three steps. First, we adaptively distribute samples in the image plane. Second, we denoise the image using a non-linear filter. Third, we estimate the residual per-pixel error of the filtered rendering, and the error estimate guides the sample distribution in the next iteration. The effectiveness of our approach hinges on the use of a state of the art image denoising technique, which we extend to an adaptive rendering framework. A key idea is to split the Monte Carlo samples into two buffers. This improves denoising performance and facilitates variance and error estimation. Our method relies only on the Monte Carlo samples, allowing us to handle arbitrary light transport and lens effects. In addition, it is robust to high noise levels and complex image content. We compare our approach to a state of the art adaptive rendering technique based on adaptive bandwidth selection and demonstrate substantial improvements in terms of both numerical error and visual quality. Our framework is easy to implement on top of standard Monte Carlo renderers and it incurs little computational overhead.},
  journal    = {ACM Trans. Graph.},
  month      = {11},
  articleno  = {195},
  numpages   = {11},
  keywords   = {adaptive sampling and reconstruction}
}

@article{10.1111/cgf.12219,
  author   = {Rousselle, Fabrice and Manzi, Marco and Zwicker, Matthias},
  title    = {Robust Denoising using Feature and Color Information},
  journal  = {Computer Graphics Forum},
  volume   = {32},
  number   = {7},
  pages    = {121-130},
  doi      = {10.1111/cgf.12219},
  abstract = {Abstract We propose a method that robustly combines color and feature buffers to denoise Monte Carlo renderings. On one hand, feature buffers, such as per pixel normals, textures, or depth, are effective in determining denoising filters because features are highly correlated with rendered images. Filters based solely on features, however, are prone to blurring image details that are not well represented by the features. On the other hand, color buffers represent all details, but they may be less effective to determine filters because they are contaminated by the noise that is supposed to be removed. We propose to obtain filters using a combination of color and feature buffers in an NL-means and cross-bilateral filtering framework. We determine a robust weighting of colors and features using a SURE-based error estimate. We show significant improvements in subjective and quantitative errors compared to the previous state-of-theart. We also demonstrate adaptive sampling and space-time filtering for animations.},
  year     = {2013}
}

@article{10.1145/2532708,
  author     = {Delbracio, Mauricio and Mus\'{e}, Pablo and Buades, Antoni and Chauvier, Julien and Phelps, Nicholas and Morel, Jean-Michel},
  title      = {Boosting {M}onte {C}arlo Rendering by Ray Histogram Fusion},
  year       = {2014},
  issue_date = {January 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {1},
  issn       = {0730-0301},
  doi        = {10.1145/2532708},
  abstract   = {This article proposes a new multiscale filter accelerating Monte Carlo renderer. Each pixel in the image is characterized by the colors of the rays that reach its surface. The proposed filter uses a statistical distance to compare with each other the ray color distributions associated with different pixels, at each scale. Based on this distance, it decides whether two pixels can share their rays or not. This simple and easily reproducible algorithm provides a psnr gain of 10 to 15 decibels, or equivalently accelerates the rendering process by using 10 to 30 times fewer samples without observable bias. The algorithm is consistent, does not assume a particular noise model, and is immediately extendable to synthetic movies. Being based on the ray color values only, it can be combined with all rendering effects.},
  journal    = {ACM Trans. Graph.},
  month      = {2},
  articleno  = {8},
  numpages   = {15},
  keywords   = {Monte Carlo rendering, adaptive filtering, nonlocal methods, global illumination, histogram distances}
}

@article{10.1111/cgf.12415,
  author   = {Munkberg, Jacob and Vaidyanathan, Karthik and Hasselgren, Jon and Clarberg, Petrik and Akenine-Möller, Tomas},
  title    = {Layered Reconstruction for Defocus and Motion Blur},
  journal  = {Computer Graphics Forum},
  volume   = {33},
  number   = {4},
  pages    = {81-92},
  keywords = {Categories and Subject Descriptors (according to ACM CCS), I.3.3 Computer Graphics: Three-Dimensional Graphics and Realism—Display Algorithms},
  doi      = {10.1111/cgf.12415},
  abstract = {Abstract Light field reconstruction algorithms can substantially decrease the noise in stochastically rendered images. Recent algorithms for defocus blur alone are both fast and accurate. However, motion blur is a considerably more complex type of camera effect, and as a consequence, current algorithms are either slow or too imprecise to use in high quality rendering. We extend previous work on real-time light field reconstruction for defocus blur to handle the case of simultaneous defocus and motion blur. By carefully introducing a few approximations, we derive a very efficient sheared reconstruction filter, which produces high quality images even for a low number of input samples. Our algorithm is temporally robust, and is about two orders of magnitude faster than previous work, making it suitable for both real-time rendering and as a post-processing pass for offline rendering.},
  year     = {2014}
}

@article{10.1111/cgf.12587,
  author   = {Bauszat, Pablo and Eisemann, Martin and Eisemann, Elmar and Magnor, Marcus},
  title    = {General and Robust Error Estimation and Reconstruction for {M}onte {C}arlo Rendering},
  journal  = {Computer Graphics Forum},
  volume   = {34},
  number   = {2},
  pages    = {597-608},
  keywords = {Categories and Subject Descriptors (according to ACM CCS), I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism—Raytracing},
  doi      = {10.1111/cgf.12587},
  abstract = {Abstract Adaptive filtering techniques have proven successful in handling non-uniform noise in Monte-Carlo rendering approaches. A recent trend is to choose an optimal filter per pixel from a selection of non spatially-varying filters. Nonetheless, the best filter choice is difficult to predict in the absence of a reference rendering. Our approach relies on the observation that the reconstruction error is locally smooth for a given filter. Hence, we propose to construct a dense error prediction from a small set of sparse but robust estimates. The filter selection is then formulated as a non-local optimization problem, which we solve via graph cuts, to avoid visual artifacts due to inconsistent filter choices. Our approach does not impose any restrictions on the used filters, outperforms previous state-of-the-art techniques and provides an extensible framework for future reconstruction techniques.},
  year     = {2015}
}

@article{10.1145/2766977,
  author     = {Kalantari, Nima Khademi and Bako, Steve and Sen, Pradeep},
  title      = {A Machine Learning Approach for Filtering {M}onte {C}arlo Noise},
  year       = {2015},
  issue_date = {August 2015},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {34},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/2766977},
  abstract   = {The most successful approaches for filtering Monte Carlo noise use feature-based filters (e.g., cross-bilateral and cross non-local means filters) that exploit additional scene features such as world positions and shading normals. However, their main challenge is finding the optimal weights for each feature in the filter to reduce noise but preserve scene detail. In this paper, we observe there is a complex relationship between the noisy scene data and the ideal filter parameters, and propose to learn this relationship using a nonlinear regression model. To do this, we use a multilayer perceptron neural network and combine it with a matching filter during both training and testing. To use our framework, we first train it in an offline process on a set of noisy images of scenes with a variety of distributed effects. Then at run-time, the trained network can be used to drive the filter parameters for new scenes to produce filtered images that approximate the ground truth. We demonstrate that our trained network can generate filtered images in only a few seconds that are superior to previous approaches on a wide range of distributed effects such as depth of field, motion blur, area lighting, glossy reflections, and global illumination.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {122},
  numpages   = {12},
  keywords   = {Monte Carlo rendering, neural networks}
}

@inproceedings{jensen1995optimizing,
  author    = {Jensen, Henrik Wann and Christensen, Niels J{\o}rgen},
  title     = {Optimizing Path Tracing using Noise Reduction Filters},
  year      = {1995},
  booktitle = {Proceedings of WSCG 1995},
  pages     = {134-142},
  url       = {http://wscg.zcu.cz/wscg1995/papers95/Jensen_95.pdf}
}

@phdthesis{keller1998quasi,
  author    = {Keller, Alexander},
  school    = {Technical University of Kaiserslautern},
  title     = {Quasi-{M}onte {C}arlo methods for photorealistic image synthesis},
  year      = {1998},
  publisher = {Shaker Verlag},
  address   = {Aachen},
  isbn      = {3-8265-3330-5}
}

@inproceedings{10.2312:EGWR:EGWR02:015-024,
  booktitle = {Proceedings of the 13th Eurographics Workshop on Rendering},
  editor    = {P. Debevec and S. Gibson},
  title     = {Interactive Global Illumination using Fast Ray Tracing},
  author    = {Wald, Ingo and Kollig, Thomas and Benthin, Carsten and Keller, Alexander and Slusallek, Philipp},
  year      = {2002},
  publisher = {The Eurographics Association},
  issn      = {1727-3463},
  isbn      = {1-58113-534-3},
  doi       = {10.2312/EGWR/EGWR02/015-024},
  pages     = {15-24},
  location  = {Pisa, Italy},
  series    = {EGRW '02},
  abstract  = {Rasterization hardware provides interactive frame rates for rendering dynamic scenes, but lacks the ability of ray tracing required for efficient global illumination simulation. Existing ray tracing based methods yield high quality renderings but are far too slow for interactive use. We present a new parallel global illumination algorithm that perfectly scales, has minimal preprocessing and communication overhead, applies highly efficient sampling techniques based on randomized quasi-Monte Carlo integration, and benefits from a fast parallel ray tracing implementation by shooting coherent groups of rays. Thus a performance is achieved that allows for applying arbitrary changes to the scene, while simulating global illumination including shadows from area light sources, indirect illumination, specular effects, and caustics at interactive frame rates. Ceasing interaction rapidly provides high quality renderings.}
}
@inproceedings{10.1007/3-540-31186-6_16,
  author    = {Kontkanen, Janne and R{\"a}s{\"a}nen, Jussi and Keller, Alexander},
  editor    = {Niederreiter, Harald and Talay, Denis},
  title     = {Irradiance Filtering for {M}onte {C}arlo Ray Tracing},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2004},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {259-272},
  abstract  = {Stochastic ray tracing algorithms generate photo-realistic images by simulating the global illumination. Typically a rather long computation time is required for decreasing the visible noise to an acceptable level. In this paper we propose a spatially variant low-pass filter for reducing this noise. We analyze the theoretical background of the method and present an efficient implementation that enables the use of a comparatively small number of samples while producing high quality images. Our algorithm can be used to accelerate path tracing and final gathering in photon mapping. We compare the method to irradiance caching and the results show that our algorithm renders images of similar or better quality up to five times faster.},
  isbn      = {978-3-540-31186-7},
  doi       = {10.1007/3-540-31186-6_16}
}

@article{10.1145/2601097.2601149,
  author     = {Lessig, Christian and Desbrun, Mathieu and Fiume, Eugene},
  title      = {A Constructive Theory of Sampling for Image Synthesis Using Reproducing Kernel Bases},
  year       = {2014},
  issue_date = {July 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {4},
  issn       = {0730-0301},
  doi        = {10.1145/2601097.2601149},
  abstract   = {Sampling a scene by tracing rays and reconstructing an image from such pointwise samples is fundamental to computer graphics. To improve the efficacy of these computations, we propose an alternative theory of sampling. In contrast to traditional formulations for image synthesis, which appeal to nonconstructive Dirac deltas, our theory employs constructive reproducing kernels for the correspondence between continuous functions and pointwise samples. Conceptually, this allows us to obtain a common mathematical formulation of almost all existing numerical techniques for image synthesis. Practically, it enables novel sampling based numerical techniques designed for light transport that provide considerably improved performance per sample. We exemplify the practical benefits of our formulation with three applications: pointwise transport of color spectra, projection of the light energy density into spherical harmonics, and approximation of the shading equation from a photon map. Experimental results verify the utility of our sampling formulation, with lower numerical error rates and enhanced visual quality compared to existing techniques.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {55},
  numpages   = {14},
  keywords   = {reproducing Kernel Hilbert Space, sampling, light transport simulation}
}

@article{10.1111/1467-8659.00212,
  author   = {Rougeron, Gilles and Péroche, Bernard},
  title    = {Color Fidelity in Computer Graphics: a Survey},
  journal  = {Computer Graphics Forum},
  volume   = {17},
  number   = {1},
  pages    = {3-15},
  keywords = {Spectral Rendering, Colorimetry, Vision Model, Color Monitor Model},
  doi      = {10.1111/1467-8659.00212},
  abstract = {The purpose of this paper is to make a state of the art for color fidelity in computer graphics. Color fidelity includes three steps. The first one is the spectral rendering phase which attributes a spectrum to each pixel of a picture. During the second step, a spectral data is transformed into a set of tristimulus values in the XYZ color space. The purpose of the third step, called Color Reproduction Function, is to determine the RGB values displayable on the screen, in such a way that subjective fidelity is reached. We especially detail the two last steps of the color fidelity process; we also point out the work still remaining to be done in this field and we propose some research ways.},
  year     = {1998}
}

@article{252554,
  author  = {Tumblin, Jack and Rushmeier, Holly},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Tone reproduction for realistic images},
  year    = {1993},
  volume  = {13},
  number  = {6},
  pages   = {42-48},
  doi     = {10.1109/38.252554}
}

@book{reinhard2010high,
  title     = {High dynamic range imaging},
  subtitle  = {acquisition, display, and image-based lighting},
  author    = {Reinhard, Erik and Heidrich, Wolfgang and Debevec, Paul and Pattanaik, Sumanta and Ward, Greg and Myszkowski, Karol},
  year      = {2010},
  publisher = {Morgan Kaufmann},
  isbn      = {9780123749147},
  edition   = {2},
  address   = {San Francisco}
}

@article{10.1145/2366145.2366220,
  author     = {Reinhard, Erik and Pouli, Tania and Kunkel, Timo and Long, Ben and Ballestad, Anders and Damberg, Gerwin},
  title      = {Calibrated Image Appearance Reproduction},
  year       = {2012},
  issue_date = {November 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {6},
  issn       = {0730-0301},
  doi        = {10.1145/2366145.2366220},
  abstract   = {Managing the appearance of images across different display environments is a difficult problem, exacerbated by the proliferation of high dynamic range imaging technologies. Tone reproduction is often limited to luminance adjustment and is rarely calibrated against psychophysical data, while color appearance modeling addresses color reproduction in a calibrated manner, albeit over a limited luminance range. Only a few image appearance models bridge the gap, borrowing ideas from both areas. Our take on scene reproduction reduces computational complexity with respect to the state-of-the-art, and adds a spatially varying model of lightness perception. The predictive capabilities of the model are validated against all psychophysical data known to us, and visual comparisons show accurate and robust reproduction for challenging high dynamic range scenes.},
  journal    = {ACM Trans. Graph.},
  month      = {11},
  articleno  = {201},
  numpages   = {11},
  keywords   = {tonemapping, color appearance, lightness perception, high dynamic range imaging}
}

@article{5719167,
  author  = {Gijsenij, Arjan and Gevers, Theo and van de Weijer, Joost},
  journal = {IEEE Transactions on Image Processing},
  title   = {Computational Color Constancy: Survey and Experiments},
  year    = {2011},
  volume  = {20},
  number  = {9},
  pages   = {2475-2489},
  doi     = {10.1109/TIP.2011.2118224}
}

@article{10.1111/j.1467-8659.2009.01487.x,
  author   = {Wilkie, Alexander and Weidlich, Andrea},
  title    = {A Robust Illumination Estimate for Chromatic Adaptation in Rendered Images},
  journal  = {Computer Graphics Forum},
  volume   = {28},
  number   = {4},
  pages    = {1101-1109},
  keywords = {Computer Graphics I.3.7: Three-Dimensional Graphics and Realism, Colour, shading, shadowing, and texture Image Processing and Computer Vision I.4.8: Scene Analysis, Colour},
  doi      = {10.1111/j.1467-8659.2009.01487.x},
  abstract = {Abstract We propose a method that improves automatic colour correction operations for rendered images. In particular, we propose a robust technique for estimating the visible and pertinent illumination in a given scene. We do this at very low computational cost by mostly re-using information that is already being computed during the image synthesis process. Conventional illuminant estimations either operate only on 2D image data, or, if they do go beyond pure image analysis, only use information on the luminaires found in the scene. The latter is usually done with little or no regard for how the light sources actually affect the part of the scene that is being viewed. Our technique goes beyond that, and also takes object reflectance into account, as well as the incident light that is actually responsible for the colour of the objects that one sees. It is therefore able to cope with difficult cases, such as scenes with mixed illuminants, complex scenes with many light sources of varying colour, or strongly coloured indirect illumination.},
  year     = {2009}
}

@book{wandell1995foundations,
  title     = {Foundations of Vision},
  author    = {Wandell, Brian A.},
  year      = {1995},
  publisher = {Sinauer Associates},
  isbn      = {978-0878938537},
  url       = {http://foundationsofvision.stanford.edu}
}

@article{946628,
  author  = {Ferwerda, James A.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {Elements of early vision for computer graphics},
  year    = {2001},
  volume  = {21},
  number  = {5},
  pages   = {22-33},
  doi     = {10.1109/38.946628}
}

@book{Malacara2011Color,
  author    = {Malacara, Daniel},
  title     = {Color Vision and Colorimetry},
  subtitle  = {Theory and Applications},
  edition   = {2},
  year      = {2011},
  isbn      = {9780819483973},
  publisher = {SPIE Press}
}

# 7.11
@inproceedings{10.1007/3-540-31186-6_14,
  author    = {Keller, Alexander},
  editor    = {Niederreiter, Harald and Talay, Denis},
  title     = {Myths of Computer Graphics},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2004},
  year      = {2006},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {217-243},
  abstract  = {Computer graphics textbooks teach that sampling by deterministic patterns or even lattices causes aliasing, which only can be avoided by random, i.e. independent sampling. They recommend random samples with blue noise characteristic, which however are highly correlated due to their maximized minimum mutual distance. On the other hand the rendering software mental ray, which is used to generate the majority of visual effects in movies, entirely is based on parametric integration by quasi-Monte Carlo methods and consequently is strictly deterministic. For its superior quality the software even received a Technical Achievement Award (Oscar) by the American Academy of Motion Picture Arts and Sciences in 2003. Along the milestones of more than ten years of development of quasi-Monte Carlo methods in computer graphics, we point out that the two previous statements are not contradictory.},
  isbn      = {978-3-540-31186-7}
}

@inproceedings{10.1007/978-3-540-74496-2_12,
  author    = {Dammertz, Sabrina and Keller, Alexander},
  editor    = {Keller, Alexander and Heinrich, Stefan and Niederreiter, Harald},
  title     = {Image Synthesis by Rank-1 Lattices},
  booktitle = {Monte Carlo and Quasi-Monte Carlo Methods 2006},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {217-236},
  abstract  = {Considering uniform points for sampling, rank-1 lattices provide the simplest generation algorithm. Compared to classical tensor product lattices or random samples, their geometry allows for a higher sampling efficiency. These considerations result in a proof that for periodic Lipschitz continuous functions, rank-1 lattices with maximized minimum distance perform best. This result is then investigated in the context of image synthesis, where we study anti-aliasing by rank-1 lattices and using the geometry of rank-1 lattices for sensor and display layouts.},
  isbn      = {978-3-540-74496-2}
}

@inproceedings{10.1145/122718.122723,
  author    = {Dorsey, Julie O'B. and Sillion, Fran\c{c}is X. and Greenberg, Donald P.},
  title     = {Design and Simulation of Opera Lighting and Projection Effects},
  year      = {1991},
  isbn      = {0897914368},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/122718.122723},
  abstract  = {A major problem challenging opera designers is the inability to co-ordinate lighting, projection systems, and set designs in the preliminary planning phase. New computer graphics techniques, which provide the set and lighting designer the opportunity to evaluate, test, and control opera designs prior to the construction of full scale systems are presented. These techniques---light source input, simulation of directional lighting, modeling of scenic projection systems, and full three-dimensional simulation---show the potential for the use of computer graphics in theater design.The light source input component consists of a program for assigning light source attributes with a set of theater lighting icons. This module allows a designer to specify light source characteristics in a way familiar to the discipline and to make preliminary evaluations of the lighting conditions.An extended progressive radiosity method is introduced to simulate the directional lighting characteristics which are specified by the input program.A new projection approach is presented to simulate the optical effects of scenic projectors. In addition, a solution to the distortion problem produced by angular projections is described.The above components are integrated to produce full three-dimensional simulations of the global illumination effects in an opera scene.},
  booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {41-50},
  numpages  = {10},
  series    = {SIGGRAPH '91}
}

@inproceedings{10.1145/237170.237199,
  author    = {Levoy, Marc and Hanrahan, Pat},
  title     = {Light Field Rendering},
  year      = {1996},
  isbn      = {0897917464},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/237170.237199},
  booktitle = {Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {31-42},
  numpages  = {12},
  keywords  = {epipolar analysis, holographic stereogram, image-based rendering, light field, vector quantization},
  series    = {SIGGRAPH '96}
}

@inproceedings{10.1145/237170.237200,
  author    = {Gortler, Steven J. and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael F.},
  title     = {The Lumigraph},
  year      = {1996},
  isbn      = {0897917464},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/237170.237200},
  booktitle = {Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {43-54},
  numpages  = {12},
  series    = {SIGGRAPH '96}
}

@inproceedings{10.1145/325334.325247,
  author    = {Perlin, Ken},
  title     = {An Image Synthesizer},
  year      = {1985},
  isbn      = {0897911660},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/325334.325247},
  abstract  = {We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle.Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of CGI.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.},
  booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {287-296},
  numpages  = {10},
  keywords  = {turbulence, algorithm development, functional composition, waves, stochastic modelling, pixel stream editor, interactive, space function, solid texture, fire},
  series    = {SIGGRAPH '85}
}

@inproceedings{10.1145/97879.97901,
  author    = {Saito, Takafumi and Takahashi, Tokiichiro},
  title     = {Comprehensible Rendering of 3-{D} Shapes},
  year      = {1990},
  isbn      = {0897913442},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/97879.97901},
  abstract  = {We propose a new rendering technique that produces 3-D images with enhanced visual comprehensibility. Shape features can be readily understood if certain geometric properties are enhanced. To achieve this, we develop drawing algorithms for discontinuities, edges, contour lines, and curved hatching. All of them are realized with 2-D image processing operations instead of line tracking processes, so that they can be efficiently combined with conventional surface rendering algorithms.Data about the geometric properties of the surfaces are preserved as Geometric Buffers (G-buffers). Each G-buffer contains one geometric property such as the depth or the normal vector of each pixel. By using G-buffers as intermediate results, artificial enhancement processes are separated from geometric processes (projection and hidden surface removal) and physical processes (shading and texture mapping), and performed as postprocesses. This permits a user to rapidly examine various combinations of enhancement techniques without excessive recomputation, and easily obtain the most comprehensible image.Our method can be widely applied for various purposes. Several of these, edge enhancement, line drawing illustrations, topographical maps, medical imaging, and surface analysis, are presented in this paper.},
  booktitle = {Proceedings of the 17th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {197-206},
  numpages  = {10},
  location  = {Dallas, TX, USA},
  series    = {SIGGRAPH '90}
}

@inproceedings{10.1145/344779.344938,
  author    = {Gershbein, Reid and Hanrahan, Pat},
  title     = {A Fast Relighting Engine for Interactive Cinematic Lighting Design},
  year      = {2000},
  isbn      = {1581132085},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/344779.344938},
  abstract  = {We present new techniques for interactive cinematic lighting design of complex scenes that use procedural shaders. Deep-framebuffers are used to store the geometric and optical information of the visible surfaces of an image. The geometric information is represented as collections of oriented points, and the optical information is represented as bi-directional reflection distribution functions, or BRDFs. The BRDFs are generated by procedurally defined surface texturing functions that spatially vary the surfaces' appearances.The deep-framebuffer information is rendered using a multi-pass algorithm built on the OpenGL graphics pipeline. In order to handle both physically-correct as well as non-realistic reflection models used in the film industry, we factor the BRDF into independent components that map onto both the lighting and texturing units of the graphics hardware. A similar factorization is used to control the lighting distribution. Using these techniques, lighting calculations can be evaluated 2500 times faster than previous methods. This allows lighting changes to be rendered at rates of 20Hz in static environments that contain millions of objects of with dozens of unique procedurally defined surface properties and scores of lights.},
  booktitle = {Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {353-358},
  numpages  = {6},
  keywords  = {animation, rendering, image-based rendering, illumination, texture mapping, rendering hardware, optics},
  series    = {SIGGRAPH '00}
}

@inproceedings{10.1145/280814.280882,
  author    = {Shade, Jonathan and Gortler, Steven and He, Li-wei and Szeliski, Richard},
  title     = {Layered Depth Images},
  year      = {1998},
  isbn      = {0897919998},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/280814.280882},
  booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {231-242},
  numpages  = {12},
  series    = {SIGGRAPH '98}
}

@article{10.1145/1531326.1531399,
  author     = {Egan, Kevin and Tseng, Yu-Ting and Holzschuch, Nicolas and Durand, Fr\'{e}do and Ramamoorthi, Ravi},
  title      = {Frequency Analysis and Sheared Reconstruction for Rendering Motion Blur},
  year       = {2009},
  issue_date = {August 2009},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {28},
  number     = {3},
  issn       = {0730-0301},
  doi        = {10.1145/1531326.1531399},
  abstract   = {Motion blur is crucial for high-quality rendering, but is also very expensive. Our first contribution is a frequency analysis of motion-blurred scenes, including moving objects, specular reflections, and shadows. We show that motion induces a shear in the frequency domain, and that the spectrum of moving scenes can be approximated by a wedge. This allows us to compute adaptive space-time sampling rates, to accelerate rendering. For uniform velocities and standard axis-aligned reconstruction, we show that the product of spatial and temporal bandlimits or sampling rates is constant, independent of velocity. Our second contribution is a novel sheared reconstruction filter that is aligned to the first-order direction of motion and enables even lower sampling rates. We present a rendering algorithm that computes a sheared reconstruction filter per pixel, without any intermediate Fourier representation. This often permits synthesis of motion-blurred images with far fewer rendering samples than standard techniques require.},
  journal    = {ACM Trans. Graph.},
  month      = {7},
  articleno  = {93},
  numpages   = {13},
  keywords   = {space-time, filter, anti-aliasing, light transport, frequency analysis, reconstruction, sampling, motion blur}
}
# 7.12
@book{DigitalSignalProcessing,
  author    = {程佩青},
  editor    = {文怡},
  publisher = {清华大学出版社},
  title     = {数字信号处理教程（第四版）},
  year      = {2013},
  address   = {北京},
  isbn      = {978-7-302-28313-3}
}

 @misc{enwiki:1115652231,
  author       = {{Wikipedia contributors}},
  title        = {{D}irac delta function --- {Wikipedia}{,} The Free Encyclopedia},
  year         = {2022},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Dirac_delta_function&oldid=1115652231}},
  note         = {[Online; accessed 23-October-2022]}
}

  @misc{enwiki:1115414995,
  author       = {{Wikipedia contributors}},
  title        = {{F}ourier transform --- {Wikipedia}{,} The Free Encyclopedia},
  year         = {2022},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Fourier_transform&oldid=1115414995}},
  note         = {[Online; accessed 25-October-2022]}
}

  @misc{enwiki:1098200554,
  author       = {{Wikipedia contributors}},
  title        = {{P}lancherel theorem --- {Wikipedia}{,} The Free Encyclopedia},
  year         = {2022},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Plancherel_theorem&oldid=1098200554}},
  note         = {[Online; accessed 26-October-2022]}
}
  
  @misc{enwiki:1114206769,
  author       = {{Wikipedia contributors}},
  title        = {Convolution theorem --- {Wikipedia}{,} The Free Encyclopedia},
  year         = {2022},
  howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Convolution_theorem&oldid=1114206769}},
  note         = {[Online; accessed 25-October-2022]}
}
# 7.13
@book{ElementaryNumberTheory,
  author    = {潘承洞 and 潘承彪},
  editor    = {刘勇},
  publisher = {北京大学出版社},
  title     = {初等数论},
  year      = {1992},
  address   = {北京},
  isbn      = {7-301-01848-7}
}

 @misc{wiki:ExtendedEuclideanAlgorithm,
  author = {维基百科},
  title  = {扩展欧几里得算法 --- 维基百科{,} 自由的百科全书},
  year   = {2022},
  url    = {https://zh.wikipedia.org/w/index.php?title=%E6%89%A9%E5%B1%95%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%AE%97%E6%B3%95&oldid=71676021},
  note   = {[Online; accessed 02-July-2022]}
}

 @misc{wiki:eye,
  author = {维基百科},
  title  = {眼 --- 维基百科{,} 自由的百科全书},
  year   = {2021},
  url    = {https://zh.wikipedia.org/w/index.php?title=%E7%9C%BC&oldid=67642524},
  note   = {[Online; accessed 19-December-2021]}
}

# 8.4
@inproceedings{10.1145/192161.192213,
  author    = {Oren, Michael and Nayar, Shree K.},
  title     = {Generalization of {L}ambert's Reflectance Model},
  year      = {1994},
  isbn      = {0897916670},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/192161.192213},
  abstract  = {Lambert's model for body reflection is widely used in computer graphics. It is used extensively by rendering techniques such as radiosity and ray tracing. For several real-world objects, however, Lambert's model can prove to be a very inaccurate approximation to the body reflectance. While the brightness of a Lambertian surface is independent of viewing direction, that of a rough surface increases as the viewing direction approaches the light source direction. In this paper, a comprehensive model is developed that predicts body reflectance from rough surfaces. The surface is modeled as a collection of Lambertian facets. It is shown that such a surface is inherently non-Lambertian due to the foreshortening of the surface facets. Further, the model accounts for complex geometric and radiometric phenomena such as masking, shadowing, and interreflections between facets. Several experiments have been conducted on samples of rough diffuse surfaces, such as, plaster, sand, clay, and cloth. All these surface demonstrate significant deviation from Lambertian behavior. The reflectance measurements obtained are in strong agreement with the reflectance predicted by the model.},
  booktitle = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {239-246},
  numpages  = {8},
  keywords  = {rough surfaces, Lambert's model, reflection models, BRDF, moon reflectance},
  series    = {SIGGRAPH '94}
}

@book{1987BeckmannSpizzichino,
  author    = {Beckmann, Petr and Spizzichino, Andre},
  title     = {The Scattering of Electromagnetic Waves from Rough Surfaces},
  year      = {1987},
  publisher = {Artech Print on Demand},
  isbn      = {9780890062388}
}

@article{Trowbridge:75,
  author    = {T. S. Trowbridge and K. P. Reitz},
  journal   = {Journal of the Optical Society of America},
  keywords  = {Diffraction; Electromagnetic radiation; Fresnel equations; Reflection; Refractive index; Surfaces},
  number    = {5},
  pages     = {531-536},
  publisher = {Optica Publishing Group},
  title     = {Average irregularity representation of a rough surface for ray reflection},
  volume    = {65},
  month     = {5},
  year      = {1975},
  doi       = {10.1364/JOSA.65.000531},
  abstract  = {A new ray model is presented for the reflection of electromagnetic radiation from the rough air-material interface of a randomly rough surface. Unlike previous derivations that modeled the rough interface as consisting of microareas randomly oriented but flat (facets), this derivation models it as consisting of microareas not only randomly oriented but also randomly curved. Physically, the models are the same, but this new derivation leads to some new results. (1) For any given rough surface, there exists a single, optically smooth, curved surface of revolution of very restricted shape that will reflect radiation in the same distribution as that reflected by the rough interface. (2) Modeling that surface as an ellipsoid of revolution gives a surface-structure function that appears more accurate and useful than existing ones. (3) Unlike the facet derivations, this derivation lends itself to a normalization that gives the absolute, instead of just a comparative, reflectance-distribution function.}
}

@inproceedings{10.5555/2383847.2383874,
  author    = {Walter, Bruce and Marschner, Stephen R. and Li, Hongsong and Torrance, Kenneth E.},
  title     = {Microfacet Models for Refraction through Rough Surfaces},
  year      = {2007},
  isbn      = {9783905673524},
  publisher = {Eurographics Association},
  address   = {Goslar, DEU},
  abstract  = {Microfacet models have proven very successful for modeling light reflection from rough surfaces. In this paper we review microfacet theory and demonstrate how it can be extended to simulate transmission through rough surfaces such as etched glass. We compare the resulting transmission model to measured data from several real surfaces and discuss appropriate choices for the microfacet distribution and shadowing-masking functions. Since rendering transmission through media requires tracking light that crosses at least two interfaces, good importance sampling is a practical necessity. Therefore, we also describe efficient schemes for sampling the microfacet models and the corresponding probability density functions.},
  booktitle = {Proceedings of the 18th Eurographics Conference on Rendering Techniques},
  pages     = {195-206},
  numpages  = {12},
  keywords  = {Monte Carlo sampling, cook-torrance model, refraction, global illumination, microfacet BTDF},
  location  = {Grenoble, France},
  series    = {EGSR'07}
}

@article{heitz:hal-01024289,
  title       = {Understanding the Masking-Shadowing Function in Microfacet-Based {BRDFs}},
  author      = {Heitz, Eric},
  url         = {https://inria.hal.science/hal-01024289},
  journal     = {Journal of Computer Graphics Techniques},
  publisher   = {Williams College},
  volume      = {3},
  number      = {2},
  pages       = {32-91},
  year        = {2014},
  month       = {6},
  hal_id      = {hal-01024289},
  hal_version = {v1}
}

# 8.5

@techreport{AshikhminPhong,
  author      = {Michael Ashikhmin and Peter Shirley},
  institution = {University of Utah},
  title       = {An anisotropic Phong light reflection model},
  type        = {Technical Report UUCS-00-014},
  url         = {https://www.cs.utah.edu/docs/techreports/2000/pdf/UUCS-00-014.pdf},
  year        = {2000}
}
@article{Ashikhmin01012000,
  author    = {Michael Ashikhmin and Peter Shirley},
  title     = {An Anisotropic Phong BRDF Model},
  journal   = {Journal of Graphics Tools},
  volume    = {5},
  number    = {2},
  pages     = {25-32},
  year      = {2000},
  publisher = {Taylor \& Francis},
  doi       = {10.1080/10867651.2000.10487522},
  abstract  = { We present a BRDF model that combines several advantages of the various empirical models currently in use. In particular, it has intuitive parameters, is anisotropic, conserves energy, is reciprocal, has an appropriate non-Lambertian diffuse term, and is well-suited for use in Monte Carlo renderers. }
}

@inproceedings{Schlick1993,
  author    = {Schlick, Christophe},
  year      = {1993},
  pages     = {73-83},
  title     = {A Customizable Reflectance Model for Everyday Rendering},
  booktitle = {Fourth Eurographics Workshop on Rendering},
  series    = {Eurographics Technical Report Series; EG 93 RW},
  address   = {Paris, France},
  publisher = {Eurographics Association},
  isbn      = {1017-4656}
}

# 08.ex01
@inproceedings{10.1145/344779.344814,
  author    = {Ashikmin, Michael and Premo\v{z}e, Simon and Shirley, Peter},
  title     = {A microfacet-based {BRDF} generator},
  year      = {2000},
  isbn      = {1581132085},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA},
  doi       = {10.1145/344779.344814},
  abstract  = {A method is presented that takes as an input a 2D microfacet orientation distribution and produces a 4D bidirectional reflectance distribution function (BRDF). This method differs from previous microfacet-based BRDF models in that it uses a simple shadowing term which allows it to handle very general microfacet distributions while maintaining reciprocity and energy conservation. The generator is shown on a variety of material types.},
  booktitle = {Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {65-74},
  numpages  = {10},
  keywords  = {reflectance \& shading models, rendering},
  series    = {SIGGRAPH '00}
}

@article{841905,
  author   = {Bourlier, Christophe and Saillard, Joseph and Berginc, Gérard},
  journal  = {IEEE Transactions on Antennas and Propagation},
  title    = {Effect of correlation between shadowing and shadowed points on the Wagner and Smith monostatic one-dimensional shadowing functions},
  year     = {2000},
  volume   = {48},
  number   = {3},
  pages    = {437-446},
  keywords = {Shadow mapping;Rough surfaces;Surface roughness;Electromagnetic scattering;Autocorrelation;Gaussian processes},
  doi      = {10.1109/8.841905}
}

@article{10.1111/1467-8659.1330233,
  author   = {Schlick, Christophe},
  title    = {An Inexpensive {BRDF} Model for Physically-based Rendering},
  journal  = {Computer Graphics Forum},
  volume   = {13},
  number   = {3},
  pages    = {233-246},
  keywords = {Physically-Based Rendering, Bidirectional Reflectance Distribution Function, Optimization},
  doi      = {https://doi.org/10.1111/1467-8659.1330233},
  abstract = {Abstract: A new BRDF model is presented which can be viewed as an kind of intermediary model between empirism and theory. Main results of physics are observed (energy conservation, reciprocity rule, microfacet theory) and numerous phenomena involved in light reflection are accounted for, in a physically plausible way (incoherent and coherent reflection, spectrum modifications, anisotropy, self-shadowing, multiple surface and subsurface reflection, differences between homogeneous and heterogeneous materials). The model has been especially intended for computer graphics applications and therefore includes two main features: simplicity (a small number of intuitively understandable parameters controls the model) and efficiency (the formulation provides adequation to Monte-Carlo rendering techniques and/or hardware implementations).},
  year     = {1994}
}

@article{1138991,
  author   = {Smith, Bruce G.},
  journal  = {IEEE Transactions on Antennas and Propagation},
  title    = {Geometrical shadowing of a random rough surface},
  year     = {1967},
  volume   = {15},
  number   = {5},
  pages    = {668-671},
  keywords = {Shadow mapping;Rough surfaces;Surface roughness;Surface waves;Backscatter;Solid modeling;Context modeling;Statistics;Probability;Computer simulation},
  doi      = {10.1109/TAP.1967.1138991}
}

        
@inproceedings{10.2312/egs.20011003,
  booktitle = {Eurographics 2001 - Short Presentations},
  title     = {{A Microfacet Based Coupled Specular-Matte BRDF Model with Importance Sampling}},
  author    = {Kelemen, Csaba and Szirmay-Kalos, Laszlo},
  year      = {2001},
  publisher = {Eurographics Association},
  issn      = {1017-4656},
  doi       = {/10.2312/egs.20011003}
}

@article{Heitz2018GGX,
  author  = {Eric Heitz},
  title   = {Sampling the GGX Distribution of Visible Normals},
  year    = {2018},
  month   = {11},
  day     = {30},
  journal = {Journal of Computer Graphics Techniques (JCGT)},
  volume  = {7},
  number  = {4},
  pages   = {1-13},
  url     = {http://jcgt.org/published/0007/04/01/},
  issn    = {2331-7418}
}          

@article{Torrance:67,
  author    = {Torrance, Kenneth E. and Sparrow, Ephraim M.},
  journal   = {Journal of the Optical Society of America},
  keywords  = {Absorption coefficient; Aluminum oxide; Bidirectional reflectance distribution function; Fresnel reflection; Reflection; Refractive index},
  number    = {9},
  pages     = {1105-1114},
  publisher = {Optica Publishing Group},
  title     = {Theory for Off-Specular Reflection From Roughened Surfaces},
  volume    = {57},
  month     = {09},
  year      = {1967},
  doi       = {10.1364/JOSA.57.001105},
  abstract  = {The directional distribution of radiant flux reflected from roughened surfaces is analyzed on the basis of geometrical optics. The analytical model assumes that the surface consists of small, randomly disposed, mirror-like facets. Specular reflection from these facets plus a diffuse component due to multiple reflections and/or internal scattering are postulated as the basic mechanisms of the reflection process. The effects of shadowing and masking of facets by adjacent facets are included in the analysis. The angular distributions of reflected flux predicted by the analysis are in very good agreement with experiment for both metallic and nonmetallic surfaces. Moreover, the analysis successfully predicts the off-specular maxima in the reflection distribution which are observed experimentally and which emerge as the incidence angle increases. The model thus affords a rational explanation for the off-specular peak phenomenon in terms of mutual masking and shadowing of mirror-like, specularly reflecting surface facets.}
}

@article{1142437,
  author   = {Brown, Gary S.},
  journal  = {IEEE Transactions on Antennas and Propagation},
  title    = {Shadowing by non-{G}aussian random surfaces},
  year     = {1980},
  volume   = {28},
  number   = {6},
  pages    = {788-790},
  keywords = {Shadow mapping;Sea surface;Rough surfaces;Surface roughness;Backscatter;Optical scattering;Probability density function;Geometrical optics;Sea ice;Sea level},
  doi      = {10.1109/TAP.1980.1142437}
}

